
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions &#8212; NVIDIA BioNeMo Framework</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../_static/design-tabs.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/bionemo-framework/0.4.0/notebooks/custom-dataset-dataloader.html" />
    <link rel="shortcut icon" href="../_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Adding the OAS Dataset: Downloading and Preprocessing" href="custom-dataset-preprocessing-fw.html" />
    <link rel="prev" title="Adding the OAS Dataset: Modifying the Dataset Class" href="custom-dataset-class-fw.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA BioNeMo Framework</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GETTING STARTED
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   What is BioNeMo?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pre-reqs.html">
   Hardware and Software Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../access-startup.html">
   Access and Startup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../initialization-guide.html">
   Initialization Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial-list.html">
   BioNeMo Framework Tutorials
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BioNeMo CORE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bionemo-fw-for-model-training-fw.html">
   Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-module-fw.html">
   Data Module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dwnstr-task-validation.html">
   Validation with a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../inference-triton-fw.html">
   Inference with Nvidia Triton Server
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-dive-esm1-pytriton-inference.html">
   Example of PyTriton Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BEST PRACTICES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../hyperparameters-fw.html">
   Hyperparameter Usage and Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../parallelism-fw.html">
   Training Parallelism
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODELS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../models/diffdock.html">
   DiffDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dnabert.html">
   DNABERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dsmbind.html">
   DSMBind
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/equidock.html">
   EquiDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm1-nv.html">
   ESM-1nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm2-nv.html">
   ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/geneformer.html">
   Geneformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/megamolbart.html">
   MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/molmim.html">
   MolMIM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/openfold.html">
   OpenFold
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/prott5nv.html">
   Prott5nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/model-benchmarks.html">
   Model Benchmarks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATASETS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/uniprot.html">
   UniProt Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/CELLxGENE.html">
   CELLxGENE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/zinc15.html">
   ZINC-15 Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/pdb.html">
   The Protein Data Bank (PDB)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/GRCh38.p13.html">
   Human Reference Genome Version GRCh38.p13
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/openproteinset.html">
   OpenProteinSet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/moleculenet-physchem.html">
   MoleculeNet Physical Chemistry Datasets - Lipophilicity, FreeSolv, ESOL
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TUTORIALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preprocessing-bcp-training-diffdock.html">
   DiffDock: Preparing Workspace and Data for Pre-training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2nv-mutant-design.html">
   Zero-Shot Protein Design Using ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MMB_GenerativeAI_Inference_with_examples.html">
   BioNeMo - MegaMolBART Inferencing for Generative Chemistry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MolMIM_GenerativeAI_local_inference_with_examples.html">
   MolMIM Inferencing for Generative Chemistry and Downstream Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ZINC15-data-preprocessing.html">
   ZINC Training Dataset Setup for small molecule language models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bionemo-finetuning-overview.html">
   Finetune pre-trained models in BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cma_es_guided_molecular_optimization_molmim.html">
   MolMIM Property Guided Molecular Optimization Using CMA-ES
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-class-fw.html">
   Adding the OAS Dataset: Modifying the Dataset Class
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-preprocessing-fw.html">
   Adding the OAS Dataset: Downloading and Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="encoder-finetuning-notebook-fw.html">
   Encoder Fine-tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_diffdock.html">
   DiffDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_equidock.html">
   EquiDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm1nv.html">
   ESM1nv Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm2nv.html">
   ESM-2nv: Data Preprocessing and Model Training Using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_mmb.html">
   MegaMolBART Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_molmim.html">
   Train MolMIM from scratch on your own data using the BioNeMo Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="physchem-notebook-fw.html">
   Finetuning LLM in BioNeMo for a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protein-esm2nv-clustering.html">
   Generating Embeddings for Protein Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="retrosynthesis-notebook.html">
   Training LLM for a Custom Downstram Task: Retrosynthesis Prediction using MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_FLIP_finetuning.html">
   Fine-Tune ESM-2nv on FLIP Data for Sequence-Level Classification, Regression, Token-Level Classification, and with LoRA Adapters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_oas_inferencing.html">
   Performing inference on OAS sequences with ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_paratope_finetuning.html">
   Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_inference.html">
   Generating and visualizing embeddings with DNABert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_pretrain_finetune.html">
   Pretrain, Fine-tune, and Perform Inference with DNABERT for Splice Site Prediction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  APPENDIX
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../faq-fw.html">
   Frequently Asked Questions (FAQ)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography-fw.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../releasenotes-fw.html">
   Release Notes
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup-and-assumptions">
     Setup and Assumptions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#customizing-a-collate-function">
     Customizing a collate function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#injecting-a-custom-collate-object-into-an-existing-model">
     Injecting a custom collate object into an existing model.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-the-dataset-object">
     Creating the Dataset object
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-our-new-collate-function">
     Testing our new collate function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataloader">
   DataLoader!
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-and-further-reading">
   Conclusion and further reading.
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup-and-assumptions">
     Setup and Assumptions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#customizing-a-collate-function">
     Customizing a collate function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#injecting-a-custom-collate-object-into-an-existing-model">
     Injecting a custom collate object into an existing model.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-the-dataset-object">
     Creating the Dataset object
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#testing-our-new-collate-function">
     Testing our new collate function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataloader">
   DataLoader!
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-and-further-reading">
   Conclusion and further reading.
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <div class="tex2jax_ignore mathjax_ignore section" id="adding-the-oas-dataset-customizing-dataset-object-and-dataloader-functions">
<h1>Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions<a class="headerlink" href="#adding-the-oas-dataset-customizing-dataset-object-and-dataloader-functions" title="Permalink to this headline">#</a></h1>
<p>This tutorial is the second part of a series focused on adding a new dataset to BioNeMo using the <a class="reference external" href="https://opig.stats.ox.ac.uk/webapps/oas/">Observed Antibody Space (OAS)</a> database. There are three steps to this task:</p>
<ol class="arabic simple">
<li><p>Preprocessing includes download of the raw data and any additional preparation steps, such as extracting the files. It also includes dividing the data into train, validation, and test splits. The preprocessing step can make use of two BioNeMo base classes, RemoteResource and ResourcePreprocessor, from bionemo.utils.remote and bionemo.data.preprocess, respectively. Their use is optional but they provide some basic functionality which can accelerate development. This step is covered by this tutorial. This objective was accomplished by the first tutorial, Downloading and Preprocessing.</p></li>
<li><p>Development of the new dataset class. Here, the NeMo dataset class CSVMemMapDataset will be used. This step was covered in the last tutorial, Modifying the Dataset Class.</p></li>
<li><p>Modification of the dataloader classes. This tutorial will cover customizing DataLoader objects using the newly created OAS datasets. This will include specifics on instantiating actual Dataset classes, customizing the collate function, and instantiating a dataloader. We will also review how these steps are executed within the BioNeMo model classes.</p></li>
</ol>
<div class="section" id="setup-and-assumptions">
<h2>Setup and Assumptions<a class="headerlink" href="#setup-and-assumptions" title="Permalink to this headline">#</a></h2>
<p>This tutorial assumes that a copy of the BioNeMo framework repo exists on workstation or server and has been mounted inside the container at /workspace/bionemo as described in the Code Development section of the Quickstart Guide. This path will be referred to with the variable BIONEMO_WORKSPACE in the tutorial.</p>
<p>All commands should be executed inside the BioNeMo docker container.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BIONEMO_WORKSPACE</span> <span class="o">=</span> <span class="s1">&#39;/workspace/bionemo&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_remove_input docutils container">
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TUTORIAL_FILE_VERSION</span> <span class="o">=</span> <span class="s1">&#39;step_999_final&#39;</span>
<span class="n">stage_files</span><span class="p">(</span><span class="n">TUTORIAL_FILE_VERSION</span><span class="p">,</span> <span class="n">source_directory</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">BIONEMO_WORKSPACE</span><span class="si">}</span><span class="s1">/examples/oas_dataset&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="customizing-a-collate-function">
<h2>Customizing a collate function<a class="headerlink" href="#customizing-a-collate-function" title="Permalink to this headline">#</a></h2>
<p>In the last tutorial we saw how you can modify your yaml file to use a different set of data with existing tooling, in some cases, this isn’t enough. The <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> parameter of pytorch DataLoaders if used for last minute adjustments to batches, including masking, shuffling, batching, padding, and other slight modifications to the input data. In BioNeMo, we build our collate function ontop of collators used for language modeling (<code class="docutils literal notranslate"><span class="pre">bionemo/data/dataloader/collate.py</span></code>).</p>
<p>The collate function is ultimately injected into the dataloader upon construction. To customize further, we can simply extend the existing <code class="docutils literal notranslate"><span class="pre">ProteinCollate</span></code> class with our own additional collation, followed by a call to the parents method.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><style>pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.output_html .hll { background-color: #ffffcc }
.output_html { background: #f8f8f8; }
.output_html .c { color: #3D7B7B; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #9C6500 } /* Comment.Preproc */
.output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #E40000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #008400 } /* Generic.Inserted */
.output_html .go { color: #717171 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #687822 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #767600 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #A45A77 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.</span>
<span class="c1"># SPDX-License-Identifier: Apache-2.0</span>

<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="nn">nemo.collections.common.tokenizers</span> <span class="kn">import</span> <span class="n">TokenizerSpec</span>
<span class="kn">from</span> <span class="nn">bionemo.data.dataloader.collate</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BertCollate</span><span class="p">,</span>
    <span class="n">BertMasking</span><span class="p">,</span>
    <span class="n">SentencePieceTokenizerAdapter</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">bionemo.data.dataloader.protein_collate</span> <span class="kn">import</span> <span class="n">ProteinBertCollate</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CustomProteinBertCollate&#39;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">CustomProteinBertCollate</span><span class="p">(</span><span class="n">ProteinBertCollate</span><span class="p">):</span>
   <span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">label_pad</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Parent does things like add padding, mask, onehot transformations, etc.</span>
<span class="sd">        in this case, we do the same thing but we sort our batch on values (strings)</span>
<span class="sd">        does this do anything useful in pratice? maybe not, but thats okay.</span>

<span class="sd">        This method ultimately will get injected into a DataLoader. We do this as a </span>
<span class="sd">        part of the standard dataloader setup method inside our ESM1nv model, by instantiating</span>
<span class="sd">        this class and then injecting the collate_fn.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">extra</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Handles odd cases</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">batch</span><span class="p">,</span> <span class="n">extra</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">back</span><span class="p">,</span> <span class="n">front</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)],</span> <span class="n">batch</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">):]</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">back</span> <span class="o">+</span> <span class="n">front</span> <span class="o">+</span> <span class="n">extra</span>

        <span class="n">new_batch</span> <span class="o">=</span> <span class="p">[</span> <span class="s1">&#39;A&#39;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">batch</span> <span class="p">]</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">(</span><span class="n">new_batch</span><span class="p">,</span> <span class="n">label_pad</span><span class="p">)</span>
</pre></div>
</div></div>
</div>
</div>
<div class="section" id="injecting-a-custom-collate-object-into-an-existing-model">
<h2>Injecting a custom collate object into an existing model.<a class="headerlink" href="#injecting-a-custom-collate-object-into-an-existing-model" title="Permalink to this headline">#</a></h2>
<p>The implemented collate function servers a single purpose, it replaces all characters with the character ‘A.’ This is both easy to implement and simple to check for correctness. Upon doing so, the batch is passed back into the parent collate function for padding and masking. Next, we will inject this into our esm1nv model to be applied to the dataset. You can see below that this occurs on the <code class="docutils literal notranslate"><span class="pre">build_pretraining_data_loader</span></code> method, which primarily operates on an already existing Dataset object.</p>
<div class="cell tag_remove_input docutils container">
<div class="cell_output docutils container">
<div class="output text_html"><style>pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.output_html .hll { background-color: #ffffcc }
.output_html { background: #f8f8f8; }
.output_html .c { color: #3D7B7B; font-style: italic } /* Comment */
.output_html .err { border: 1px solid #FF0000 } /* Error */
.output_html .k { color: #008000; font-weight: bold } /* Keyword */
.output_html .o { color: #666666 } /* Operator */
.output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.output_html .cp { color: #9C6500 } /* Comment.Preproc */
.output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.output_html .gd { color: #A00000 } /* Generic.Deleted */
.output_html .ge { font-style: italic } /* Generic.Emph */
.output_html .gr { color: #E40000 } /* Generic.Error */
.output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.output_html .gi { color: #008400 } /* Generic.Inserted */
.output_html .go { color: #717171 } /* Generic.Output */
.output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.output_html .gs { font-weight: bold } /* Generic.Strong */
.output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.output_html .gt { color: #0044DD } /* Generic.Traceback */
.output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.output_html .kp { color: #008000 } /* Keyword.Pseudo */
.output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.output_html .kt { color: #B00040 } /* Keyword.Type */
.output_html .m { color: #666666 } /* Literal.Number */
.output_html .s { color: #BA2121 } /* Literal.String */
.output_html .na { color: #687822 } /* Name.Attribute */
.output_html .nb { color: #008000 } /* Name.Builtin */
.output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.output_html .no { color: #880000 } /* Name.Constant */
.output_html .nd { color: #AA22FF } /* Name.Decorator */
.output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */
.output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.output_html .nf { color: #0000FF } /* Name.Function */
.output_html .nl { color: #767600 } /* Name.Label */
.output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */
.output_html .nv { color: #19177C } /* Name.Variable */
.output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.output_html .w { color: #bbbbbb } /* Text.Whitespace */
.output_html .mb { color: #666666 } /* Literal.Number.Bin */
.output_html .mf { color: #666666 } /* Literal.Number.Float */
.output_html .mh { color: #666666 } /* Literal.Number.Hex */
.output_html .mi { color: #666666 } /* Literal.Number.Integer */
.output_html .mo { color: #666666 } /* Literal.Number.Oct */
.output_html .sa { color: #BA2121 } /* Literal.String.Affix */
.output_html .sb { color: #BA2121 } /* Literal.String.Backtick */
.output_html .sc { color: #BA2121 } /* Literal.String.Char */
.output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */
.output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.output_html .s2 { color: #BA2121 } /* Literal.String.Double */
.output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */
.output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.output_html .sx { color: #008000 } /* Literal.String.Other */
.output_html .sr { color: #A45A77 } /* Literal.String.Regex */
.output_html .s1 { color: #BA2121 } /* Literal.String.Single */
.output_html .ss { color: #19177C } /* Literal.String.Symbol */
.output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */
.output_html .fm { color: #0000FF } /* Name.Function.Magic */
.output_html .vc { color: #19177C } /* Name.Variable.Class */
.output_html .vg { color: #19177C } /* Name.Variable.Global */
.output_html .vi { color: #19177C } /* Name.Variable.Instance */
.output_html .vm { color: #19177C } /* Name.Variable.Magic */
.output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">omegaconf.dictconfig</span> <span class="kn">import</span> <span class="n">DictConfig</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="kn">from</span> <span class="nn">nemo.core.neural_types</span> <span class="kn">import</span> <span class="n">NeuralType</span>
<span class="kn">from</span> <span class="nn">nemo.collections.nlp.models.language_modeling.megatron_bert_model</span> <span class="kn">import</span> <span class="n">MegatronBertModel</span>
<span class="kn">from</span> <span class="nn">nemo.collections.nlp.modules.common.megatron.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">average_losses_across_data_parallel_group</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">nemo.utils</span> <span class="kn">import</span> <span class="n">logging</span>

<span class="kn">from</span> <span class="nn">bionemo.model.protein.esm1nv.esm1nv_model</span> <span class="kn">import</span> <span class="n">ESM1nvModel</span>
<span class="kn">from</span> <span class="nn">bionemo.data.molecule</span> <span class="kn">import</span> <span class="n">megamolbart_build_train_valid_test_datasets</span>
<span class="kn">from</span> <span class="nn">bionemo.data.dataloader.custom_protein_collate</span> <span class="kn">import</span> <span class="n">CustomProteinBertCollate</span>
<span class="kn">from</span> <span class="nn">nemo.collections.nlp.modules.common.tokenizer_utils</span> <span class="kn">import</span> <span class="n">get_nmt_tokenizer</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">apex.transformer</span> <span class="kn">import</span> <span class="n">tensor_parallel</span>


    <span class="n">HAVE_APEX</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="p">(</span><span class="ne">ImportError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">):</span>
    <span class="n">HAVE_APEX</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;CustomESM1nvModel&quot;</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">CustomESM1nvModel</span><span class="p">(</span><span class="n">ESM1nvModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; CustomESM1nv model that extends the dataloader function to use our custom collate function.</span>
<span class="sd">    Checkout the base class for more information on how it all fits together.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">trainer</span><span class="p">:</span> <span class="n">Trainer</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_pretraining_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">consumed_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Buld dataloader given an input dataset.&quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader_type</span> <span class="o">==</span> <span class="s1">&#39;single&#39;</span><span class="p">,</span> <span class="ne">AssertionError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;Only the Megatron sequential (&quot;single&quot;) sampler is currently supported. </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader_type</span><span class="si">}</span><span class="s1"> was chosen.&#39;</span>
            <span class="p">)</span>

        <span class="n">dataloader</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build_pretraining_data_loader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">consumed_samples</span><span class="o">=</span><span class="n">consumed_samples</span><span class="p">)</span>

        <span class="c1"># Add collate function and unpin memory to avoid crash with CUDA misaligned address</span>
        <span class="n">dataloader</span><span class="o">.</span><span class="n">pin_memory</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># must be False with CSV dataset TODO check with binary</span>
        <span class="n">pad_size_divisible_by_8</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">masked_softmax_fusion</span> <span class="k">else</span> <span class="kc">False</span>

        <span class="n">dataloader</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">CustomProteinBertCollate</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                                                    <span class="n">seq_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">seq_length</span><span class="p">,</span>
                                                    <span class="n">pad_size_divisible_by_8</span><span class="o">=</span><span class="n">pad_size_divisible_by_8</span><span class="p">,</span>
                                                    <span class="n">modify_percent</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">modify_percent</span><span class="p">,</span>
                                                    <span class="n">perturb_percent</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">perturb_percent</span><span class="p">,</span>
                                                    <span class="p">)</span><span class="o">.</span><span class="n">collate_fn</span>

        <span class="k">return</span> <span class="n">dataloader</span>
</pre></div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">std_out</span> <span class="o">=</span> <span class="o">!</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span><span class="o">{</span>BIONEMO_WORKSPACE<span class="o">}</span>/examples/protein/esm1nv<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>python<span class="w"> </span>pretrain_oas.py<span class="w"> </span>++trainer.max_steps<span class="o">=</span><span class="m">101</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">std_out</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[NeMo W 2023-08-25 18:46:43 experimental:27] Module &lt;class &#39;nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel&#39;&gt; is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2023-08-25 18:46:44 experimental:27] Module &lt;class &#39;nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures&#39;&gt; is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2023-08-25 18:46:44 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In &#39;pretrain_oas&#39;: Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information
      warnings.warn(msg, UserWarning)
    
[NeMo W 2023-08-25 18:46:44 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
      ret = run_job(
    
[NeMo I 2023-08-25 18:46:44 pretrain_oas:12] 
    
    ************** Experiment configuration ***********
[NeMo I 2023-08-25 18:46:44 pretrain_oas:13] 
    name: esm1nv-oas
    do_training: true
    do_testing: false
    restore_from_path: null
    trainer:
      devices: 1
      num_nodes: 1
      accelerator: gpu
      precision: 16-mixed
      logger: false
      enable_checkpointing: false
      use_distributed_sampler: false
      max_epochs: null
      max_steps: 101
      log_every_n_steps: 10
      val_check_interval: 100
      limit_val_batches: 10
      limit_test_batches: 500
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      benchmark: false
    exp_manager:
      name: ${name}
      exp_dir: /result/nemo_experiments/${.name}/${.wandb_logger_kwargs.name}
      explicit_log_dir: ${.exp_dir}
      create_wandb_logger: false
      create_tensorboard_logger: true
      wandb_logger_kwargs:
        project: ${name}_pretraining
        name: ${name}_pretraining
        group: ${name}
        job_type: Localhost_nodes_${trainer.num_nodes}_gpus_${trainer.devices}
        notes: &#39;date: ${now:%y%m%d-%H%M%S}&#39;
        tags:
        - ${name}
        offline: false
      resume_if_exists: false
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        monitor: val_loss
        save_top_k: 10
        mode: min
        always_save_nemo: false
        filename: megatron_bert--{val_loss:.2f}-{step}-{consumed_samples}
        model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}
    model:
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      seq_length: 512
      max_position_embeddings: ${.seq_length}
      encoder_seq_length: ${.seq_length}
      num_layers: 6
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      bert_binary_head: false
      resume_from_checkpoint: null
      masked_softmax_fusion: true
      tokenizer:
        library: sentencepiece
        type: null
        model: /tokenizers/protein/esm1nv/vocab/protein_sequence_sentencepiece.model
        vocab_file: /tokenizers/vocab/protein_sequence_sentencepiece.vocab
        merge_file: null
      native_amp_init_scale: 4294967296
      native_amp_growth_interval: 1000
      fp32_residual_connection: false
      fp16_lm_cross_entropy: false
      seed: 1234
      use_cpu_initialization: false
      onnx_safe: false
      activations_checkpoint_method: null
      activations_checkpoint_num_layers: 1
      data:
        ngc_registry_target: uniref50_2022_05
        ngc_registry_version: v23.06
        data_prefix: &#39;&#39;
        num_workers: 10
        dataloader_type: single
        reset_position_ids: false
        reset_attention_mask: false
        eod_mask_loss: false
        masked_lm_prob: 0.15
        short_seq_prob: 0.1
        skip_lines: 0
        drop_last: false
        pin_memory: false
        data_impl: csv_mmap
        data_impl_kwargs:
          csv_mmap:
            header_lines: 1
            newline_int: 10
            workers: ${model.data.num_workers}
            sort_dataset_paths: true
            data_sep: &#39;,&#39;
            data_col: 1
        use_upsampling: true
        seed: ${model.seed}
        max_seq_length: ${model.seq_length}
        dataset_path: /data/OASpaired/processed/heavy
        dataset:
          train: x[000..005]
          test: x[000..001]
          val: x[000..001]
        micro_batch_size: ${model.micro_batch_size}
        modify_percent: 0.1
        perturb_percent: 0.5
      optim:
        name: fused_adam
        lr: 0.0002
        weight_decay: 0.01
        betas:
        - 0.9
        - 0.98
        sched:
          name: CosineAnnealing
          warmup_steps: 500
          constant_steps: 50000
          min_lr: 2.0e-05
    do_dataloader: false
    
[NeMo W 2023-08-25 18:46:44 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/plugins/precision/native_amp.py:131: LightningDeprecationWarning: The `NativeMixedPrecisionPlugin` class has been renamed in v1.9.0 and will be removed in v2.0.0. Please use `pytorch_lightning.plugins.MixedPrecisionPlugin` instead.
      rank_zero_deprecation(
    
[NeMo I 2023-08-25 18:46:44 utils:168] Selected Callbacks: [&lt;class &#39;pytorch_lightning.callbacks.model_summary.ModelSummary&#39;&gt;]
Trainer already configured with model summary callbacks: [&lt;class &#39;pytorch_lightning.callbacks.model_summary.ModelSummary&#39;&gt;]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[NeMo E 2023-08-25 18:46:44 exp_manager:646] exp_manager received explicit_log_dir: /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining and at least one of exp_dir: /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining, or version: None. Please note that exp_dir, name, and version will be ignored.
[NeMo W 2023-08-25 18:46:44 exp_manager:651] Exp_manager is logging to /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining, but it already exists.
[NeMo I 2023-08-25 18:46:44 exp_manager:374] Experiments will be logged at /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining
[NeMo I 2023-08-25 18:46:44 exp_manager:797] TensorboardLogger has been set up
[NeMo W 2023-08-25 18:46:44 exp_manager:893] The checkpoint callback was told to monitor a validation value and trainer&#39;s max_steps was set to 101. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.
[NeMo I 2023-08-25 18:46:44 utils:191] Resuming training from checkpoint: None
[NeMo I 2023-08-25 18:46:44 utils:234] 
    
    ************** Trainer configuration ***********
[NeMo I 2023-08-25 18:46:44 utils:235] 
    name: esm1nv-oas
    do_training: true
    do_testing: false
    restore_from_path: null
    trainer:
      devices: 1
      num_nodes: 1
      accelerator: gpu
      precision: 16-mixed
      logger: false
      enable_checkpointing: false
      use_distributed_sampler: false
      max_epochs: null
      max_steps: 101
      log_every_n_steps: 10
      val_check_interval: 100
      limit_val_batches: 10
      limit_test_batches: 500
      accumulate_grad_batches: 1
      gradient_clip_val: 1.0
      benchmark: false
    exp_manager:
      name: ${name}
      exp_dir: /result/nemo_experiments/${.name}/${.wandb_logger_kwargs.name}
      explicit_log_dir: ${.exp_dir}
      create_wandb_logger: false
      create_tensorboard_logger: true
      wandb_logger_kwargs:
        project: ${name}_pretraining
        name: ${name}_pretraining
        group: ${name}
        job_type: Localhost_nodes_${trainer.num_nodes}_gpus_${trainer.devices}
        notes: &#39;date: ${now:%y%m%d-%H%M%S}&#39;
        tags:
        - ${name}
        offline: false
      resume_if_exists: false
      resume_ignore_no_checkpoint: true
      create_checkpoint_callback: true
      checkpoint_callback_params:
        monitor: val_loss
        save_top_k: 10
        mode: min
        always_save_nemo: false
        filename: megatron_bert--{val_loss:.2f}-{step}-{consumed_samples}
        model_parallel_size: ${multiply:${model.tensor_model_parallel_size}, ${model.pipeline_model_parallel_size}}
    model:
      micro_batch_size: 8
      tensor_model_parallel_size: 1
      pipeline_model_parallel_size: 1
      seq_length: 512
      max_position_embeddings: ${.seq_length}
      encoder_seq_length: ${.seq_length}
      num_layers: 6
      hidden_size: 768
      ffn_hidden_size: 3072
      num_attention_heads: 12
      init_method_std: 0.02
      hidden_dropout: 0.1
      kv_channels: null
      apply_query_key_layer_scaling: true
      layernorm_epsilon: 1.0e-05
      make_vocab_size_divisible_by: 128
      pre_process: true
      post_process: true
      bert_binary_head: false
      resume_from_checkpoint: null
      masked_softmax_fusion: true
      tokenizer:
        library: sentencepiece
        type: null
        model: /tokenizers/protein/esm1nv/vocab/protein_sequence_sentencepiece.model
        vocab_file: /tokenizers/vocab/protein_sequence_sentencepiece.vocab
        merge_file: null
      native_amp_init_scale: 4294967296
      native_amp_growth_interval: 1000
      fp32_residual_connection: false
      fp16_lm_cross_entropy: false
      seed: 1234
      use_cpu_initialization: false
      onnx_safe: false
      activations_checkpoint_method: null
      activations_checkpoint_num_layers: 1
      data:
        ngc_registry_target: uniref50_2022_05
        ngc_registry_version: v23.06
        data_prefix: &#39;&#39;
        num_workers: 10
        dataloader_type: single
        reset_position_ids: false
        reset_attention_mask: false
        eod_mask_loss: false
        masked_lm_prob: 0.15
        short_seq_prob: 0.1
        skip_lines: 0
        drop_last: false
        pin_memory: false
        data_impl: csv_mmap
        data_impl_kwargs:
          csv_mmap:
            header_lines: 1
            newline_int: 10
            workers: ${model.data.num_workers}
            sort_dataset_paths: true
            data_sep: &#39;,&#39;
            data_col: 1
        use_upsampling: true
        seed: ${model.seed}
        max_seq_length: ${model.seq_length}
        dataset_path: /data/OASpaired/processed/heavy
        dataset:
          train: x[000..005]
          test: x[000..001]
          val: x[000..001]
        micro_batch_size: ${model.micro_batch_size}
        modify_percent: 0.1
        perturb_percent: 0.5
      optim:
        name: fused_adam
        lr: 0.0002
        weight_decay: 0.01
        betas:
        - 0.9
        - 0.98
        sched:
          name: CosineAnnealing
          warmup_steps: 500
          constant_steps: 50000
          min_lr: 2.0e-05
      global_batch_size: 8
      precision: 16-mixed
    do_dataloader: false
    
[NeMo I 2023-08-25 18:46:44 pretrain_oas:19] ************** Starting Training ***********
[NeMo I 2023-08-25 18:46:44 megatron_init:231] Rank 0 has data parallel group: [0]
[NeMo I 2023-08-25 18:46:44 megatron_init:234] All data parallel group ranks: [[0]]
[NeMo I 2023-08-25 18:46:44 megatron_init:235] Ranks 0 has data parallel rank: 0
[NeMo I 2023-08-25 18:46:44 megatron_init:243] Rank 0 has model parallel group: [0]
[NeMo I 2023-08-25 18:46:44 megatron_init:244] All model parallel group ranks: [[0]]
[NeMo I 2023-08-25 18:46:44 megatron_init:254] Rank 0 has tensor model parallel group: [0]
[NeMo I 2023-08-25 18:46:44 megatron_init:258] All tensor model parallel group ranks: [[0]]
[NeMo I 2023-08-25 18:46:44 megatron_init:259] Rank 0 has tensor model parallel rank: 0
[NeMo I 2023-08-25 18:46:44 megatron_init:273] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2023-08-25 18:46:44 megatron_init:285] Rank 0 has embedding group: [0]
[NeMo I 2023-08-25 18:46:44 megatron_init:291] All pipeline model parallel group ranks: [[0]]
[NeMo I 2023-08-25 18:46:44 megatron_init:292] Rank 0 has pipeline model parallel rank 0
[NeMo I 2023-08-25 18:46:44 megatron_init:293] All embedding group ranks: [[0]]
[NeMo I 2023-08-25 18:46:44 megatron_init:294] Rank 0 has embedding rank: 0
23-08-25 18:46:44 - PID:2297 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 1
[NeMo I 2023-08-25 18:46:44 tokenizer_utils:191] Getting SentencePiece with model: /tokenizers/protein/esm1nv/vocab/protein_sequence_sentencepiece.model
[NeMo I 2023-08-25 18:46:44 megatron_base_model:229] Padded vocab_size: 128, original vocab_size: 30, dummy tokens: 98.
[NeMo W 2023-08-25 18:46:44 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `CustomESM1nvModel.on_train_batch_start` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.
      rank_zero_warn(
    
[NeMo W 2023-08-25 18:46:44 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `CustomESM1nvModel.on_train_batch_end` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.
      rank_zero_warn(
    
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
Added key: store_based_barrier_key:1 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

Added key: store_based_barrier_key:2 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.
Added key: store_based_barrier_key:3 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.
Added key: store_based_barrier_key:4 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.
Added key: store_based_barrier_key:5 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.
Added key: store_based_barrier_key:6 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.
Added key: store_based_barrier_key:7 to store for rank: 0
Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.
[NeMo W 2023-08-25 18:46:45 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining/checkpoints exists and is not empty.
      rank_zero_warn(f&quot;Checkpoint directory {dirpath} exists and is not empty.&quot;)
    
[NeMo I 2023-08-25 18:46:45 megatron_bert_model:563] Pipeline model parallel rank: 0, Tensor model parallel rank: 0, Number of model parameters on device: 4.36e+07. Total number of model parameters: 4.36e+07.
[NeMo I 2023-08-25 18:46:45 esm1nv_model:96] Building Bert datasets.
train:808
Loading data from /data/OASpaired/processed/heavy/train/x000.csv, /data/OASpaired/processed/heavy/train/x001.csv, /data/OASpaired/processed/heavy/train/x002.csv, /data/OASpaired/processed/heavy/train/x003.csv, /data/OASpaired/processed/heavy/train/x004.csv, /data/OASpaired/processed/heavy/train/x005.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:104] Building data files
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:343] Processing 6 data files using 10 workers
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:349] Time building 0 / 6 mem-mapped files: 0:00:00.235856
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:114] Loading data files
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x000.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x001.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x002.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x003.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x004.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x005.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:117] Time loading 6 mem-mapped files: 0:00:00.002752
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:121] Computing global indices
[NeMo I 2023-08-25 18:46:45 dataset_utils:1341]  &gt; loading indexed mapping from /data/OASpaired/processed/heavy/train/__indexmap_808mns_512msl_0.00ssp_1234s.npy
[NeMo I 2023-08-25 18:46:45 dataset_utils:1344]     loaded indexed file in 0.001 seconds
[NeMo I 2023-08-25 18:46:45 dataset_utils:1345]     total number of samples: 21129
val:160
Loading data from /data/OASpaired/processed/heavy/val/x000.csv, /data/OASpaired/processed/heavy/val/x001.csv
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:104] Building data files
[NeMo I 2023-08-25 18:46:45 text_memmap_dataset:343] Processing 2 data files using 10 workers
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:349] Time building 0 / 2 mem-mapped files: 0:00:00.231405
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:114] Loading data files
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/val/x000.csv
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/val/x001.csv
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:117] Time loading 2 mem-mapped files: 0:00:00.001060
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:121] Computing global indices
[NeMo I 2023-08-25 18:46:46 dataset_utils:1341]  &gt; loading indexed mapping from /data/OASpaired/processed/heavy/val/__indexmap_160mns_512msl_0.00ssp_1234s.npy
[NeMo I 2023-08-25 18:46:46 dataset_utils:1344]     loaded indexed file in 0.000 seconds
[NeMo I 2023-08-25 18:46:46 dataset_utils:1345]     total number of samples: 294
test:4000
Loading data from /data/OASpaired/processed/heavy/test/x000.csv, /data/OASpaired/processed/heavy/test/x001.csv
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:104] Building data files
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:343] Processing 2 data files using 10 workers
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:349] Time building 0 / 2 mem-mapped files: 0:00:00.246505
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:114] Loading data files
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/test/x000.csv
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/test/x001.csv
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:117] Time loading 2 mem-mapped files: 0:00:00.001123
[NeMo I 2023-08-25 18:46:46 text_memmap_dataset:121] Computing global indices
[NeMo I 2023-08-25 18:46:46 dataset_utils:1341]  &gt; loading indexed mapping from /data/OASpaired/processed/heavy/test/__indexmap_4000mns_512msl_0.00ssp_1234s.npy
[NeMo I 2023-08-25 18:46:46 dataset_utils:1344]     loaded indexed file in 0.000 seconds
[NeMo I 2023-08-25 18:46:46 dataset_utils:1345]     total number of samples: 6499
[NeMo I 2023-08-25 18:46:46 esm1nv_model:114] Length of train dataset: 808
[NeMo I 2023-08-25 18:46:46 esm1nv_model:115] Length of val dataset: 160
[NeMo I 2023-08-25 18:46:46 esm1nv_model:116] Length of test dataset: 4000
[NeMo I 2023-08-25 18:46:46 esm1nv_model:117] Finished building Bert datasets.
[NeMo I 2023-08-25 18:46:46 megatron_bert_model:662] Setting up train dataloader with len(len(self._train_ds)): 808 and consumed samples: 0
[NeMo I 2023-08-25 18:46:46 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 808 and consumed_samples: 0
[NeMo I 2023-08-25 18:46:46 megatron_bert_model:670] Setting up validation dataloader with len(len(self._validation_ds)): 160 and consumed samples: 0
[NeMo I 2023-08-25 18:46:46 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 160 and consumed_samples: 0
[NeMo I 2023-08-25 18:46:46 megatron_bert_model:678] Setting up test dataloader with len(len(self._test_ds)): 4000 and consumed samples: 0
[NeMo I 2023-08-25 18:46:46 data_samplers:76] Instantiating MegatronPretrainingSampler with total_samples: 4000 and consumed_samples: 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[NeMo I 2023-08-25 18:46:46 nlp_overrides:124] Configuring DDP for model parallelism.
[NeMo I 2023-08-25 18:46:46 modelPT:722] Optimizer config = FusedAdam (
    Parameter Group 0
        betas: [0.9, 0.98]
        bias_correction: True
        eps: 1e-08
        lr: 0.0002
        weight_decay: 0.01
    
    Parameter Group 1
        betas: [0.9, 0.98]
        bias_correction: True
        eps: 1e-08
        lr: 0.0002
        weight_decay: 0.0
    )
[NeMo I 2023-08-25 18:46:46 lr_scheduler:910] Scheduler &quot;&lt;nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f39a83d3400&gt;&quot; 
    will be used during training (effective maximum steps = 101) - 
    Parameters : 
    (warmup_steps: 500
    constant_steps: 50000
    min_lr: 2.0e-05
    max_steps: 101
    )

  | Name                           | Type                     | Params
----------------------------------------------------------------------------
0 | model                          | BertModel                | 43.6 M
1 | model.language_model           | TransformerLanguageModel | 43.0 M
2 | model.language_model.embedding | Embedding                | 491 K 
3 | model.language_model.encoder   | ParallelTransformer      | 42.5 M
4 | model.lm_head                  | BertLMHead               | 592 K 
5 | model.lm_head.dense            | Linear                   | 590 K 
6 | model.lm_head.layernorm        | MixedFusedLayerNorm      | 1.5 K 
----------------------------------------------------------------------------
43.6 M    Trainable params
0         Non-trainable params
43.6 M    Total params
87.225    Total estimated model params size (MB)

Sanity Checking: 0it [00:00, ?it/s][NeMo W 2023-08-25 18:46:46 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:401: UserWarning: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.
      rank_zero_warn(
    

Sanity Checking:   0%|          | 0/2 [00:00&lt;?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00&lt;?, ?it/s]
Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01&lt;00:01,  1.56s/it]
Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:01&lt;00:00,  1.26it/s][NeMo W 2023-08-25 18:46:48 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log(&#39;consumed_samples&#39;, ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.
      warning_cache.warn(
    
[NeMo W 2023-08-25 18:46:48 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log(&#39;val_loss&#39;, ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
      warning_cache.warn(
    
[NeMo W 2023-08-25 18:46:48 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log(&#39;val_loss_ECE&#39;, ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
      warning_cache.warn(
    
[NeMo W 2023-08-25 18:46:48 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log(&#39;consumed_samples&#39;, ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
      warning_cache.warn(
    

                                                                           [NeMo W 2023-08-25 18:46:48 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/loops/fit_loop.py:344: UserWarning: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.
      rank_zero_warn(
    


Training: 0it [00:00, ?it/s]
Training:   0%|          | 0/111 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/111 [00:00&lt;?, ?it/s] [NeMo W 2023-08-25 18:46:50 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log(&#39;global_step&#39;, ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
      warning_cache.warn(
    
[NeMo W 2023-08-25 18:46:50 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log(&#39;consumed_samples&#39;, ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
      warning_cache.warn(
    
[NeMo W 2023-08-25 18:46:50 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      warnings.warn(&quot;Detected call of `lr_scheduler.step()` before `optimizer.step()`. &quot;
    

Epoch 0:   1%|          | 1/111 [00:01&lt;03:36,  1.97s/it]
Epoch 0:   1%|          | 1/111 [00:01&lt;03:36,  1.97s/it, loss=4.82, v_num=, reduced_train_loss=4.820, global_step=0.000, consumed_samples=0.000]
Epoch 0:   2%|▏         | 2/111 [00:02&lt;01:49,  1.01s/it, loss=4.82, v_num=, reduced_train_loss=4.820, global_step=0.000, consumed_samples=0.000]
Epoch 0:   2%|▏         | 2/111 [00:02&lt;01:49,  1.01s/it, loss=4.83, v_num=, reduced_train_loss=4.840, global_step=1.000, consumed_samples=8.000]
Epoch 0:   3%|▎         | 3/111 [00:02&lt;01:15,  1.42it/s, loss=4.83, v_num=, reduced_train_loss=4.840, global_step=1.000, consumed_samples=8.000]
Epoch 0:   3%|▎         | 3/111 [00:02&lt;01:15,  1.42it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=2.000, consumed_samples=16.00]
Epoch 0:   4%|▎         | 4/111 [00:02&lt;00:57,  1.86it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=2.000, consumed_samples=16.00]
Epoch 0:   4%|▎         | 4/111 [00:02&lt;00:57,  1.86it/s, loss=4.84, v_num=, reduced_train_loss=4.860, global_step=3.000, consumed_samples=24.00]
Epoch 0:   5%|▍         | 5/111 [00:02&lt;00:46,  2.28it/s, loss=4.84, v_num=, reduced_train_loss=4.860, global_step=3.000, consumed_samples=24.00]
Epoch 0:   5%|▍         | 5/111 [00:02&lt;00:46,  2.28it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=4.000, consumed_samples=32.00]
Epoch 0:   5%|▌         | 6/111 [00:02&lt;00:39,  2.68it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=4.000, consumed_samples=32.00]
Epoch 0:   5%|▌         | 6/111 [00:02&lt;00:39,  2.68it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=5.000, consumed_samples=40.00]
Epoch 0:   6%|▋         | 7/111 [00:02&lt;00:33,  3.06it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=5.000, consumed_samples=40.00]
Epoch 0:   6%|▋         | 7/111 [00:02&lt;00:33,  3.06it/s, loss=4.84, v_num=, reduced_train_loss=4.810, global_step=6.000, consumed_samples=48.00]
Epoch 0:   7%|▋         | 8/111 [00:02&lt;00:29,  3.44it/s, loss=4.84, v_num=, reduced_train_loss=4.810, global_step=6.000, consumed_samples=48.00]
Epoch 0:   7%|▋         | 8/111 [00:02&lt;00:29,  3.44it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=7.000, consumed_samples=56.00]
Epoch 0:   8%|▊         | 9/111 [00:02&lt;00:26,  3.80it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=7.000, consumed_samples=56.00]
Epoch 0:   8%|▊         | 9/111 [00:02&lt;00:26,  3.80it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=8.000, consumed_samples=64.00]
Epoch 0:   9%|▉         | 10/111 [00:02&lt;00:24,  4.14it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=8.000, consumed_samples=64.00]
Epoch 0:   9%|▉         | 10/111 [00:02&lt;00:24,  4.14it/s, loss=4.84, v_num=, reduced_train_loss=4.850, global_step=9.000, consumed_samples=72.00]
Epoch 0:  10%|▉         | 11/111 [00:02&lt;00:22,  4.46it/s, loss=4.84, v_num=, reduced_train_loss=4.850, global_step=9.000, consumed_samples=72.00]
Epoch 0:  10%|▉         | 11/111 [00:02&lt;00:22,  4.46it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=10.00, consumed_samples=80.00]
Epoch 0:  11%|█         | 12/111 [00:02&lt;00:20,  4.78it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=10.00, consumed_samples=80.00]
Epoch 0:  11%|█         | 12/111 [00:02&lt;00:20,  4.78it/s, loss=4.84, v_num=, reduced_train_loss=4.850, global_step=11.00, consumed_samples=88.00]
Epoch 0:  12%|█▏        | 13/111 [00:02&lt;00:19,  5.07it/s, loss=4.84, v_num=, reduced_train_loss=4.850, global_step=11.00, consumed_samples=88.00]
Epoch 0:  12%|█▏        | 13/111 [00:02&lt;00:19,  5.07it/s, loss=4.84, v_num=, reduced_train_loss=4.820, global_step=12.00, consumed_samples=96.00]
Epoch 0:  13%|█▎        | 14/111 [00:02&lt;00:18,  5.37it/s, loss=4.84, v_num=, reduced_train_loss=4.820, global_step=12.00, consumed_samples=96.00]
Epoch 0:  13%|█▎        | 14/111 [00:02&lt;00:18,  5.37it/s, loss=4.84, v_num=, reduced_train_loss=4.800, global_step=13.00, consumed_samples=104.0]
Epoch 0:  14%|█▎        | 15/111 [00:02&lt;00:16,  5.66it/s, loss=4.84, v_num=, reduced_train_loss=4.800, global_step=13.00, consumed_samples=104.0]
Epoch 0:  14%|█▎        | 15/111 [00:02&lt;00:16,  5.66it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=14.00, consumed_samples=112.0]
Epoch 0:  14%|█▍        | 16/111 [00:02&lt;00:16,  5.93it/s, loss=4.84, v_num=, reduced_train_loss=4.840, global_step=14.00, consumed_samples=112.0]
Epoch 0:  14%|█▍        | 16/111 [00:02&lt;00:16,  5.93it/s, loss=4.83, v_num=, reduced_train_loss=4.810, global_step=15.00, consumed_samples=120.0]
Epoch 0:  15%|█▌        | 17/111 [00:02&lt;00:15,  6.20it/s, loss=4.83, v_num=, reduced_train_loss=4.810, global_step=15.00, consumed_samples=120.0]
Epoch 0:  15%|█▌        | 17/111 [00:02&lt;00:15,  6.20it/s, loss=4.83, v_num=, reduced_train_loss=4.820, global_step=16.00, consumed_samples=128.0]
Epoch 0:  16%|█▌        | 18/111 [00:02&lt;00:14,  6.46it/s, loss=4.83, v_num=, reduced_train_loss=4.820, global_step=16.00, consumed_samples=128.0]
Epoch 0:  16%|█▌        | 18/111 [00:02&lt;00:14,  6.46it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=17.00, consumed_samples=136.0]
Epoch 0:  17%|█▋        | 19/111 [00:02&lt;00:13,  6.71it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=17.00, consumed_samples=136.0]
Epoch 0:  17%|█▋        | 19/111 [00:02&lt;00:13,  6.71it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=18.00, consumed_samples=144.0]
Epoch 0:  18%|█▊        | 20/111 [00:02&lt;00:13,  6.96it/s, loss=4.83, v_num=, reduced_train_loss=4.830, global_step=18.00, consumed_samples=144.0]
Epoch 0:  18%|█▊        | 20/111 [00:02&lt;00:13,  6.96it/s, loss=4.83, v_num=, reduced_train_loss=4.820, global_step=19.00, consumed_samples=152.0]
Epoch 0:  19%|█▉        | 21/111 [00:02&lt;00:12,  7.19it/s, loss=4.83, v_num=, reduced_train_loss=4.820, global_step=19.00, consumed_samples=152.0]
Epoch 0:  19%|█▉        | 21/111 [00:02&lt;00:12,  7.18it/s, loss=4.83, v_num=, reduced_train_loss=4.850, global_step=20.00, consumed_samples=160.0]
Epoch 0:  20%|█▉        | 22/111 [00:02&lt;00:12,  7.41it/s, loss=4.83, v_num=, reduced_train_loss=4.850, global_step=20.00, consumed_samples=160.0]
Epoch 0:  20%|█▉        | 22/111 [00:02&lt;00:12,  7.41it/s, loss=4.83, v_num=, reduced_train_loss=4.860, global_step=21.00, consumed_samples=168.0]
Epoch 0:  21%|██        | 23/111 [00:03&lt;00:11,  7.63it/s, loss=4.83, v_num=, reduced_train_loss=4.860, global_step=21.00, consumed_samples=168.0]
Epoch 0:  21%|██        | 23/111 [00:03&lt;00:11,  7.63it/s, loss=4.83, v_num=, reduced_train_loss=4.650, global_step=22.00, consumed_samples=176.0]
Epoch 0:  22%|██▏       | 24/111 [00:03&lt;00:11,  7.83it/s, loss=4.83, v_num=, reduced_train_loss=4.650, global_step=22.00, consumed_samples=176.0]
Epoch 0:  22%|██▏       | 24/111 [00:03&lt;00:11,  7.83it/s, loss=4.8, v_num=, reduced_train_loss=4.350, global_step=23.00, consumed_samples=184.0] 
Epoch 0:  23%|██▎       | 25/111 [00:03&lt;00:10,  8.02it/s, loss=4.8, v_num=, reduced_train_loss=4.350, global_step=23.00, consumed_samples=184.0]
Epoch 0:  23%|██▎       | 25/111 [00:03&lt;00:10,  8.02it/s, loss=4.75, v_num=, reduced_train_loss=3.900, global_step=24.00, consumed_samples=192.0]
Epoch 0:  23%|██▎       | 26/111 [00:03&lt;00:10,  8.21it/s, loss=4.75, v_num=, reduced_train_loss=3.900, global_step=24.00, consumed_samples=192.0]
Epoch 0:  23%|██▎       | 26/111 [00:03&lt;00:10,  8.21it/s, loss=4.68, v_num=, reduced_train_loss=3.310, global_step=25.00, consumed_samples=200.0]
Epoch 0:  24%|██▍       | 27/111 [00:03&lt;00:10,  8.39it/s, loss=4.68, v_num=, reduced_train_loss=3.310, global_step=25.00, consumed_samples=200.0]
Epoch 0:  24%|██▍       | 27/111 [00:03&lt;00:10,  8.39it/s, loss=4.57, v_num=, reduced_train_loss=2.680, global_step=26.00, consumed_samples=208.0]
Epoch 0:  25%|██▌       | 28/111 [00:03&lt;00:09,  8.56it/s, loss=4.57, v_num=, reduced_train_loss=2.680, global_step=26.00, consumed_samples=208.0]
Epoch 0:  25%|██▌       | 28/111 [00:03&lt;00:09,  8.56it/s, loss=4.43, v_num=, reduced_train_loss=2.000, global_step=27.00, consumed_samples=216.0]
Epoch 0:  26%|██▌       | 29/111 [00:03&lt;00:09,  8.75it/s, loss=4.43, v_num=, reduced_train_loss=2.000, global_step=27.00, consumed_samples=216.0]
Epoch 0:  26%|██▌       | 29/111 [00:03&lt;00:09,  8.74it/s, loss=4.26, v_num=, reduced_train_loss=1.400, global_step=28.00, consumed_samples=224.0]
Epoch 0:  27%|██▋       | 30/111 [00:03&lt;00:09,  8.92it/s, loss=4.26, v_num=, reduced_train_loss=1.400, global_step=28.00, consumed_samples=224.0]
Epoch 0:  27%|██▋       | 30/111 [00:03&lt;00:09,  8.92it/s, loss=4.06, v_num=, reduced_train_loss=0.983, global_step=29.00, consumed_samples=232.0]
Epoch 0:  28%|██▊       | 31/111 [00:03&lt;00:08,  9.09it/s, loss=4.06, v_num=, reduced_train_loss=0.983, global_step=29.00, consumed_samples=232.0]
Epoch 0:  28%|██▊       | 31/111 [00:03&lt;00:08,  9.09it/s, loss=3.85, v_num=, reduced_train_loss=0.624, global_step=30.00, consumed_samples=240.0]
Epoch 0:  29%|██▉       | 32/111 [00:03&lt;00:08,  9.26it/s, loss=3.85, v_num=, reduced_train_loss=0.624, global_step=30.00, consumed_samples=240.0]
Epoch 0:  29%|██▉       | 32/111 [00:03&lt;00:08,  9.26it/s, loss=3.63, v_num=, reduced_train_loss=0.420, global_step=31.00, consumed_samples=248.0]
Epoch 0:  30%|██▉       | 33/111 [00:03&lt;00:08,  9.43it/s, loss=3.63, v_num=, reduced_train_loss=0.420, global_step=31.00, consumed_samples=248.0]
Epoch 0:  30%|██▉       | 33/111 [00:03&lt;00:08,  9.43it/s, loss=3.4, v_num=, reduced_train_loss=0.256, global_step=32.00, consumed_samples=256.0] 
Epoch 0:  31%|███       | 34/111 [00:03&lt;00:08,  9.57it/s, loss=3.4, v_num=, reduced_train_loss=0.256, global_step=32.00, consumed_samples=256.0]
Epoch 0:  31%|███       | 34/111 [00:03&lt;00:08,  9.57it/s, loss=3.17, v_num=, reduced_train_loss=0.180, global_step=33.00, consumed_samples=264.0]
Epoch 0:  32%|███▏      | 35/111 [00:03&lt;00:07,  9.72it/s, loss=3.17, v_num=, reduced_train_loss=0.180, global_step=33.00, consumed_samples=264.0]
Epoch 0:  32%|███▏      | 35/111 [00:03&lt;00:07,  9.72it/s, loss=2.93, v_num=, reduced_train_loss=0.121, global_step=34.00, consumed_samples=272.0]
Epoch 0:  32%|███▏      | 36/111 [00:03&lt;00:07,  9.86it/s, loss=2.93, v_num=, reduced_train_loss=0.121, global_step=34.00, consumed_samples=272.0]
Epoch 0:  32%|███▏      | 36/111 [00:03&lt;00:07,  9.86it/s, loss=2.7, v_num=, reduced_train_loss=0.0845, global_step=35.00, consumed_samples=280.0]
Epoch 0:  33%|███▎      | 37/111 [00:03&lt;00:07,  9.99it/s, loss=2.7, v_num=, reduced_train_loss=0.0845, global_step=35.00, consumed_samples=280.0]
Epoch 0:  33%|███▎      | 37/111 [00:03&lt;00:07,  9.99it/s, loss=2.46, v_num=, reduced_train_loss=0.081, global_step=36.00, consumed_samples=288.0]
Epoch 0:  34%|███▍      | 38/111 [00:03&lt;00:07, 10.14it/s, loss=2.46, v_num=, reduced_train_loss=0.081, global_step=36.00, consumed_samples=288.0]
Epoch 0:  34%|███▍      | 38/111 [00:03&lt;00:07, 10.14it/s, loss=2.22, v_num=, reduced_train_loss=0.0499, global_step=37.00, consumed_samples=296.0]
Epoch 0:  35%|███▌      | 39/111 [00:03&lt;00:06, 10.29it/s, loss=2.22, v_num=, reduced_train_loss=0.0499, global_step=37.00, consumed_samples=296.0]
Epoch 0:  35%|███▌      | 39/111 [00:03&lt;00:06, 10.29it/s, loss=1.98, v_num=, reduced_train_loss=0.042, global_step=38.00, consumed_samples=304.0] 
Epoch 0:  36%|███▌      | 40/111 [00:03&lt;00:06, 10.42it/s, loss=1.98, v_num=, reduced_train_loss=0.042, global_step=38.00, consumed_samples=304.0]
Epoch 0:  36%|███▌      | 40/111 [00:03&lt;00:06, 10.42it/s, loss=1.74, v_num=, reduced_train_loss=0.0138, global_step=39.00, consumed_samples=312.0]
Epoch 0:  37%|███▋      | 41/111 [00:03&lt;00:06, 10.54it/s, loss=1.74, v_num=, reduced_train_loss=0.0138, global_step=39.00, consumed_samples=312.0]
Epoch 0:  37%|███▋      | 41/111 [00:03&lt;00:06, 10.54it/s, loss=1.5, v_num=, reduced_train_loss=0.0586, global_step=40.00, consumed_samples=320.0] 
Epoch 0:  38%|███▊      | 42/111 [00:03&lt;00:06, 10.67it/s, loss=1.5, v_num=, reduced_train_loss=0.0586, global_step=40.00, consumed_samples=320.0]
Epoch 0:  38%|███▊      | 42/111 [00:03&lt;00:06, 10.67it/s, loss=1.26, v_num=, reduced_train_loss=0.00855, global_step=41.00, consumed_samples=328.0]
Epoch 0:  39%|███▊      | 43/111 [00:03&lt;00:06, 10.79it/s, loss=1.26, v_num=, reduced_train_loss=0.00855, global_step=41.00, consumed_samples=328.0]
Epoch 0:  39%|███▊      | 43/111 [00:03&lt;00:06, 10.79it/s, loss=1.03, v_num=, reduced_train_loss=0.0298, global_step=42.00, consumed_samples=336.0] 
Epoch 0:  40%|███▉      | 44/111 [00:04&lt;00:06, 10.91it/s, loss=1.03, v_num=, reduced_train_loss=0.0298, global_step=42.00, consumed_samples=336.0]
Epoch 0:  40%|███▉      | 44/111 [00:04&lt;00:06, 10.91it/s, loss=0.813, v_num=, reduced_train_loss=0.0272, global_step=43.00, consumed_samples=344.0]
Epoch 0:  41%|████      | 45/111 [00:04&lt;00:05, 11.04it/s, loss=0.813, v_num=, reduced_train_loss=0.0272, global_step=43.00, consumed_samples=344.0]
Epoch 0:  41%|████      | 45/111 [00:04&lt;00:05, 11.03it/s, loss=0.619, v_num=, reduced_train_loss=0.00627, global_step=44.00, consumed_samples=352.0]
Epoch 0:  41%|████▏     | 46/111 [00:04&lt;00:05, 11.15it/s, loss=0.619, v_num=, reduced_train_loss=0.00627, global_step=44.00, consumed_samples=352.0]
Epoch 0:  41%|████▏     | 46/111 [00:04&lt;00:05, 11.15it/s, loss=0.454, v_num=, reduced_train_loss=0.0058, global_step=45.00, consumed_samples=360.0] 
Epoch 0:  42%|████▏     | 47/111 [00:04&lt;00:05, 11.26it/s, loss=0.454, v_num=, reduced_train_loss=0.0058, global_step=45.00, consumed_samples=360.0]
Epoch 0:  42%|████▏     | 47/111 [00:04&lt;00:05, 11.26it/s, loss=0.322, v_num=, reduced_train_loss=0.0466, global_step=46.00, consumed_samples=368.0]
Epoch 0:  43%|████▎     | 48/111 [00:04&lt;00:05, 11.38it/s, loss=0.322, v_num=, reduced_train_loss=0.0466, global_step=46.00, consumed_samples=368.0]
Epoch 0:  43%|████▎     | 48/111 [00:04&lt;00:05, 11.38it/s, loss=0.222, v_num=, reduced_train_loss=0.00506, global_step=47.00, consumed_samples=376.0]
Epoch 0:  44%|████▍     | 49/111 [00:04&lt;00:05, 11.49it/s, loss=0.222, v_num=, reduced_train_loss=0.00506, global_step=47.00, consumed_samples=376.0]
Epoch 0:  44%|████▍     | 49/111 [00:04&lt;00:05, 11.49it/s, loss=0.152, v_num=, reduced_train_loss=0.00475, global_step=48.00, consumed_samples=384.0]
Epoch 0:  45%|████▌     | 50/111 [00:04&lt;00:05, 11.57it/s, loss=0.152, v_num=, reduced_train_loss=0.00475, global_step=48.00, consumed_samples=384.0]
Epoch 0:  45%|████▌     | 50/111 [00:04&lt;00:05, 11.57it/s, loss=0.104, v_num=, reduced_train_loss=0.00427, global_step=49.00, consumed_samples=392.0]
Epoch 0:  46%|████▌     | 51/111 [00:04&lt;00:05, 11.65it/s, loss=0.104, v_num=, reduced_train_loss=0.00427, global_step=49.00, consumed_samples=392.0]
Epoch 0:  46%|████▌     | 51/111 [00:04&lt;00:05, 11.65it/s, loss=0.0735, v_num=, reduced_train_loss=0.0238, global_step=50.00, consumed_samples=400.0]
Epoch 0:  47%|████▋     | 52/111 [00:04&lt;00:05, 11.72it/s, loss=0.0735, v_num=, reduced_train_loss=0.0238, global_step=50.00, consumed_samples=400.0]
Epoch 0:  47%|████▋     | 52/111 [00:04&lt;00:05, 11.72it/s, loss=0.0536, v_num=, reduced_train_loss=0.0226, global_step=51.00, consumed_samples=408.0]
Epoch 0:  48%|████▊     | 53/111 [00:04&lt;00:04, 11.82it/s, loss=0.0536, v_num=, reduced_train_loss=0.0226, global_step=51.00, consumed_samples=408.0]
Epoch 0:  48%|████▊     | 53/111 [00:04&lt;00:04, 11.82it/s, loss=0.0419, v_num=, reduced_train_loss=0.0215, global_step=52.00, consumed_samples=416.0]
Epoch 0:  49%|████▊     | 54/111 [00:04&lt;00:04, 11.93it/s, loss=0.0419, v_num=, reduced_train_loss=0.0215, global_step=52.00, consumed_samples=416.0]
Epoch 0:  49%|████▊     | 54/111 [00:04&lt;00:04, 11.93it/s, loss=0.0339, v_num=, reduced_train_loss=0.022, global_step=53.00, consumed_samples=424.0] 
Epoch 0:  50%|████▉     | 55/111 [00:04&lt;00:04, 12.04it/s, loss=0.0339, v_num=, reduced_train_loss=0.022, global_step=53.00, consumed_samples=424.0]
Epoch 0:  50%|████▉     | 55/111 [00:04&lt;00:04, 12.04it/s, loss=0.0304, v_num=, reduced_train_loss=0.0491, global_step=54.00, consumed_samples=432.0]
Epoch 0:  50%|█████     | 56/111 [00:04&lt;00:04, 12.07it/s, loss=0.0304, v_num=, reduced_train_loss=0.0491, global_step=54.00, consumed_samples=432.0]
Epoch 0:  50%|█████     | 56/111 [00:04&lt;00:04, 12.07it/s, loss=0.0263, v_num=, reduced_train_loss=0.00395, global_step=55.00, consumed_samples=440.0]
Epoch 0:  51%|█████▏    | 57/111 [00:04&lt;00:04, 12.16it/s, loss=0.0263, v_num=, reduced_train_loss=0.00395, global_step=55.00, consumed_samples=440.0]
Epoch 0:  51%|█████▏    | 57/111 [00:04&lt;00:04, 12.16it/s, loss=0.0225, v_num=, reduced_train_loss=0.00413, global_step=56.00, consumed_samples=448.0]
Epoch 0:  52%|█████▏    | 58/111 [00:04&lt;00:04, 12.25it/s, loss=0.0225, v_num=, reduced_train_loss=0.00413, global_step=56.00, consumed_samples=448.0]
Epoch 0:  52%|█████▏    | 58/111 [00:04&lt;00:04, 12.25it/s, loss=0.0217, v_num=, reduced_train_loss=0.0349, global_step=57.00, consumed_samples=456.0] 
Epoch 0:  53%|█████▎    | 59/111 [00:04&lt;00:04, 12.32it/s, loss=0.0217, v_num=, reduced_train_loss=0.0349, global_step=57.00, consumed_samples=456.0]
Epoch 0:  53%|█████▎    | 59/111 [00:04&lt;00:04, 12.32it/s, loss=0.0214, v_num=, reduced_train_loss=0.0356, global_step=58.00, consumed_samples=464.0]
Epoch 0:  54%|█████▍    | 60/111 [00:04&lt;00:04, 12.40it/s, loss=0.0214, v_num=, reduced_train_loss=0.0356, global_step=58.00, consumed_samples=464.0]
Epoch 0:  54%|█████▍    | 60/111 [00:04&lt;00:04, 12.40it/s, loss=0.0217, v_num=, reduced_train_loss=0.0194, global_step=59.00, consumed_samples=472.0]
Epoch 0:  55%|█████▍    | 61/111 [00:04&lt;00:04, 12.46it/s, loss=0.0217, v_num=, reduced_train_loss=0.0194, global_step=59.00, consumed_samples=472.0]
Epoch 0:  55%|█████▍    | 61/111 [00:04&lt;00:04, 12.46it/s, loss=0.0198, v_num=, reduced_train_loss=0.0199, global_step=60.00, consumed_samples=480.0]
Epoch 0:  56%|█████▌    | 62/111 [00:04&lt;00:03, 12.52it/s, loss=0.0198, v_num=, reduced_train_loss=0.0199, global_step=60.00, consumed_samples=480.0]
Epoch 0:  56%|█████▌    | 62/111 [00:04&lt;00:03, 12.52it/s, loss=0.0203, v_num=, reduced_train_loss=0.0202, global_step=61.00, consumed_samples=488.0]
Epoch 0:  57%|█████▋    | 63/111 [00:05&lt;00:03, 12.56it/s, loss=0.0203, v_num=, reduced_train_loss=0.0202, global_step=61.00, consumed_samples=488.0]
Epoch 0:  57%|█████▋    | 63/111 [00:05&lt;00:03, 12.56it/s, loss=0.0204, v_num=, reduced_train_loss=0.0319, global_step=62.00, consumed_samples=496.0]
Epoch 0:  58%|█████▊    | 64/111 [00:05&lt;00:03, 12.64it/s, loss=0.0204, v_num=, reduced_train_loss=0.0319, global_step=62.00, consumed_samples=496.0]
Epoch 0:  58%|█████▊    | 64/111 [00:05&lt;00:03, 12.64it/s, loss=0.0194, v_num=, reduced_train_loss=0.00546, global_step=63.00, consumed_samples=504.0]
Epoch 0:  59%|█████▊    | 65/111 [00:05&lt;00:03, 12.72it/s, loss=0.0194, v_num=, reduced_train_loss=0.00546, global_step=63.00, consumed_samples=504.0]
Epoch 0:  59%|█████▊    | 65/111 [00:05&lt;00:03, 12.72it/s, loss=0.0199, v_num=, reduced_train_loss=0.0178, global_step=64.00, consumed_samples=512.0] 
Epoch 0:  59%|█████▉    | 66/111 [00:05&lt;00:03, 12.77it/s, loss=0.0199, v_num=, reduced_train_loss=0.0178, global_step=64.00, consumed_samples=512.0]
Epoch 0:  59%|█████▉    | 66/111 [00:05&lt;00:03, 12.76it/s, loss=0.0205, v_num=, reduced_train_loss=0.018, global_step=65.00, consumed_samples=520.0] 
Epoch 0:  60%|██████    | 67/111 [00:05&lt;00:03, 12.85it/s, loss=0.0205, v_num=, reduced_train_loss=0.018, global_step=65.00, consumed_samples=520.0]
Epoch 0:  60%|██████    | 67/111 [00:05&lt;00:03, 12.85it/s, loss=0.0183, v_num=, reduced_train_loss=0.00246, global_step=66.00, consumed_samples=528.0]
Epoch 0:  61%|██████▏   | 68/111 [00:05&lt;00:03, 12.94it/s, loss=0.0183, v_num=, reduced_train_loss=0.00246, global_step=66.00, consumed_samples=528.0]
Epoch 0:  61%|██████▏   | 68/111 [00:05&lt;00:03, 12.94it/s, loss=0.0195, v_num=, reduced_train_loss=0.0292, global_step=67.00, consumed_samples=536.0] 
Epoch 0:  62%|██████▏   | 69/111 [00:05&lt;00:03, 13.02it/s, loss=0.0195, v_num=, reduced_train_loss=0.0292, global_step=67.00, consumed_samples=536.0]
Epoch 0:  62%|██████▏   | 69/111 [00:05&lt;00:03, 13.01it/s, loss=0.0211, v_num=, reduced_train_loss=0.0361, global_step=68.00, consumed_samples=544.0]
Epoch 0:  63%|██████▎   | 70/111 [00:05&lt;00:03, 13.08it/s, loss=0.0211, v_num=, reduced_train_loss=0.0361, global_step=68.00, consumed_samples=544.0]
Epoch 0:  63%|██████▎   | 70/111 [00:05&lt;00:03, 13.08it/s, loss=0.0218, v_num=, reduced_train_loss=0.0176, global_step=69.00, consumed_samples=552.0]
Epoch 0:  64%|██████▍   | 71/111 [00:05&lt;00:03, 13.15it/s, loss=0.0218, v_num=, reduced_train_loss=0.0176, global_step=69.00, consumed_samples=552.0]
Epoch 0:  64%|██████▍   | 71/111 [00:05&lt;00:03, 13.15it/s, loss=0.0207, v_num=, reduced_train_loss=0.00187, global_step=70.00, consumed_samples=560.0]
Epoch 0:  65%|██████▍   | 72/111 [00:05&lt;00:02, 13.21it/s, loss=0.0207, v_num=, reduced_train_loss=0.00187, global_step=70.00, consumed_samples=560.0]
Epoch 0:  65%|██████▍   | 72/111 [00:05&lt;00:02, 13.21it/s, loss=0.0212, v_num=, reduced_train_loss=0.0326, global_step=71.00, consumed_samples=568.0] 
Epoch 0:  66%|██████▌   | 73/111 [00:05&lt;00:02, 13.29it/s, loss=0.0212, v_num=, reduced_train_loss=0.0326, global_step=71.00, consumed_samples=568.0]
Epoch 0:  66%|██████▌   | 73/111 [00:05&lt;00:02, 13.29it/s, loss=0.0209, v_num=, reduced_train_loss=0.0162, global_step=72.00, consumed_samples=576.0]
Epoch 0:  67%|██████▋   | 74/111 [00:05&lt;00:02, 13.36it/s, loss=0.0209, v_num=, reduced_train_loss=0.0162, global_step=72.00, consumed_samples=576.0]
Epoch 0:  67%|██████▋   | 74/111 [00:05&lt;00:02, 13.35it/s, loss=0.0206, v_num=, reduced_train_loss=0.0163, global_step=73.00, consumed_samples=584.0]
Epoch 0:  68%|██████▊   | 75/111 [00:05&lt;00:02, 13.42it/s, loss=0.0206, v_num=, reduced_train_loss=0.0163, global_step=73.00, consumed_samples=584.0]
Epoch 0:  68%|██████▊   | 75/111 [00:05&lt;00:02, 13.42it/s, loss=0.019, v_num=, reduced_train_loss=0.0169, global_step=74.00, consumed_samples=592.0] 
Epoch 0:  68%|██████▊   | 76/111 [00:05&lt;00:02, 13.49it/s, loss=0.019, v_num=, reduced_train_loss=0.0169, global_step=74.00, consumed_samples=592.0]
Epoch 0:  68%|██████▊   | 76/111 [00:05&lt;00:02, 13.48it/s, loss=0.0192, v_num=, reduced_train_loss=0.00711, global_step=75.00, consumed_samples=600.0]
Epoch 0:  69%|██████▉   | 77/111 [00:05&lt;00:02, 13.52it/s, loss=0.0192, v_num=, reduced_train_loss=0.00711, global_step=75.00, consumed_samples=600.0]
Epoch 0:  69%|██████▉   | 77/111 [00:05&lt;00:02, 13.51it/s, loss=0.0197, v_num=, reduced_train_loss=0.015, global_step=76.00, consumed_samples=608.0]  
Epoch 0:  70%|███████   | 78/111 [00:05&lt;00:02, 13.58it/s, loss=0.0197, v_num=, reduced_train_loss=0.015, global_step=76.00, consumed_samples=608.0]
Epoch 0:  70%|███████   | 78/111 [00:05&lt;00:02, 13.58it/s, loss=0.0187, v_num=, reduced_train_loss=0.0147, global_step=77.00, consumed_samples=616.0]
Epoch 0:  71%|███████   | 79/111 [00:05&lt;00:02, 13.65it/s, loss=0.0187, v_num=, reduced_train_loss=0.0147, global_step=77.00, consumed_samples=616.0]
Epoch 0:  71%|███████   | 79/111 [00:05&lt;00:02, 13.65it/s, loss=0.017, v_num=, reduced_train_loss=0.00149, global_step=78.00, consumed_samples=624.0]
Epoch 0:  72%|███████▏  | 80/111 [00:05&lt;00:02, 13.71it/s, loss=0.017, v_num=, reduced_train_loss=0.00149, global_step=78.00, consumed_samples=624.0]
Epoch 0:  72%|███████▏  | 80/111 [00:05&lt;00:02, 13.71it/s, loss=0.0169, v_num=, reduced_train_loss=0.0169, global_step=79.00, consumed_samples=632.0]
Epoch 0:  73%|███████▎  | 81/111 [00:05&lt;00:02, 13.77it/s, loss=0.0169, v_num=, reduced_train_loss=0.0169, global_step=79.00, consumed_samples=632.0]
Epoch 0:  73%|███████▎  | 81/111 [00:05&lt;00:02, 13.77it/s, loss=0.0183, v_num=, reduced_train_loss=0.0474, global_step=80.00, consumed_samples=640.0]
Epoch 0:  74%|███████▍  | 82/111 [00:05&lt;00:02, 13.83it/s, loss=0.0183, v_num=, reduced_train_loss=0.0474, global_step=80.00, consumed_samples=640.0]
Epoch 0:  74%|███████▍  | 82/111 [00:05&lt;00:02, 13.83it/s, loss=0.0173, v_num=, reduced_train_loss=0.00144, global_step=81.00, consumed_samples=648.0]
Epoch 0:  75%|███████▍  | 83/111 [00:05&lt;00:02, 13.85it/s, loss=0.0173, v_num=, reduced_train_loss=0.00144, global_step=81.00, consumed_samples=648.0]
Epoch 0:  75%|███████▍  | 83/111 [00:05&lt;00:02, 13.85it/s, loss=0.0168, v_num=, reduced_train_loss=0.0219, global_step=82.00, consumed_samples=656.0] 
Epoch 0:  76%|███████▌  | 84/111 [00:06&lt;00:01, 13.89it/s, loss=0.0168, v_num=, reduced_train_loss=0.0219, global_step=82.00, consumed_samples=656.0]
Epoch 0:  76%|███████▌  | 84/111 [00:06&lt;00:01, 13.89it/s, loss=0.0177, v_num=, reduced_train_loss=0.0229, global_step=83.00, consumed_samples=664.0]
Epoch 0:  77%|███████▋  | 85/111 [00:06&lt;00:01, 13.94it/s, loss=0.0177, v_num=, reduced_train_loss=0.0229, global_step=83.00, consumed_samples=664.0]
Epoch 0:  77%|███████▋  | 85/111 [00:06&lt;00:01, 13.94it/s, loss=0.0184, v_num=, reduced_train_loss=0.031, global_step=84.00, consumed_samples=672.0] 
Epoch 0:  77%|███████▋  | 86/111 [00:06&lt;00:01, 13.99it/s, loss=0.0184, v_num=, reduced_train_loss=0.031, global_step=84.00, consumed_samples=672.0]
Epoch 0:  77%|███████▋  | 86/111 [00:06&lt;00:01, 13.99it/s, loss=0.0186, v_num=, reduced_train_loss=0.022, global_step=85.00, consumed_samples=680.0]
Epoch 0:  78%|███████▊  | 87/111 [00:06&lt;00:01, 14.02it/s, loss=0.0186, v_num=, reduced_train_loss=0.022, global_step=85.00, consumed_samples=680.0]
Epoch 0:  78%|███████▊  | 87/111 [00:06&lt;00:01, 14.02it/s, loss=0.0186, v_num=, reduced_train_loss=0.00275, global_step=86.00, consumed_samples=688.0]
Epoch 0:  79%|███████▉  | 88/111 [00:06&lt;00:01, 14.06it/s, loss=0.0186, v_num=, reduced_train_loss=0.00275, global_step=86.00, consumed_samples=688.0]
Epoch 0:  79%|███████▉  | 88/111 [00:06&lt;00:01, 14.05it/s, loss=0.0174, v_num=, reduced_train_loss=0.00636, global_step=87.00, consumed_samples=696.0]
Epoch 0:  80%|████████  | 89/111 [00:06&lt;00:01, 14.10it/s, loss=0.0174, v_num=, reduced_train_loss=0.00636, global_step=87.00, consumed_samples=696.0]
Epoch 0:  80%|████████  | 89/111 [00:06&lt;00:01, 14.10it/s, loss=0.0168, v_num=, reduced_train_loss=0.0227, global_step=88.00, consumed_samples=704.0] 
Epoch 0:  81%|████████  | 90/111 [00:06&lt;00:01, 14.14it/s, loss=0.0168, v_num=, reduced_train_loss=0.0227, global_step=88.00, consumed_samples=704.0]
Epoch 0:  81%|████████  | 90/111 [00:06&lt;00:01, 14.14it/s, loss=0.0159, v_num=, reduced_train_loss=0.000591, global_step=89.00, consumed_samples=712.0]
Epoch 0:  82%|████████▏ | 91/111 [00:06&lt;00:01, 14.19it/s, loss=0.0159, v_num=, reduced_train_loss=0.000591, global_step=89.00, consumed_samples=712.0]
Epoch 0:  82%|████████▏ | 91/111 [00:06&lt;00:01, 14.18it/s, loss=0.0158, v_num=, reduced_train_loss=0.000612, global_step=90.00, consumed_samples=720.0]
Epoch 0:  83%|████████▎ | 92/111 [00:06&lt;00:01, 14.23it/s, loss=0.0158, v_num=, reduced_train_loss=0.000612, global_step=90.00, consumed_samples=720.0]
Epoch 0:  83%|████████▎ | 92/111 [00:06&lt;00:01, 14.23it/s, loss=0.0147, v_num=, reduced_train_loss=0.0107, global_step=91.00, consumed_samples=728.0]  
Epoch 0:  84%|████████▍ | 93/111 [00:06&lt;00:01, 14.28it/s, loss=0.0147, v_num=, reduced_train_loss=0.0107, global_step=91.00, consumed_samples=728.0]
Epoch 0:  84%|████████▍ | 93/111 [00:06&lt;00:01, 14.27it/s, loss=0.014, v_num=, reduced_train_loss=0.000628, global_step=92.00, consumed_samples=736.0]
Epoch 0:  85%|████████▍ | 94/111 [00:06&lt;00:01, 14.32it/s, loss=0.014, v_num=, reduced_train_loss=0.000628, global_step=92.00, consumed_samples=736.0]
Epoch 0:  85%|████████▍ | 94/111 [00:06&lt;00:01, 14.32it/s, loss=0.0132, v_num=, reduced_train_loss=0.000621, global_step=93.00, consumed_samples=744.0]
Epoch 0:  86%|████████▌ | 95/111 [00:06&lt;00:01, 14.36it/s, loss=0.0132, v_num=, reduced_train_loss=0.000621, global_step=93.00, consumed_samples=744.0]
Epoch 0:  86%|████████▌ | 95/111 [00:06&lt;00:01, 14.36it/s, loss=0.0124, v_num=, reduced_train_loss=0.000607, global_step=94.00, consumed_samples=752.0]
Epoch 0:  86%|████████▋ | 96/111 [00:06&lt;00:01, 14.40it/s, loss=0.0124, v_num=, reduced_train_loss=0.000607, global_step=94.00, consumed_samples=752.0]
Epoch 0:  86%|████████▋ | 96/111 [00:06&lt;00:01, 14.40it/s, loss=0.012, v_num=, reduced_train_loss=0.000597, global_step=95.00, consumed_samples=760.0] 
Epoch 0:  87%|████████▋ | 97/111 [00:06&lt;00:00, 14.44it/s, loss=0.012, v_num=, reduced_train_loss=0.000597, global_step=95.00, consumed_samples=760.0]
Epoch 0:  87%|████████▋ | 97/111 [00:06&lt;00:00, 14.44it/s, loss=0.0113, v_num=, reduced_train_loss=0.000654, global_step=96.00, consumed_samples=768.0]
Epoch 0:  88%|████████▊ | 98/111 [00:06&lt;00:00, 14.48it/s, loss=0.0113, v_num=, reduced_train_loss=0.000654, global_step=96.00, consumed_samples=768.0]
Epoch 0:  88%|████████▊ | 98/111 [00:06&lt;00:00, 14.48it/s, loss=0.0106, v_num=, reduced_train_loss=0.000605, global_step=97.00, consumed_samples=776.0]
Epoch 0:  89%|████████▉ | 99/111 [00:06&lt;00:00, 14.52it/s, loss=0.0106, v_num=, reduced_train_loss=0.000605, global_step=97.00, consumed_samples=776.0]
Epoch 0:  89%|████████▉ | 99/111 [00:06&lt;00:00, 14.52it/s, loss=0.0106, v_num=, reduced_train_loss=0.000655, global_step=98.00, consumed_samples=784.0]
Epoch 0:  90%|█████████ | 100/111 [00:06&lt;00:00, 14.56it/s, loss=0.0106, v_num=, reduced_train_loss=0.000655, global_step=98.00, consumed_samples=784.0]
Epoch 0:  90%|█████████ | 100/111 [00:06&lt;00:00, 14.56it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation: 0it [00:00, ?it/s]

Validation:   0%|          | 0/10 [00:00&lt;?, ?it/s]

Validation DataLoader 0:   0%|          | 0/10 [00:00&lt;?, ?it/s]

Validation DataLoader 0:  10%|█         | 1/10 [00:00&lt;00:00, 11.68it/s]
Epoch 0:  91%|█████████ | 101/111 [00:06&lt;00:00, 14.48it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  20%|██        | 2/10 [00:00&lt;00:00, 17.98it/s]
Epoch 0:  92%|█████████▏| 102/111 [00:06&lt;00:00, 14.57it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  30%|███       | 3/10 [00:00&lt;00:00, 24.02it/s]
Epoch 0:  93%|█████████▎| 103/111 [00:07&lt;00:00, 14.69it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  40%|████      | 4/10 [00:00&lt;00:00, 28.93it/s]
Epoch 0:  94%|█████████▎| 104/111 [00:07&lt;00:00, 14.80it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  50%|█████     | 5/10 [00:00&lt;00:00, 33.06it/s]
Epoch 0:  95%|█████████▍| 105/111 [00:07&lt;00:00, 14.92it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  60%|██████    | 6/10 [00:00&lt;00:00, 32.88it/s]
Epoch 0:  95%|█████████▌| 106/111 [00:07&lt;00:00, 14.99it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  70%|███████   | 7/10 [00:00&lt;00:00, 34.25it/s]
Epoch 0:  96%|█████████▋| 107/111 [00:07&lt;00:00, 15.09it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  80%|████████  | 8/10 [00:00&lt;00:00, 36.78it/s]
Epoch 0:  97%|█████████▋| 108/111 [00:07&lt;00:00, 15.20it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0:  90%|█████████ | 9/10 [00:00&lt;00:00, 39.04it/s]
Epoch 0:  98%|█████████▊| 109/111 [00:07&lt;00:00, 15.31it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]

Validation DataLoader 0: 100%|██████████| 10/10 [00:00&lt;00:00, 41.05it/s]
Epoch 0:  99%|█████████▉| 110/111 [00:07&lt;00:00, 15.43it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0]
Epoch 0:  99%|█████████▉| 110/111 [00:07&lt;00:00, 15.42it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0, val_loss=0.000501]

                                                                        Epoch 0, global step 100: &#39;val_loss&#39; reached 0.00050 (best 0.00050), saving model to &#39;/result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining/checkpoints/megatron_bert--val_loss=0.00-step=100-consumed_samples=800.0-v11.ckpt&#39; as top 10

Epoch 0: 100%|██████████| 111/111 [00:08&lt;00:00, 13.07it/s, loss=0.00978, v_num=, reduced_train_loss=0.000861, global_step=99.00, consumed_samples=792.0, val_loss=0.000501]
Epoch 0: 100%|██████████| 111/111 [00:08&lt;00:00, 13.07it/s, loss=0.00745, v_num=, reduced_train_loss=0.000713, global_step=100.0, consumed_samples=800.0, val_loss=0.000501]
Epoch 0: 100%|██████████| 111/111 [00:08&lt;00:00, 13.07it/s, loss=0.00745, v_num=, reduced_train_loss=0.000713, global_step=100.0, consumed_samples=800.0, val_loss=0.000501]`Trainer.fit` stopped: `max_steps=101` reached.

Epoch 0: 100%|██████████| 111/111 [00:08&lt;00:00, 13.07it/s, loss=0.00745, v_num=, reduced_train_loss=0.000713, global_step=100.0, consumed_samples=800.0, val_loss=0.000501]
[NeMo I 2023-08-25 18:46:57 nlp_overrides:226] Removing checkpoint: /result/nemo_experiments/esm1nv-oas/esm1nv-oas_pretraining/checkpoints/megatron_bert--val_loss=0.00-step=100-consumed_samples=800.0-last.ckpt
[NeMo I 2023-08-25 18:46:58 pretrain_oas:24] ************** Finished Training ***********
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="creating-the-dataset-object">
<h2>Creating the Dataset object<a class="headerlink" href="#creating-the-dataset-object" title="Permalink to this headline">#</a></h2>
<p>Underneath the abstractions we provide, ultimately the dataset is constructed by invoking the relevant NeMo object, specified with <code class="docutils literal notranslate"><span class="pre">model.data.data_impl</span></code> in the config file. Additionally we provide the requisite keyword arguments, specified with <code class="docutils literal notranslate"><span class="pre">model.data.data_impl_kwargs</span></code> field. Look around in NeMo for additional dataset types, or implement your own!</p>
<p>We can do this manually as well!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_paths</span> <span class="o">=</span> <span class="p">[</span> 
    <span class="s1">&#39;/data/OASpaired/processed/heavy/train/x000.csv&#39;</span> <span class="p">,</span>
    <span class="s1">&#39;/data/OASpaired/processed/heavy/train/x001.csv&#39;</span> <span class="p">,</span>
    <span class="s1">&#39;/data/OASpaired/processed/heavy/train/x002.csv&#39;</span> <span class="p">,</span>
<span class="p">]</span>
<span class="c1"># Checkout nemo for examples of other dataset types, or add your own!</span>
<span class="kn">from</span> <span class="nn">nemo.collections.nlp.data.language_modeling.text_memmap_dataset</span> <span class="kn">import</span> <span class="n">CSVMemMapDataset</span>
<span class="c1"># The kwargs here are taken from our yaml file.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">CSVMemMapDataset</span><span class="p">(</span><span class="n">dataset_paths</span><span class="o">=</span><span class="n">dataset_paths</span><span class="p">,</span> <span class="n">header_lines</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">newline_int</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sort_dataset_paths</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">data_sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">data_col</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataset</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span> <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[NeMo W 2023-08-25 18:47:09 experimental:27] Module &lt;class &#39;nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel&#39;&gt; is experimental, not ready for production and is not fully supported. Use at your own risk.
[NeMo W 2023-08-25 18:47:10 experimental:27] Module &lt;class &#39;nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures&#39;&gt; is experimental, not ready for production and is not fully supported. Use at your own risk.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:104] Building data files
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:343] Processing 3 data files using 1 workers
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:349] Time building 0 / 3 mem-mapped files: 0:00:00.051294
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:114] Loading data files
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x000.csv
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x001.csv
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:205] Loading /data/OASpaired/processed/heavy/train/x002.csv
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:117] Time loading 3 mem-mapped files: 0:00:00.005260
[NeMo I 2023-08-25 18:47:10 text_memmap_dataset:121] Computing global indices
GGGAGAGGAGGCCTGTCCTGGATTCGATTCCCAGTTCCTCACATTCAGTCAGCACTGAACACGGACCCCTCACCATGAACTTCGGGCTCAGCTTGATTTTCCTTGTCCTTGTTTTAAAAGGTGTCCAGTGTGAAGTGATGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATGCCATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCAACCATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACAGTGTGAAGGGGCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAGGTCTGAGGACACGGCCATGTATTACTGTGCAAGACGGGGGAATGATGGTTACTACGAAGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
GAGCTCTGACAGAGGAGGCCAGTCCTGGAATTGATTCCCAGTTCCTCACGTTCAGTGATGAGCACTGAACACAGACACCTCACCATGAACTTTGGGCTCAGATTGATTTTCCTTGTCCTTACTTTAAAAGGTGTGAAGTGTGAAGTGCAGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCGCTTTCAGTAGCTATGACATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCATACATTAGTAGTGGTGGTGGTATCACCTACTATCCAGACACTGTGAAGGGCCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAAGTCTGAGGACACAGCCATGTATTACTGTGCAAGGCCCCCGGGACGGGGCTACTGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGCCAAAACAACAGCCCCATCGGTCTATCCACTGGCCCCTGTGTGTGGAGATACAACTGGCTCCTCGGTGACTCTAGGGTGCCTGGTCAAGGATTATT
AACATATGTCCAATGTCCTCTCCACAGACACTGAACACACTGACTCTAACCATGGGATGGAGCTGGATCTTTCTCTTCCTCCTGTCAGGAACTGCAGGCGTCCACTCTGAGGTCCAGCTTCAGCAGTCAGGACCTGAGCTGGTGAAACCTGGGGCCTCAGTGAAGATATCCTGCAAGGCTTCTGGATACACATTCACTGACTACAACATGCACTGGGTGAAGCAGAGCCATGGAAAGAGCCTTGAGTGGATTGGATATATTTATCCTTACAATGGTGGTACTGGCTACAACCAGAAGTTCAAGAGCAAGGCCACATTGACTGTAGACAATTCCTCCAGCACAGCCTACATGGAGCTCCGCAGCCTGACATCTGAGGACTCTGCAGTCTATTACTGTGCAAGATGGGGGCTAACTGGTGATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
GACATAACAGCAAGAGAGTGTCCGGTTAGTCTCAAGGAAGACTGAGACACAGTCTTAGATATCATGGAATGGCTGTGGAACTTGCTATTTCTCATGGCAGCAGCTCAAAGTATCCAAGCACAGATCCAGTTGGTGCAGTCTGGACCTGAGCTGAAGAAGCCTGGAGAGACAGTCAGGATCTCCTGCAAGGCTTCTGGGTATACCTTCACAACTGCTGGAATGCAGTGGGTGCAAAAGATGCCAGGAAAGGGTTTGAAGTGGATTGGCTGGATAAACACCCACTCTGGAGTGCCAAAATATGCAGAAGACTTCAAGGGACGGTTTGCCTTCTCTTTGGAAACCTCTGCCAGCACTGCATATTTACAGATAAGCAACCTCAAAAATGAGGACACGGCTACGTATTTCTGTGCGAGATCAGGTTACGACGCCTTTGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
GGGGAGCATATGATCAGTGTCCTCTCCAAAGTCCTTGAACATAGACTCTAACCATGGAATGGACCTGGGTCTTTCTCTTCCTCCTGTCAGTAACTGCAGGTGTCCACTCCCAGGTTCAGCTGCAGCAGTCTGGAGTTGAGCTGATGAAGCCTGGGGCCTCAGTGAAGATATCCTGCAAGGCTACTGGCTACACACTCAGTAACTACTGGATAGAGTGGGTAAAGCAGAGGCCTGGACATGGCCTTGAGTGGATTGGAGAGATTTTACCTGGAGATGTTATTACTAACTACAATGAGAGGTTCAAGGACAAGGCCACATTCACTGCAGATACATCCTCCAACACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGATTCTGCCGTCTATTACTGTGCAAGAAGGGTTATTAAGGGGGGGTTTGCTTACTGGGGCCAAGGGACTCTGGTCACTGTCTCTGCAGCCAAAACAACAGCCCCATCGGTCTATCCACTGGCCCCTGTGTGTGGAGATACAACTGGCTCCTCGGTGACTCTAGGATGCCTGGTCAAGG
ACATCGCTCTCACTGGAGGCTGATCTCTGAAGATAAGGAGGTGTAGCCTAAAAGATGAGAGTGCTGATTCTTTTGTGGCTGTTCACAGCCTTTCCTGGTATCCTGTCTGATGTGCAGCTTCAGGAGTCGGGACCTGGCCTGGTGAAACCTTCTCAGTCTCTGTCCCTCACCTGCACTGTCACTGGCTACTCAATCACCAGTGATTATGCCTGGAACTGGATCCGGCAGTTTCCAGGAAACAAACTGGAGTGGATGGGCTACATAAGCTACAGTGGTAGCACTAGCTACAACCCATCTCTCAAAAGTCGAATCTCTATCACTCGAGACACATCCAAGAACCAGTTCTTCCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGAAGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
ATCGCTCTCACTGGAGGCTGATCTCTGAAGATAAGGAGGTGTAGCCTAAAAGATGAGAGTGCTGATTCTTTTGTGGCTGTTCACAGCCTTTCCTGGTATCCTGTCTGATGTGCAGCTTCAGGAGTCGGGACCTGGCCTGGTGAAACCTTCTCAGTCTCTGTCCCTCACCTGCACTGTCACTGGCTACTCAATCACCAGTGATTATGCCTGGAACTGGATCCGGCAGTTTCCAGGAAACAAACTGGAGTGGATGGGCTACATAAGCTACAGTGGTAGCACTAGCTACAACCCATCTCTCAAAAGTCGAATCTCTATCACTCGAGACACATCCAAGAACCAGTTCTTCCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGGAGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
GGGGAAAAACATGAGATCACAGTTCTCTCTACAGTTACTGAGCACACAGGAACTCACCATGGGATGGAGCTATATCATCCTCTTTTTGGTAGCAACAGCTACAGGTGTCCACTCCCAGGTCCAACTGCAGCAGCCTGGGGCTGAACTGGTGAAGCCTGGGGCTTCAGTGAAGTTGTCCTGCAAGGCTTCTGGCTACACCTTCACCAGCTACTATATGTACTGGGTGAAGCAGAGGCCTGGACAAGGCCTTGAGTGGATTGGGGGGATTAATCCTAGCAATGGTGGTACTAACTTCAATGAGAAGTTCAAGAGCAAGGCCACACTGACTGTAGACAAATCCTCCAGCACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGACTCTGCGGTCTATTACTGTACAAGATACGGCCTCTATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
ACTAGTGTGCAGATATGGACAGGCTTACTTCCTCATTGCTGCTGCTGATTGTCCCTGCATATGTCCTGTCCCAGGTTACTCTGAAAGAGTCTGGCCCTGGGATATTGCAGCCCTCCCAGACCCTCAGTCTGACTTGTTCTTTCTCTGGGTTTTCACTGACCACTTCTGGTATGGGTGTGACCTGGATTCGTCAGCCTTCAGGAAAGGGTCTGGAGTGGCTGGCACACATTTACTGGGATAATGACAAGCGCTATAATACATCCCTGAAGAGCCGGCTCACAATCTCCAAGGATACCTCCAGCAACCGGGTATTCCTCAAGATAACCAGTGTGGACACTGCAGATACTGCCACATACTACTGTACTCGAGTTACTACGTTGGTGGGCTACTTTGACCAATGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGCCAAAACGACACCCCCATCTGTCTATCCACTGGCCCCTGGATCTGCTGCCCAAACTAACTCCATGGTGACCCTGGGATGCCTGGTCAAGGG
AACACCACCAACAACGACATCGACAATCATTCCCTACACAAAGCTCTTCCGATCTAAACGGGAGAATAGAGTCAATGATTTATTCTTATATGAGGAGAAAAACATGAGATCACAGTTCTCTCTACAGTTACTGAGCACACAGGACCTCACCATGGGATGGAGCTATATCATTTTCTTTTTGGTAGCAACAGCTACAGGTGTCCACTCCCAGGTCCAACTCCAGCAGCCTGGGGCTGAACTGGTGAAGCCTGGGGCTTCAGTGAAGTTGTCCTGCAAGGCTTCTGGCTACACCTTCACCAGCTACTGGATGCACTGGGTGAAGCTGAGGCCTGGACAAGGCTTTGAGTGGATTGGAGAGATTAATCCTAGCAATGGTGGTACTAACTACAATGAGAAGTTCAAGAGAAAGGCCACACTGACTGTAGACAAATCCTCCAGCACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGACTCTGCGGTCTATTACTGTACAATACGGAATTACTACGGTAGTAGCTACGAGGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
GTCTATGGCAGTTCCTATCTCTCTCACTGGAGGCTGATTTTTGAAGAAAGGGGTTGTAGCCTAAAAGATGATGGTGTTAAGTCTTCTGTACCTGTTGACAGCCCTTCCGGGTATCCTGTCAGAGGTGCAGCTTCAGGAGTCAGGACCTAGCCTCGTGAAACCTTCTCAGACTCTGTCCCTCACCTGTTCTGTCACTGGCGACTCCATCACCAGTGGTTACTGGAACTGGATCCGGAAATTCCCAGGGAATAAACTTGAGTACATGGGGTACATAAGCTACAGTGGTAGCACTTACTACAATCCATCTCTCAAAAGTCGAATCTCCATCACTCGAGACACATCCAAGAACCAGTACTACCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGATGGGACTATGACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="testing-our-new-collate-function">
<h2>Testing our new collate function<a class="headerlink" href="#testing-our-new-collate-function" title="Permalink to this headline">#</a></h2>
<p>Before we inject our collate function into a dataloader, lets first take a look at what it actually does. As we saw previously, it simply replaces every character with ‘A’, this should be visually obvious! To do this, we must also include a tokenizer. This is required by the default language modeling collate function, which tokenizes the input, applies padding, and aligns it for distributed training. We call <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> with some dummy data and then watch the output transformed to <code class="docutils literal notranslate"><span class="pre">AAAA..</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bionemo.data.dataloader.custom_protein_collate</span> <span class="kn">import</span> <span class="n">CustomProteinBertCollate</span>

<span class="c1"># Some magic to get our NeMo tokenizer, filled with arguments from our config file.</span>
<span class="kn">from</span> <span class="nn">nemo.collections.nlp.modules.common.tokenizer_utils</span> <span class="kn">import</span> <span class="n">get_nmt_tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_nmt_tokenizer</span><span class="p">(</span>
            <span class="n">library</span><span class="o">=</span><span class="s1">&#39;sentencepiece&#39;</span><span class="p">,</span>
            <span class="n">tokenizer_model</span><span class="o">=</span> <span class="s1">&#39;/tokenizers/protein/esm1nv/vocab/protein_sequence_sentencepiece.model&#39;</span><span class="p">,</span>
            <span class="n">vocab_file</span><span class="o">=</span><span class="s1">&#39;/tokenizers/vocab/protein_sequence_sentencepiece.vocab&#39;</span><span class="p">,</span>
            <span class="n">legacy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Extra kwargs are again taken from our config file.</span>
<span class="n">collate_fn</span> <span class="o">=</span> <span class="n">CustomProteinBertCollate</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                                                    <span class="n">seq_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                                                    <span class="n">pad_size_divisible_by_8</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                    <span class="n">modify_percent</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="c1"># Fraction of tokens to mask or perturb</span>
                                                    <span class="n">perturb_percent</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="c1"># Fraction of modified tokens to perturb, 1-perturb_percent is masking probability</span>
                                                    <span class="p">)</span><span class="o">.</span><span class="n">collate_fn</span>
<span class="n">collate_fn</span><span class="p">([</span><span class="s1">&#39;ACTGT&#39;</span><span class="p">,</span> <span class="s1">&#39;ADFASDFA&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[NeMo I 2023-08-25 18:47:10 tokenizer_utils:191] Getting SentencePiece with model: /tokenizers/protein/esm1nv/vocab/protein_sequence_sentencepiece.model
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: tensor([[1, 6, 6, 6, 6, 6, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3],
         [1, 6, 6, 4, 6, 6, 6, 6, 6, 2, 3, 3, 3, 3, 3, 3]]),
 &#39;types&#39;: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
 &#39;is_random&#39;: tensor([0, 1]),
 &#39;loss_mask&#39;: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),
 &#39;labels&#39;: tensor([[1, 6, 6, 6, 6, 6, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3],
         [1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 3, 3, 3, 3, 3, 3]]),
 &#39;padding_mask&#39;: tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]),
 &#39;batch&#39;: [&#39;AAAAA&#39;, &#39;AAAAAAAA&#39;]}
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="dataloader">
<h1>DataLoader!<a class="headerlink" href="#dataloader" title="Permalink to this headline">#</a></h1>
<p>Lastly, we must construct a dataloader composed of our collate function and our dataset object. From here, we can iterate over the reuslt and ensure it changed the data in the same way as manually calling the collate function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Before:&quot;</span><span class="p">)</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dl</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n\n</span><span class="s2">After:&quot;</span><span class="p">)</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dl</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before:
[&#39;GGGAGAGGAGGCCTGTCCTGGATTCGATTCCCAGTTCCTCACATTCAGTCAGCACTGAACACGGACCCCTCACCATGAACTTCGGGCTCAGCTTGATTTTCCTTGTCCTTGTTTTAAAAGGTGTCCAGTGTGAAGTGATGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATGCCATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCAACCATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACAGTGTGAAGGGGCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAGGTCTGAGGACACGGCCATGTATTACTGTGCAAGACGGGGGAATGATGGTTACTACGAAGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;GAGCTCTGACAGAGGAGGCCAGTCCTGGAATTGATTCCCAGTTCCTCACGTTCAGTGATGAGCACTGAACACAGACACCTCACCATGAACTTTGGGCTCAGATTGATTTTCCTTGTCCTTACTTTAAAAGGTGTGAAGTGTGAAGTGCAGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCGCTTTCAGTAGCTATGACATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCATACATTAGTAGTGGTGGTGGTATCACCTACTATCCAGACACTGTGAAGGGCCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAAGTCTGAGGACACAGCCATGTATTACTGTGCAAGGCCCCCGGGACGGGGCTACTGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGCCAAAACAACAGCCCCATCGGTCTATCCACTGGCCCCTGTGTGTGGAGATACAACTGGCTCCTCGGTGACTCTAGGGTGCCTGGTCAAGGATTATT&#39;]
[&#39;AACATATGTCCAATGTCCTCTCCACAGACACTGAACACACTGACTCTAACCATGGGATGGAGCTGGATCTTTCTCTTCCTCCTGTCAGGAACTGCAGGCGTCCACTCTGAGGTCCAGCTTCAGCAGTCAGGACCTGAGCTGGTGAAACCTGGGGCCTCAGTGAAGATATCCTGCAAGGCTTCTGGATACACATTCACTGACTACAACATGCACTGGGTGAAGCAGAGCCATGGAAAGAGCCTTGAGTGGATTGGATATATTTATCCTTACAATGGTGGTACTGGCTACAACCAGAAGTTCAAGAGCAAGGCCACATTGACTGTAGACAATTCCTCCAGCACAGCCTACATGGAGCTCCGCAGCCTGACATCTGAGGACTCTGCAGTCTATTACTGTGCAAGATGGGGGCTAACTGGTGATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;GACATAACAGCAAGAGAGTGTCCGGTTAGTCTCAAGGAAGACTGAGACACAGTCTTAGATATCATGGAATGGCTGTGGAACTTGCTATTTCTCATGGCAGCAGCTCAAAGTATCCAAGCACAGATCCAGTTGGTGCAGTCTGGACCTGAGCTGAAGAAGCCTGGAGAGACAGTCAGGATCTCCTGCAAGGCTTCTGGGTATACCTTCACAACTGCTGGAATGCAGTGGGTGCAAAAGATGCCAGGAAAGGGTTTGAAGTGGATTGGCTGGATAAACACCCACTCTGGAGTGCCAAAATATGCAGAAGACTTCAAGGGACGGTTTGCCTTCTCTTTGGAAACCTCTGCCAGCACTGCATATTTACAGATAAGCAACCTCAAAAATGAGGACACGGCTACGTATTTCTGTGCGAGATCAGGTTACGACGCCTTTGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;GGGGAGCATATGATCAGTGTCCTCTCCAAAGTCCTTGAACATAGACTCTAACCATGGAATGGACCTGGGTCTTTCTCTTCCTCCTGTCAGTAACTGCAGGTGTCCACTCCCAGGTTCAGCTGCAGCAGTCTGGAGTTGAGCTGATGAAGCCTGGGGCCTCAGTGAAGATATCCTGCAAGGCTACTGGCTACACACTCAGTAACTACTGGATAGAGTGGGTAAAGCAGAGGCCTGGACATGGCCTTGAGTGGATTGGAGAGATTTTACCTGGAGATGTTATTACTAACTACAATGAGAGGTTCAAGGACAAGGCCACATTCACTGCAGATACATCCTCCAACACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGATTCTGCCGTCTATTACTGTGCAAGAAGGGTTATTAAGGGGGGGTTTGCTTACTGGGGCCAAGGGACTCTGGTCACTGTCTCTGCAGCCAAAACAACAGCCCCATCGGTCTATCCACTGGCCCCTGTGTGTGGAGATACAACTGGCTCCTCGGTGACTCTAGGATGCCTGGTCAAGG&#39;, &#39;ACATCGCTCTCACTGGAGGCTGATCTCTGAAGATAAGGAGGTGTAGCCTAAAAGATGAGAGTGCTGATTCTTTTGTGGCTGTTCACAGCCTTTCCTGGTATCCTGTCTGATGTGCAGCTTCAGGAGTCGGGACCTGGCCTGGTGAAACCTTCTCAGTCTCTGTCCCTCACCTGCACTGTCACTGGCTACTCAATCACCAGTGATTATGCCTGGAACTGGATCCGGCAGTTTCCAGGAAACAAACTGGAGTGGATGGGCTACATAAGCTACAGTGGTAGCACTAGCTACAACCCATCTCTCAAAAGTCGAATCTCTATCACTCGAGACACATCCAAGAACCAGTTCTTCCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGAAGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;ATCGCTCTCACTGGAGGCTGATCTCTGAAGATAAGGAGGTGTAGCCTAAAAGATGAGAGTGCTGATTCTTTTGTGGCTGTTCACAGCCTTTCCTGGTATCCTGTCTGATGTGCAGCTTCAGGAGTCGGGACCTGGCCTGGTGAAACCTTCTCAGTCTCTGTCCCTCACCTGCACTGTCACTGGCTACTCAATCACCAGTGATTATGCCTGGAACTGGATCCGGCAGTTTCCAGGAAACAAACTGGAGTGGATGGGCTACATAAGCTACAGTGGTAGCACTAGCTACAACCCATCTCTCAAAAGTCGAATCTCTATCACTCGAGACACATCCAAGAACCAGTTCTTCCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGGAGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;GGGGAAAAACATGAGATCACAGTTCTCTCTACAGTTACTGAGCACACAGGAACTCACCATGGGATGGAGCTATATCATCCTCTTTTTGGTAGCAACAGCTACAGGTGTCCACTCCCAGGTCCAACTGCAGCAGCCTGGGGCTGAACTGGTGAAGCCTGGGGCTTCAGTGAAGTTGTCCTGCAAGGCTTCTGGCTACACCTTCACCAGCTACTATATGTACTGGGTGAAGCAGAGGCCTGGACAAGGCCTTGAGTGGATTGGGGGGATTAATCCTAGCAATGGTGGTACTAACTTCAATGAGAAGTTCAAGAGCAAGGCCACACTGACTGTAGACAAATCCTCCAGCACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGACTCTGCGGTCTATTACTGTACAAGATACGGCCTCTATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;ACTAGTGTGCAGATATGGACAGGCTTACTTCCTCATTGCTGCTGCTGATTGTCCCTGCATATGTCCTGTCCCAGGTTACTCTGAAAGAGTCTGGCCCTGGGATATTGCAGCCCTCCCAGACCCTCAGTCTGACTTGTTCTTTCTCTGGGTTTTCACTGACCACTTCTGGTATGGGTGTGACCTGGATTCGTCAGCCTTCAGGAAAGGGTCTGGAGTGGCTGGCACACATTTACTGGGATAATGACAAGCGCTATAATACATCCCTGAAGAGCCGGCTCACAATCTCCAAGGATACCTCCAGCAACCGGGTATTCCTCAAGATAACCAGTGTGGACACTGCAGATACTGCCACATACTACTGTACTCGAGTTACTACGTTGGTGGGCTACTTTGACCAATGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGCCAAAACGACACCCCCATCTGTCTATCCACTGGCCCCTGGATCTGCTGCCCAAACTAACTCCATGGTGACCCTGGGATGCCTGGTCAAGGG&#39;, &#39;AACACCACCAACAACGACATCGACAATCATTCCCTACACAAAGCTCTTCCGATCTAAACGGGAGAATAGAGTCAATGATTTATTCTTATATGAGGAGAAAAACATGAGATCACAGTTCTCTCTACAGTTACTGAGCACACAGGACCTCACCATGGGATGGAGCTATATCATTTTCTTTTTGGTAGCAACAGCTACAGGTGTCCACTCCCAGGTCCAACTCCAGCAGCCTGGGGCTGAACTGGTGAAGCCTGGGGCTTCAGTGAAGTTGTCCTGCAAGGCTTCTGGCTACACCTTCACCAGCTACTGGATGCACTGGGTGAAGCTGAGGCCTGGACAAGGCTTTGAGTGGATTGGAGAGATTAATCCTAGCAATGGTGGTACTAACTACAATGAGAAGTTCAAGAGAAAGGCCACACTGACTGTAGACAAATCCTCCAGCACAGCCTACATGCAACTCAGCAGCCTGACATCTGAGGACTCTGCGGTCTATTACTGTACAATACGGAATTACTACGGTAGTAGCTACGAGGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;GTCTATGGCAGTTCCTATCTCTCTCACTGGAGGCTGATTTTTGAAGAAAGGGGTTGTAGCCTAAAAGATGATGGTGTTAAGTCTTCTGTACCTGTTGACAGCCCTTCCGGGTATCCTGTCAGAGGTGCAGCTTCAGGAGTCAGGACCTAGCCTCGTGAAACCTTCTCAGACTCTGTCCCTCACCTGTTCTGTCACTGGCGACTCCATCACCAGTGGTTACTGGAACTGGATCCGGAAATTCCCAGGGAATAAACTTGAGTACATGGGGTACATAAGCTACAGTGGTAGCACTTACTACAATCCATCTCTCAAAAGTCGAATCTCCATCACTCGAGACACATCCAAGAACCAGTACTACCTGCAGTTGAATTCTGTGACTACTGAGGACACAGCCACATATTACTGTGCAAGATGGGACTATGACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;AGTTGCGTCTTTTCTTATATGGGATCCTCTTCTCATAGAGCCTCCATCAGAGCATGGCTGTCTTGGGGCTGCTCTTCTGCCTGGTGACATTCCCAAGCTGTGTCCTATCCCAGGTGCAGCTGAAGCAGTCAGGACCTGGCCTAGTGCAGCCCTCACAGAGCCTGTCCATCACCTGCACAGTCTCTGGTTTCTCATTAACTAGCTATGGTGTACACTGGGTTCGCCAGTCTCCAGGAAAGGGTCTGGAGTGGCTGGGAGTGATATGGAGTGGTGGAAGCACAGACTATAATGCAGCTTTCATATCCAGACTGAGCATCAGCAAGGACAATTCCAAGAGCCAAGTTTTCTTTAAAATGAACAGTCTGCAAGCTAATGACACAGCCATATATTACTGTGCCAGAAATTCGGGGGGGTATGGTAACTACGCCCTTTTTGCTTACTGGGGCCAAGGGACTCTGGTCACTGTCTCTGCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;GGGGAACAGACACACAAACCTGGACTCACAAGTTTTTCTCTTCAGTGACAGACACAGACATAGAACATTCACGATGTACTTGGGACTGAACTATGTATTCATAGTTTTTCTCTTAAATGGTGTCCAGAGTGAAGTGAAGCTTGAGGAGTCTGGAGGAGGCTTGGTGCAACCTGGAGGATCCATGAAACTCTCTTGTGCTGCCTCTGGATTCACTTTTAGTGACGCCTGGATGGACTGGGTCCGCCAGTCTCCAGAGAAGGGGCTTGAGTGGGTTGCTGAAATTAGAAGCAAAGCTAATAATCATGCAACATACTATGCTGAGTCTGTGAAAGGGAGGTTCACCATCTCAAGAGATGATTCCAAAAGTAGTGTCTACCTGCAAATGAACAGCTTAAGAGCTGAAGACACTGGCATTTATTACTGTACCCGGTATGGTAACTGGCGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;GGAGCTCTGACAGAGGAGGCAGGTCCTGGATTCGATTCCCAGTTCCTCACATTCAGTCAGCACTGAACACGGACCCCTCACCATGAACTTTGTGCTCAGCTTGATTTTCCTTGCCCTCATTTTAAAAGGTGTCCAGTGTGAAGTGCAGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATGCCATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCAACCATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACAGTGTGAAGGGTCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAGGTCTGAGGACACGGCCATGTATTACTGTGCAAGACTAGACCCAACTGGGAACTATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;ATCTCCTCACTAGAGCCCCCATCAGAGCATGGCTGTCCTGGTGCTGTTCCTCTGCCTGGTTGCATTTCCAAGCTGTGTCCTGTCCCAGGTGCAACTGAAGGAGTCAGGACCTGGCCTGGTGGCGCCCTCACAGAGCCTGTCCATCACTTGCACTGTCTCTGGGTTTTCCTTAACCAGCTATGGTGTACACTGGGTTCGCCAGCCTCCAGGAAAGGGTCTGGAGTGGCTGGGAGTAATATGGGCTGGTGGAATCACAAATTATAATTCGGCTCTCATGTCCAGACTGAGCATCAGCAAAGACAACTCCAAGAGCCAAGTTTTCTTAAAAATGAACAGTCTGCAAACTGTTGACACAGCCATGTACTACTGTGCCAGAGATAGGGCCGGCTACTATGGTAACTACTTTGACTACTGGGGCCAAGGCACCACTCTCACAGTCTCCTCAGCCAAAACGACACCCCCATCTGTCTATCCACTGGCCCCTGGATCTGCTGCCCAAACTAACTCCATGGTGACCCTGGGATGCCTGGTCAAGGG&#39;, &#39;GACATACCAGCAAGGGAGTGACCAGTTTGTCTTAAGGCACCACTGAGCCCAAGTCTTAGACATCATGGATTGGCTGTGGAACTTGCTATTCCTGATGGCAGCTGCCCAAAGTGCCCAAGCACAGATCCAGTTGGTGCAGTCTGGACCTGAGCTGAAGAAGCCTGGAGAGACAGTCAAGATCTCCTGCAAGGCTTCTGGGTATACCTTCACAAACTATGGAATGAACTGGGTGAAGCAGGCTCCAGGAAAGGGTTTAAAGTGGATGGGCTGGATAAACACCTACACTGGAGAGCCAACATATGCTGATGACTTCAAGGGACGGTTTGCCTTCTCTTTGGAAACCTCTGCCAGCACTGCCTATTTGCAGATCAACAACCTCAAAAATGAGGACATGGCTACATATTTCTGTGCAAGAGGGGGTAGTAGCTACAGGGACTGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;GAGCTCTGACAGAGGAGGCCAGTCCTGGAATTGATTCCCAGTTCCTCACGTTCAGTGATGAGCAGTGAACACAGACCCCTCACCATGAACTTCGGGCTCAGATTGATTTTCCTTGTCCTTACTTTAAAAGGTGTCCAGTGTGACGTGAAGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATACCATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCAACCATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACAGTGTGAAGGGCCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAAGTCTGAGGACACAGCCATGTATTACTGTACAAGCTCCCACCCTGATTGGGGAGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;TGGGGAGCTCTGACAGAGGAGGCCGGTCCTGGATTCGATTCCCAGTTCCTCACATTCAGTCAGCACTGAACACAGACACCTCACCATGAACTTCGGGCTCAGCTTGATTTTCCTTGTCCTTATTTTAAAAGGTGTCCAGTGTGAAGTGCAGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATGCCATGTCTTGGGTTCGCCAGTCTCCAGAGAAGAGGCTGGAGTGGGTCGCAGAAATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACACTGTGACGGGCCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGGAAATGAGCAGTCTGAGGTCTGAGGACACGGCCATGTATTACTGTGCAAGGGATCAGTCTACTATGATTACGTCGTTTGCTTACTGGGGCCAAGGGACTCTGGTCACTGTCTCTGCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;TCATCTCCTCACTAGAGCCCCCATCAGAGCATGGCTGTCCTGGTGCTGTTCCTCTGCCTGGTTGCATTTCCAAGCTGTGTCCTGTCCCAGGTGCAGCTGAAGGAGTCAGGACCTGGCCTGGTGGCGCCCTCACAGAGCCTGTCCATCACTTGCACTGTCTCTGGGTTTTCATTAACCAGCTATGGTGTACACTGGGTTCGCCAGCCTCCAGGAAAGGGTCTGGAGTGGCTGGGAGTAATATGGGCTGGTGGAAGCACAAATTATAATTCGGCTCTCATGTCCAGACTGAGCATCAGCAAAGACAACTCCAAGAGCCAAGTTTTCTTAAAAATGAACAGTCTGCAAACTGATGACACAGCCATGTACTACTGTGCCAGAGATCTATTCTATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;TATTTTTCTTATATGGGGATCCTCTTCTCATAGAGCCTCCATCAGAGCATGGCTGTCCTGGTGCTGCTCTTCTGCCTGGTGACATTCCCAAGCTGTGTCCTATCCCAGGTGCAGCTGAAGCAGTCAGGACCTGGCCTAGTGCAGCCCTCACAGAGCCTGTCCATCACCTGCACAGTCTCTGGTTTCTCATTAACTAGCTATGGTGTACACTGGGTTCGCCAGCCTCCAGGAAAGGGTCTGGAGTGGCTGGGAGTGATATGGAGTGGTGGAAGCACAGACTATAATGCTGCTTTCATATCCAGACTGAGCATCAGCAAGGACAACTCCAAGAGCCAAGTTTTCTTTAAAATGAACAGTCTGCAAGCTGATGACACAGCCATATACTACTGTGCCAGAAAGGCCCCCTATGCTATGGACTACTGGGGTCAAGGAACCTCAGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]
[&#39;CTGAGCTTTCTTATATGGGGAGCTCTGACAGAGGAGGCCTGTCCTGGATTCGATTCCCAGTTCCTCACATTCAGTCAGCACTGAACACGGACCCCTCACCATGAACTTCGGGCTCAGCTTGATTTTCCTTGTCCTTGTTTTAAAAGGTGTCCAGTGTGAAGTGATGCTGGTGGAGTCTGGGGGAGGCTTAGTGAAGCCTGGAGGGTCCCTGAAACTCTCCTGTGCAGCCTCTGGATTCACTTTCAGTAGCTATGCCATGTCTTGGGTTCGCCAGACTCCGGAGAAGAGGCTGGAGTGGGTCGCAACCATTAGTAGTGGTGGTAGTTACACCTACTATCCAGACAGTGTGAAGGGGCGATTCACCATCTCCAGAGACAATGCCAAGAACACCCTGTACCTGCAAATGAGCAGTCTGAGGTCTGAGGACACGGCCATGTATTACTGTGCAAGAGGAGGGGACTATGGTAACGGGTACTTCGATGTCTGGGGCGCAGGGACCACGGTCACCGTCTCCTCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;, &#39;ACAGTCATTGAAAACACTGACTCTAATCATGGAATGTAACTGGATACTTCCTTTTATTCTGTCGGTAATTTCAGGGGTCTACTCAGAGGTTCAGCTCCAGCAGTCTGGGACTGTGCTGGCAAGGCCTGGGGCTTCCGTGAAGATGTCCTGCAAGGCTTCTGGCTACAGCTTTACCAGCTACTGGATGCACTGGGTAAAACAGAGGCCTGGACAGGGTCTAGAATGGATTGGTGCTATTTATCCTGGAAATAGTGATACTAGCTACAACCAGAAGTTCAAGGGCAAGGCCAAACTGACTGCAGTCACATCCGCCAGCACTGCCTACATGGAGCTCAGCAGCCTGACAAATGAGGACTCTGCGGTCTATTACTGTACCCTTATGATTACGACGACGGTTTTTGCTTACTGGGGCCAAGGGACTCTGGTCACTGTCTCTGCAGAGAGTCAGTCCTTCCCAAATGTCTTCCCCCTCGTCTCCTGCGAGAGCCCCCTGTCTGATAAGAATCTGGTGGCCATGGGCTGCCTGG&#39;]



After:
{&#39;text&#39;: tensor([[ 1,  6, 13,  ...,  6,  6,  6],
        [16,  6,  6,  ...,  4,  9,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 1,  ..., 0, 0, 0],
        [1, 0, 0,  ..., 1, 1, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[ 1, 25,  6,  ...,  6,  6,  6],
        [ 1,  6,  6,  ...,  6,  6,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 1, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[1, 6, 6,  ..., 6, 4, 6],
        [1, 6, 4,  ..., 6, 6, 6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 0, 1, 0],
        [0, 0, 1,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[ 1,  6, 26,  ...,  6,  6,  6],
        [ 1,  6,  4,  ...,  6,  6,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 1,  ..., 0, 0, 0],
        [0, 0, 1,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[ 1,  6,  6,  ..., 22,  6,  6],
        [ 4,  6,  6,  ...,  6,  6,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 1, 0, 0],
        [1, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[ 1,  4,  6,  ...,  6,  6,  6],
        [ 1, 26,  6,  ...,  6,  6,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 1, 0,  ..., 0, 0, 0],
        [0, 1, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
{&#39;text&#39;: tensor([[ 1,  4,  6,  ...,  6,  6,  6],
        [ 1,  6,  6,  ...,  6, 19,  6]]), &#39;types&#39;: tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]]), &#39;is_random&#39;: tensor([0, 1]), &#39;loss_mask&#39;: tensor([[0, 1, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 1, 0]]), &#39;labels&#39;: tensor([[1, 6, 6,  ..., 6, 6, 6],
        [1, 6, 6,  ..., 6, 6, 6]]), &#39;padding_mask&#39;: tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]]), &#39;batch&#39;: [&#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;, &#39;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#39;]}
</pre></div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="conclusion-and-further-reading">
<h1>Conclusion and further reading.<a class="headerlink" href="#conclusion-and-further-reading" title="Permalink to this headline">#</a></h1>
<p>This concludes our tutorial on including custom data in the BioNeMo framework. Throughout these tutorials we described how to manually update a model with a new dataset, and how those changes propagate throughout the framework. Checkout other Dataset classes and tokenizers in NeMo to learn about further customization.</p>
</div>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="custom-dataset-class-fw.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Adding the OAS Dataset: Modifying the Dataset Class</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="custom-dataset-preprocessing-fw.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Adding the OAS Dataset: Downloading and Preprocessing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2023-2024 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved..<br/>
    Last updated on Nov 20, 2024.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>