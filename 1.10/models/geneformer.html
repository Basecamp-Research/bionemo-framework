
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Geneformer &#8212; NVIDIA BioNeMo Framework</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/bionemo-framework/0.4.0/models/geneformer.html" />
    <link rel="shortcut icon" href="../_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MegaMolBART" href="megamolbart.html" />
    <link rel="prev" title="ESM-2nv" href="esm2-nv.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA BioNeMo Framework</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GETTING STARTED
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   What is BioNeMo?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pre-reqs.html">
   Hardware and Software Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../access-startup.html">
   Access and Startup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../initialization-guide.html">
   Initialization Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial-list.html">
   BioNeMo Framework Tutorials
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BioNeMo CORE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bionemo-fw-for-model-training-fw.html">
   Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-module-fw.html">
   Data Module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dwnstr-task-validation.html">
   Validation with a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../inference-triton-fw.html">
   Inference with Nvidia Triton Server
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-dive-esm1-pytriton-inference.html">
   Example of PyTriton Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BEST PRACTICES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../hyperparameters-fw.html">
   Hyperparameter Usage and Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../parallelism-fw.html">
   Training Parallelism
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODELS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="diffdock.html">
   DiffDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert.html">
   DNABERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dsmbind.html">
   Model Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="equidock.html">
   EquiDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm1-nv.html">
   ESM-1nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2-nv.html">
   ESM-2nv
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Geneformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="megamolbart.html">
   MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="molmim.html">
   MolMIM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openfold.html">
   OpenFold
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="prott5nv.html">
   Prott5nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model-benchmarks.html">
   Model Benchmarks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATASETS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/uniprot.html">
   UniProt Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/CELLxGENE.html">
   CELLxGENE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/zinc15.html">
   ZINC-15 Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/pdb.html">
   The Protein Data Bank (PDB)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/GRCh38.p13.html">
   Human Reference Genome Version GRCh38.p13
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/openproteinset.html">
   OpenProteinSet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/moleculenet-physchem.html">
   MoleculeNet Physical Chemistry Datasets - Lipophilicity, FreeSolv, ESOL
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TUTORIALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preprocessing-bcp-training-diffdock.html">
   DiffDock: Preparing Workspace and Data for Pre-training
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/esm2nv-mutant-design.html">
   Zero-Shot Protein Design Using ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/MMB_GenerativeAI_Inference_with_examples.html">
   BioNeMo - MegaMolBART Inferencing for Generative Chemistry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/MolMIM_GenerativeAI_local_inference_with_examples.html">
   MolMIM Inferencing for Generative Chemistry and Downstream Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/ZINC15-data-preprocessing.html">
   ZINC Training Dataset Setup for small molecule language models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/bionemo-finetuning-overview.html">
   Finetune pre-trained models in BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/cma_es_guided_molecular_optimization_molmim.html">
   MolMIM Property Guided Molecular Optimization Using CMA-ES
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/custom-dataset-class-fw.html">
   Adding the OAS Dataset: Modifying the Dataset Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/custom-dataset-dataloader.html">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/custom-dataset-preprocessing-fw.html">
   Adding the OAS Dataset: Downloading and Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/encoder-finetuning-notebook-fw.html">
   Encoder Fine-tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_diffdock.html">
   DiffDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_equidock.html">
   EquiDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_esm1nv.html">
   ESM1nv Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_esm2nv.html">
   ESM-2nv: Data Preprocessing and Model Training Using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_mmb.html">
   MegaMolBART Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/model_training_molmim.html">
   Train MolMIM from scratch on your own data using the BioNeMo Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/physchem-notebook-fw.html">
   Finetuning LLM in BioNeMo for a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/protein-esm2nv-clustering.html">
   Generating Embeddings for Protein Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/retrosynthesis-notebook.html">
   Training LLM for a Custom Downstram Task: Retrosynthesis Prediction using MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/esm2_FLIP_finetuning.html">
   Fine-Tune ESM-2nv on FLIP Data for Sequence-Level Classification, Regression, Token-Level Classification, and with LoRA Adapters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/esm2_oas_inferencing.html">
   Performing inference on OAS sequences with ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/esm2_paratope_finetuning.html">
   Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/dnabert_inference.html">
   Generating and visualizing embeddings with DNABert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks/dnabert_pretrain_finetune.html">
   Pretrain, Fine-tune, and Perform Inference with DNABERT for Splice Site Prediction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  APPENDIX
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../faq-fw.html">
   Frequently Asked Questions (FAQ)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography-fw.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../releasenotes-fw.html">
   Release Notes
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-overview">
   Model Overview
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#description">
     Description:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-architecture">
     Model Architecture:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#input">
     Input:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#output">
     Output:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-integration">
     Software Integration:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-version-s">
     Model Version(s):
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-evaluation">
   Training &amp; Evaluation:
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-dataset">
     Training Dataset:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-dataset">
   Evaluation Dataset:
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference">
     Inference:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ethical-considerations">
     Ethical Considerations:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-diagnostics">
   Training diagnostics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geneformer-10m-240530">
     geneformer-10M-240530
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geneformer-106m-240530">
     geneformer-106M-240530
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#benchmarking">
   Benchmarking
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-benchmarks">
     Accuracy Benchmarks
    </a>
    <ul class="visible nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#masked-language-model-mlm-loss">
       Masked language model (MLM) loss
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#downstream-task-accuracy">
       Downstream task accuracy
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#performance-benchmarks">
     Performance Benchmarks
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Geneformer</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-overview">
   Model Overview
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#description">
     Description:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-architecture">
     Model Architecture:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#input">
     Input:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#output">
     Output:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#software-integration">
     Software Integration:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-version-s">
     Model Version(s):
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-evaluation">
   Training &amp; Evaluation:
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-dataset">
     Training Dataset:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-dataset">
   Evaluation Dataset:
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#inference">
     Inference:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ethical-considerations">
     Ethical Considerations:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-diagnostics">
   Training diagnostics
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geneformer-10m-240530">
     geneformer-10M-240530
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#geneformer-106m-240530">
     geneformer-106M-240530
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#benchmarking">
   Benchmarking
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#accuracy-benchmarks">
     Accuracy Benchmarks
    </a>
    <ul class="visible nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#masked-language-model-mlm-loss">
       Masked language model (MLM) loss
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#downstream-task-accuracy">
       Downstream task accuracy
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#performance-benchmarks">
     Performance Benchmarks
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <div class="tex2jax_ignore mathjax_ignore section" id="geneformer">
<h1>Geneformer<a class="headerlink" href="#geneformer" title="Permalink to this headline">#</a></h1>
<div class="section" id="model-overview">
<h2>Model Overview<a class="headerlink" href="#model-overview" title="Permalink to this headline">#</a></h2>
<div class="section" id="description">
<h3>Description:<a class="headerlink" href="#description" title="Permalink to this headline">#</a></h3>
<p>Geneformer generates a dense representation of a sc-RNA cell by learning co-expression patterns within single cells. Geneformer is a tabular count model trained on sc-RNA from the Chan Zuckerberg Cell x Gene census. Geneformer computes a complete embedding for each cell over the top 1024 expressed genes. The embeddings are used as features for a variety of predictive tasks. This model is ready for both commercial and academic use.</p>
</div>
<div class="section" id="references">
<h3>References:<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Geneformer, reference foundation model for single-cell RNA: <a class="reference external" href="https://www.nature.com/articles/s41586-023-06139-9">Transfer learning enables predictions in network biology | Nature</a></p></li>
<li><p>scGPT, alternative foundation model for single-cell RNA: <a class="reference external" href="https://www.nature.com/articles/s41592-024-02201-0">scGPT: toward building a foundation model for single-cell multi-omics using generative AI | Nature Methods</a></p></li>
<li><p>scBERT, alternative foundation model for single-cell RNA: <a class="reference external" href="https://www.nature.com/articles/s42256-022-00534-z">scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data | Nature Machine Intelligence</a></p></li>
<li><p>scFoundation, alternative foundation model for single-cell RNA: <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.05.29.542705v4">Large Scale Foundation Model on Single-cell Transcriptomics | bioRxiv</a>
Cell x Gene census, public repository for sc-RNA experiments: <a class="reference external" href="https://cellxgene.cziscience.com/">CZ CELLxGENE Discover - Cellular Visualization Tool (cziscience.com)</a></p></li>
</ul>
</div>
<div class="section" id="model-architecture">
<h3>Model Architecture:<a class="headerlink" href="#model-architecture" title="Permalink to this headline">#</a></h3>
<p><strong>Architecture Type:</strong> <a class="reference external" href="https://arxiv.org/abs/1810.04805">Bidirectional Encoder Representations from Transformers (BERT)</a>  <br>
<strong>Network Architecture:</strong> <a class="reference external" href="https://rdcu.be/ddrx0">Geneformer</a> <br></p>
</div>
<div class="section" id="input">
<h3>Input:<a class="headerlink" href="#input" title="Permalink to this headline">#</a></h3>
<p><strong>Input Type(s):</strong> Number (Row represents cell, containing gene names and single cell expression counts) <br>
<strong>Input Format(s):</strong>  Array <a class="reference external" href="https://anndata.readthedocs.io/en/latest/">AnnData</a><br>
<strong>Input Parameters:</strong> 1D <br></p>
</div>
<div class="section" id="output">
<h3>Output:<a class="headerlink" href="#output" title="Permalink to this headline">#</a></h3>
<p><strong>Output Type(s):</strong> Vector (Dense Embedding Predictions)embeddings. <br>
<strong>Output Format:</strong> NumPy <br>
<strong>Output Parameters:</strong> 1D <br>
<strong>Other Properties Related to Output:</strong> Numeric floating point vector (fp16, bf16, or fp32); geneformer-10M-240530 outputs 256 dimensional embeddings; geneformer-106M-240530 outputs 768 dimensional embeddings <br></p>
</div>
<div class="section" id="software-integration">
<h3>Software Integration:<a class="headerlink" href="#software-integration" title="Permalink to this headline">#</a></h3>
<p><strong>Runtime Engine(s):</strong></p>
<ul class="simple">
<li><p>BioNeMo, NeMo 1.2 <br></p></li>
</ul>
<p><strong>Supported Hardware Microarchitecture Compatibility:</strong> <br></p>
<ul class="simple">
<li><p>Ampere <br></p></li>
<li><p>Hopper <br></p></li>
<li><p>Volta <br></p></li>
</ul>
<p><strong>[Preferred/Supported] Operating System(s):</strong> <br></p>
<ul class="simple">
<li><p>Linux <br></p></li>
</ul>
</div>
<div class="section" id="model-version-s">
<h3>Model Version(s):<a class="headerlink" href="#model-version-s" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>geneformer-10M-240530  <br></p>
<ul>
<li><p>10.3M parameter geneformer variant.</p></li>
<li><p>25429 ensemble ID based gene tokens</p></li>
<li><p>256 hidden dimensions with 4 heads, 6 layers and an 512 dimensional FFN</p></li>
<li><p>relu activation</p></li>
<li><p>1e-12 EPS layernorm</p></li>
<li><p>bf16 mixed precision training with 32 bit residual connections</p></li>
<li><p>2% hidden dropout, 10% attention dropout</p></li>
</ul>
</li>
<li><p>geneformer-106M-240530</p>
<ul>
<li><p>106M parameter geneformer variant.</p></li>
<li><p>25429 ensemble ID based gene tokens</p></li>
<li><p>768 hidden dimensions with 12 heads, 12 layers and an 3072 dimensional FFN</p></li>
<li><p>relu activation</p></li>
<li><p>1e-12 EPS layernorm</p></li>
<li><p>bf16 mixed precision training with 32 bit residual connections</p></li>
<li><p>2% hidden dropout, 10% attention dropout</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="training-evaluation">
<h2>Training &amp; Evaluation:<a class="headerlink" href="#training-evaluation" title="Permalink to this headline">#</a></h2>
<div class="section" id="training-dataset">
<h3>Training Dataset:<a class="headerlink" href="#training-dataset" title="Permalink to this headline">#</a></h3>
<p>Single cell expression counts from CELLxGENE Census used for the direct download of data matching similar criteria to those described in the geneformer publication. limiting cell data to organism=”Homo sapiens”, with a non “na” suspension_type, is_primary_data=True, and disease=”normal” to limit to non-diseased tissues that are also the primary data source per cell to make sure that cells are only included once in the download. We tracked metadata including “assay”, “sex”, “development_stage”, “tissue_general”, “dataset_id” and “self_reported_ethnicity”. The metadata “assay”, “tissue_general”, and “dataset_id” were used to construct dataset splits into train, validation, and test sets.</p>
<p>The training set represented 99% of the downloaded cells. We partitioned the data by dataset_id into a train set (99%) and a hold-out set (1%), to make sure that the hold-out datasets were independently collected single cell experiments, which helps evaluate generalizability to new future datasets.</p>
<p>In this training split, we made sure that all “assay” and “tissue_general” labels were present in the training set so that our model would have maximal visibility into different tissues and assay biases.</p>
<p>The 1% hold-out evaluation set was split further into a validation and test set. This final split was mostly done randomly by cell; however, we set aside a full dataset into the test split so that we could evaluate performance after training on a completely unseen dataset, including when monitoring the validation loss during training.</p>
<p><strong>Link:</strong> Datasets downloaded from <a class="reference external" href="https://cellxgene.cziscience.com/">CZ CELLxGENE Discover - Cellular Visualization Tool (cziscience.com)</a> <br>
** Data Collection Method by dataset <br></p>
<ul class="simple">
<li><p>[Human] <br></p></li>
</ul>
<p>** Labeling Method by dataset <br></p>
<ul class="simple">
<li><p>Hybrid: Automated, Human <br></p></li>
</ul>
<p><strong>Properties (Quantity, Dataset Descriptions, Sensor(s)):</strong>
23.64 million non-diseased and human-derived single cells were chosen from the CZI CELLxGENE census, which is characterized as follows:  <br></p>
<ul class="simple">
<li><p>Assay Bias:</p>
<ul>
<li><p>The vast majority of the dataset is one of the 10x genomics assays, Approximately 20M of 26M cells are genomic assays, 4M are sci-RNA-seq, while Remaining assays (microwell-seq, drop-seq, bd rhapsody, smart-seq, seq-well, and MARS-seq) represent small fractions of the full datasets.</p></li>
</ul>
</li>
<li><p>Sex:</p>
<ul>
<li><p>12.5M are male-derived cells; 10M are female  derived cells. The remaining cells are not annotated.</p></li>
</ul>
</li>
<li><p>Self-Reported Ethnicity:</p>
<ul>
<li><p>Approximately 12M cells are not annotated; 9M are annotated as “European.” .5M are annotated as “Han Chinese.” followed by “African American”.</p></li>
</ul>
</li>
<li><p>Age Bias:</p>
<ul>
<li><p>The dataset is heavily biased toward donors less than one year. The next highest group would be the segment that includes ages 21-30.</p></li>
</ul>
</li>
<li><p>Tissue Type Bias:</p>
<ul>
<li><p>9M cells are “brain” derived. 4M are blood derived, followed by “lung”, “breast”, “heart” and “eye” at approximately 1M cells each.</p></li>
</ul>
</li>
</ul>
<p>Dataset was derived from a limited number of public sources where methods and protocols may not represent sufficiently diverse sources to capture the full scope of gene expression.</p>
</div>
</div>
<div class="section" id="evaluation-dataset">
<h2>Evaluation Dataset:<a class="headerlink" href="#evaluation-dataset" title="Permalink to this headline">#</a></h2>
<p>Adamson et al 2016 PERTURB-seq dataset, accessed by Harvard dataverse.
<strong>Link:</strong>  <a class="reference external" href="https://dataverse.harvard.edu/file.xhtml?fileId=6154417">adamson.zip - Harvard Dataverse</a> <br>
** Data Collection Method by dataset <br></p>
<ul class="simple">
<li><p>Human <br></p></li>
</ul>
<p>** Labeling Method by dataset <br></p>
<ul class="simple">
<li><p>Automated - Molecular Barcoding <br></p></li>
</ul>
<p><strong>Properties (Quantity, Dataset Descriptions, Sensor(s)):</strong> There are ~20k single cells, half of which represent unperturbed control samples, and the other half which contain an additional datatable containing the CRISPR knock-out targets for each cell.</p>
<p><strong>Link:</strong> <a class="reference external" href="https://cellxgene.cziscience.com/">CZ CELLxGENE Discover - Cellular Visualization Tool (cziscience.com)</a> <br>
** Data Collection Method by dataset <br></p>
<ul class="simple">
<li><p>Human <br></p></li>
</ul>
<p>** Labeling Method by dataset <br></p>
<ul class="simple">
<li><p>Hybrid: Automated, Human <br></p></li>
</ul>
<p><strong>Properties (Quantity, Dataset Descriptions, Sensor(s)):</strong></p>
<ul class="simple">
<li><p>240,000 single cells were chosen from the CZI cell x gene census such that they did not share a <code class="docutils literal notranslate"><span class="pre">dataset_id</span></code> with any cell in the training data described previously.</p></li>
</ul>
<div class="section" id="inference">
<h3>Inference:<a class="headerlink" href="#inference" title="Permalink to this headline">#</a></h3>
<p><strong>Engine:</strong> BioNeMo, NeMo <br>
<strong>Test Hardware:</strong> <br></p>
<ul class="simple">
<li><p>Ampere <br></p></li>
<li><p>Hopper <br></p></li>
<li><p>Volta  <br></p></li>
</ul>
<p>*Additional description content may be included here</p>
</div>
<div class="section" id="ethical-considerations">
<h3>Ethical Considerations:<a class="headerlink" href="#ethical-considerations" title="Permalink to this headline">#</a></h3>
<p>NVIDIA believes Trustworthy AI is a shared responsibility and we have established policies and practices to enable development for a wide array of AI applications.  When downloaded or used in accordance with our terms of service, developers should work with their internal team to ensure this model meets requirements for the relevant industry and use case and addresses unforeseen product misuse.  For more detailed information on ethical considerations for this model, please see the Model Card++ Explainability, Bias, Safety &amp; Security, and Privacy Subcards [Insert Link to Model Card++ here].  Please report security vulnerabilities or NVIDIA AI Concerns <a class="reference external" href="https://www.nvidia.com/en-us/support/submit-security-vulnerability/">here</a>.</p>
</div>
</div>
<div class="section" id="training-diagnostics">
<h2>Training diagnostics<a class="headerlink" href="#training-diagnostics" title="Permalink to this headline">#</a></h2>
<div class="section" id="geneformer-10m-240530">
<h3>geneformer-10M-240530<a class="headerlink" href="#geneformer-10m-240530" title="Permalink to this headline">#</a></h3>
<p>This checkpoint was trained for approximately 11 epochs through the CELLxGENE split. Training was performed on 8 servers with 8 A100 GPUs each for a total of 115430 steps of per-gpu micro batch size 32 and global batch size of 2048. Training took a total of 1 day, 20 hours and 19 minutes of wallclock time. As can be seen in the following image, training and validation curves both decreased fairly smoothly throughout the course of training. In fact validation (blue) and training (orange) loss were both still decreasing at the end of 11 epochs through the dataset. The model could likely be trained for more epochs without overfitting.
<img alt="Validation and training losses both decreased smoothly through training" src="../_images/geneformer-10m-240530-val-train-loss.png" /></p>
</div>
<div class="section" id="geneformer-106m-240530">
<h3>geneformer-106M-240530<a class="headerlink" href="#geneformer-106m-240530" title="Permalink to this headline">#</a></h3>
<p>This checkpoint was trained for approximately 11 epochs through the CELLxGENE split. Training was performed on 16 servers with 8 A100 GPUs each for a total of 115430 steps of per-gpu micro batch size 16 and global batch size of 2048. Training took a total of 3 days, 18  hours and 55 minutes of wallclock time. As can be seen in the following image, training and validation curves both decreased fairly smoothly throughout the course of training. In fact validation (blue) and training (orange) loss were both still decreasing at the end of 11 epochs through the dataset. The model could likely be trained for more epochs without overfitting.
<img alt="Validation and training losses both decreased smoothly through training" src="../_images/geneformer-106m-240530-val-train-loss.png" /></p>
<p>Additionally, validation loss decreased both faster and continued to decrease at the same improved rate throughout training in the 106M parameter model (red) as compared to the 10M parameter model (blue). It would be interesting to test even larger models to see if we continue to observe improved performance in larger models.
<img alt="106M parameter model outperformed 10M parameter model" src="../_images/geneformer-240530-val-comparison.png" /></p>
</div>
</div>
<div class="section" id="benchmarking">
<h2>Benchmarking<a class="headerlink" href="#benchmarking" title="Permalink to this headline">#</a></h2>
<div class="section" id="accuracy-benchmarks">
<h3>Accuracy Benchmarks<a class="headerlink" href="#accuracy-benchmarks" title="Permalink to this headline">#</a></h3>
<div class="section" id="masked-language-model-mlm-loss">
<h4>Masked language model (MLM) loss<a class="headerlink" href="#masked-language-model-mlm-loss" title="Permalink to this headline">#</a></h4>
<p>The following describes the bert MLM token loss. Like in the original BERT paper, and the geneformer paper, 15% of all tokens are included in the loss. Of the included tokens, 80% are <code class="docutils literal notranslate"><span class="pre">&quot;[MASK]&quot;</span></code> token, 2% are a random gene token, and 18% are the correct output token. Note that this was an unintentional deviation from the original publication, but so far it seems to be working well. In the future we will test the intended 80%/10%/10% mixture proposed in the paper. The token loss in the following table is the mean cross entropy loss of the 15% of tokens included in the loss mask averaged across cells. As a baseline geneformer was downloaded from <a class="reference external" href="https://huggingface.co/ctheodoris/Geneformer">the ctheodoris/Geneformer page on hugging face on 2024/05/13</a> and applied to the same masking/unmasking problem on this dataset. The held-out <code class="docutils literal notranslate"><span class="pre">test</span></code> datset from our training splits described previously was used, and it should be noted that some of these cells may have been involved in training the baseline geneformer. Since the baseline performed slightly worse than our new checkpoints, and our goal was an equivalent or better model checkpoint, this possibility was not explored further.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Model Description</p></th>
<th class="head"><p>Token Loss (lower is better)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Baseline geneformer</p></td>
<td><p>3.35</p></td>
</tr>
<tr class="row-odd"><td><p>geneformer-10M-240530</p></td>
<td><p>2.79</p></td>
</tr>
<tr class="row-even"><td><p>geneformer-106M-240530</p></td>
<td><p>2.50</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="downstream-task-accuracy">
<h4>Downstream task accuracy<a class="headerlink" href="#downstream-task-accuracy" title="Permalink to this headline">#</a></h4>
<p>Here we benchmark four models, with two baselines. These models are tasked with cell type classification, using the Chron’s disease small intestine dataset from
Elmentaite et al. (2020), Developmental Cell. This dataset contains approximately 22,500 single cells from both healthy children aged 4-13 and chidlren with Chron’s disease. This dataset contains 31 unique cell types which we assume to be annotated accurately. This dataset was held out of our pre-training dataset as all diseased samples were removed.</p>
<ul class="simple">
<li><p>Baseline 1) scRNA workflow: this model uses PCA with 10 components and random forest on normalized and log transformed expression counts to produce a result.</p></li>
<li><p>Baseline 2) geneformer-qa, a model trained for approximately 100 steps with approximately random weights. We expect this model to perform no differently than working on counts directly.</p></li>
<li><p>geneformer-10M-240530 and geneformer-106M-240530 as described above.</p></li>
</ul>
<p>For more details see the example notebook titled Geneformer-celltype-classification-example.ipynb</p>
<p><img alt="F1-score for both released models, a random baseline, and a PCA based transformation of the raw expression." src="../_images/F1-score-models.png" />
<img alt="Average accuracy across cell types for both released models, a random baseline, and a PCA based transformation of the raw expression." src="../_images/average-accuracy-models.png" /></p>
</div>
</div>
<div class="section" id="performance-benchmarks">
<h3>Performance Benchmarks<a class="headerlink" href="#performance-benchmarks" title="Permalink to this headline">#</a></h3>
<p>The 106M parameter variant of Geneformer achieves over 50 TFLOPS per GPU during training. This is consistent whether trained with 1 or 8 A100s.</p>
<p><img alt="TFLOPs per GPU (A100) shows improved utilization by 106M variant" src="../_images/model_tflops_per_gpu_chart_tight_layout.png" /></p>
</div>
</div>
</div>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="esm2-nv.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">ESM-2nv</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="megamolbart.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MegaMolBART</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2023-2024 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved..<br/>
    Last updated on Oct 17, 2024.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>