
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Zero-Shot Protein Design Using ESM-2nv &#8212; NVIDIA BioNeMo Framework</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/bionemo-framework/0.4.0/notebooks/esm2nv-mutant-design.html" />
    <link rel="shortcut icon" href="../_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="BioNeMo - MegaMolBART Inferencing for Generative Chemistry" href="MMB_GenerativeAI_Inference_with_examples.html" />
    <link rel="prev" title="DiffDock: Preparing Workspace and Data for Pre-training" href="../preprocessing-bcp-training-diffdock.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA BioNeMo Framework</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GETTING STARTED
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   What is BioNeMo?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pre-reqs.html">
   Hardware and Software Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../access-startup.html">
   Access and Startup
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../initialization-guide.html">
   Initialization Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tutorial-list.html">
   BioNeMo Framework Tutorials
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BioNeMo CORE
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bionemo-fw-for-model-training-fw.html">
   Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../data-module-fw.html">
   Data Module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dwnstr-task-validation.html">
   Validation with a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../inference-triton-fw.html">
   Inference with Nvidia Triton Server
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep-dive-esm1-pytriton-inference.html">
   Example of PyTriton Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  BEST PRACTICES
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../hyperparameters-fw.html">
   Hyperparameter Usage and Tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../parallelism-fw.html">
   Training Parallelism
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODELS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../models/diffdock.html">
   DiffDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dnabert.html">
   DNABERT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/dsmbind.html">
   Model Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/equidock.html">
   EquiDock
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm1-nv.html">
   ESM-1nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/esm2-nv.html">
   ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/geneformer.html">
   Geneformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/megamolbart.html">
   MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/molmim.html">
   MolMIM
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/openfold.html">
   OpenFold
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/prott5nv.html">
   Prott5nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../models/model-benchmarks.html">
   Model Benchmarks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DATASETS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/uniprot.html">
   UniProt Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/CELLxGENE.html">
   CELLxGENE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/zinc15.html">
   ZINC-15 Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/pdb.html">
   The Protein Data Bank (PDB)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/GRCh38.p13.html">
   Human Reference Genome Version GRCh38.p13
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/openproteinset.html">
   OpenProteinSet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../datasets/moleculenet-physchem.html">
   MoleculeNet Physical Chemistry Datasets - Lipophilicity, FreeSolv, ESOL
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TUTORIALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../preprocessing-bcp-training-diffdock.html">
   DiffDock: Preparing Workspace and Data for Pre-training
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Zero-Shot Protein Design Using ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MMB_GenerativeAI_Inference_with_examples.html">
   BioNeMo - MegaMolBART Inferencing for Generative Chemistry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MolMIM_GenerativeAI_local_inference_with_examples.html">
   MolMIM Inferencing for Generative Chemistry and Downstream Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ZINC15-data-preprocessing.html">
   ZINC Training Dataset Setup for small molecule language models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bionemo-finetuning-overview.html">
   Finetune pre-trained models in BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cma_es_guided_molecular_optimization_molmim.html">
   MolMIM Property Guided Molecular Optimization Using CMA-ES
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-class-fw.html">
   Adding the OAS Dataset: Modifying the Dataset Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-dataloader.html">
   Adding the OAS Dataset: Customizing Dataset Object and Dataloader Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="custom-dataset-preprocessing-fw.html">
   Adding the OAS Dataset: Downloading and Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="encoder-finetuning-notebook-fw.html">
   Encoder Fine-tuning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_diffdock.html">
   DiffDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_equidock.html">
   EquiDock Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm1nv.html">
   ESM1nv Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_esm2nv.html">
   ESM-2nv: Data Preprocessing and Model Training Using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_mmb.html">
   MegaMolBART Model Training using BioNeMo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_training_molmim.html">
   Train MolMIM from scratch on your own data using the BioNeMo Framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="physchem-notebook-fw.html">
   Finetuning LLM in BioNeMo for a Downstream Task
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protein-esm2nv-clustering.html">
   Generating Embeddings for Protein Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="retrosynthesis-notebook.html">
   Training LLM for a Custom Downstram Task: Retrosynthesis Prediction using MegaMolBART
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_FLIP_finetuning.html">
   Fine-Tune ESM-2nv on FLIP Data for Sequence-Level Classification, Regression, Token-Level Classification, and with LoRA Adapters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_oas_inferencing.html">
   Performing inference on OAS sequences with ESM-2nv
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="esm2_paratope_finetuning.html">
   Pretrain from Scratch, Continue Training from an Existing Checkpoint, and Fine-tune ESM-2nv on Custom Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_inference.html">
   Generating and visualizing embeddings with DNABert
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dnabert_pretrain_finetune.html">
   Pretrain, Fine-tune, and Perform Inference with DNABERT for Splice Site Prediction
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  APPENDIX
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../faq-fw.html">
   Frequently Asked Questions (FAQ)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography-fw.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../releasenotes-fw.html">
   Release Notes
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-objectives">
   Demo Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-required-libraries">
     Import Required Libraries
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#home-directory">
     Home Directory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-model-checkpoints">
     Download Model Checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#esm-2nv-inference">
   ESM-2nv Inference
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-configurations">
     Load Configurations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#esm-2nv-inference-functions">
     ESM-2nv Inference Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#obtaining-model-outputs-logits-and-probabilities">
   Obtaining Model Outputs (Logits and Probabilities)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#language-model-head">
     Language Model Head
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizer">
     Tokenizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extract-logits-and-probabilities">
     Extract Logits and Probabilities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mutant-design-through-esm-2nv">
   Mutant Design through ESM-2nv
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-masking">
     Sequential Masking
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extraction-of-probabilities">
     Extraction of Probabilities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#amino-acid-heatmap">
     Amino Acid Heatmap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mutant-discovery">
     Mutant Discovery
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Zero-Shot Protein Design Using ESM-2nv</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-objectives">
   Demo Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#background">
   Background
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-required-libraries">
     Import Required Libraries
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#home-directory">
     Home Directory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#download-model-checkpoints">
     Download Model Checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#esm-2nv-inference">
   ESM-2nv Inference
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-configurations">
     Load Configurations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#esm-2nv-inference-functions">
     ESM-2nv Inference Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#obtaining-model-outputs-logits-and-probabilities">
   Obtaining Model Outputs (Logits and Probabilities)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#language-model-head">
     Language Model Head
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizer">
     Tokenizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extract-logits-and-probabilities">
     Extract Logits and Probabilities
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mutant-design-through-esm-2nv">
   Mutant Design through ESM-2nv
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-masking">
     Sequential Masking
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extraction-of-probabilities">
     Extraction of Probabilities
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#amino-acid-heatmap">
     Amino Acid Heatmap
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mutant-discovery">
     Mutant Discovery
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <div class="tex2jax_ignore mathjax_ignore section" id="zero-shot-protein-design-using-esm-2nv">
<h1>Zero-Shot Protein Design Using ESM-2nv<a class="headerlink" href="#zero-shot-protein-design-using-esm-2nv" title="Permalink to this headline">#</a></h1>
<p><em>We thank Adrian Lange from A-Alpha Bio for originally contributing this recipe. This notebook has since been modified by NVIDIA.</em></p>
<div class="alert alert-block alert-info"> <b>NOTE</b> Note: This notebook has been tested on a single A100, and is compatible with BioNeMo Framework v1.7 and v1.8. The expected runtime is ~3 minutes on an A100, and less than 1 hour on an A1000.</div><div class="section" id="demo-objectives">
<h2>Demo Objectives<a class="headerlink" href="#demo-objectives" title="Permalink to this headline">#</a></h2>
<ol class="arabic simple">
<li><p><strong>ESM-2nv Inference Functionality</strong></p>
<ul class="simple">
<li><p>Objective: Perform inference on the pre-trained ESM-2nv model.</p></li>
<li><p>Steps: Download model checkpoints, instantiate an inference object, and generate hidden state representations and sequence embeddings from input protein sequences.</p></li>
</ul>
</li>
<li><p><strong>Logit and Probability Extraction</strong></p>
<ul class="simple">
<li><p>Objective: Obtain probability values of all possible tokens at each position in the amino acid sequence.</p></li>
<li><p>Steps: Access the BERT language model head, generate logits from hidden states, and transform them into probabilities.</p></li>
</ul>
</li>
<li><p><strong>Protein Mutant Design</strong></p>
<ul class="simple">
<li><p>Objective: Optimize an input protein sequence to align it more closely with naturally occurring protein variants.</p></li>
<li><p>Steps: Sequentially mask amino acids, extract per-position probabilities (and create a heatmap), analyze positions where single-point mutants have higher likelihood than wild-type, and develop new candidates.</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">#</a></h2>
<p>ESM-2nv is a large-scale protein language model (PLM) trained on millions of protein sequences. It can capture complex patterns and relationships in protein sequences, allowing it to be used to predict likely amino acid substitutions at different positions. By leveraging ESM-2nv’s masked language modeling (MLM) capabilities, we can identify potential mutations that may enhance a protein’s properties or align it more closely with naturally occurring variants. ESM-2nv has 650M and 3B parameter versions - for this demo, we will be using ESM-2nv 3B.</p>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h2>
<p>Ensure you have read through the <a class="reference external" href="https://docs.nvidia.com/bionemo-framework/latest/">Getting Started</a> section, can run the BioNeMo Framework docker container, and have configured the NGC Command Line Interface (CLI) within the container. It is assumed that this notebook is being executed from within the container. Additionally, this tutorial depends on the <a class="reference external" href="https://docs.nvidia.com/bionemo-framework/latest/models/esm2-nv.html">ESM-2nv</a> model.</p>
<div class="alert alert-block alert-info"> <b>NOTE</b> Some of the cells below generate long text output. We're using <pre>%%capture --no-display --no-stderr cell_output</pre> to suppress this output. Comment or delete this line in the cells below to restore full output.</div><div class="section" id="import-required-libraries">
<h3>Import Required Libraries<a class="headerlink" href="#import-required-libraries" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display --no-stderr cell_output

<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">bionemo.utils.hydra</span> <span class="kn">import</span> <span class="n">load_model_config</span>
<span class="kn">from</span> <span class="nn">bionemo.model.protein.esm1nv.infer</span> <span class="kn">import</span> <span class="n">ESM1nvInference</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="home-directory">
<h3>Home Directory<a class="headerlink" href="#home-directory" title="Permalink to this headline">#</a></h3>
<p>Set the home directory as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bionemo_home</span> <span class="o">=</span> <span class="s2">&quot;/workspace/bionemo&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;BIONEMO_HOME&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bionemo_home</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-model-checkpoints">
<h3>Download Model Checkpoints<a class="headerlink" href="#download-model-checkpoints" title="Permalink to this headline">#</a></h3>
<p>The following code will download the pre-trained model, <code class="docutils literal notranslate"><span class="pre">esm2nv_3B_converted.nemo</span></code>, from the NGC registry:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the NGC CLI API KEY and ORG for the model download</span>
<span class="c1"># If these variables are not already set in the container, uncomment below to define and set API KEY and ORG</span>
<span class="c1"># api_key = &lt;YOUR_API_KEY&gt;</span>
<span class="c1"># ngc_cli_org = &lt;YOUR_ORG&gt;</span>
<span class="c1"># Update the environment variable</span>
<span class="c1"># os.environ[&#39;NGC_CLI_API_KEY&#39;] = api_key</span>
<span class="c1"># os.environ[&#39;NGC_CLI_ORG&#39;] = ngc_cli_org</span>

<span class="c1"># Set variables and paths for model and checkpoint</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;esm2nv&quot;</span>
<span class="n">model_version</span> <span class="o">=</span> <span class="s2">&quot;esm2nv_3b&quot;</span> <span class="c1"># for ESM-2nv 650M, write &quot;esm2nv_650m&quot;</span>
<span class="n">actual_checkpoint_name</span> <span class="o">=</span> <span class="s2">&quot;esm2nv_3B_converted.nemo&quot;</span> <span class="c1"># for ESM-2nv 650M, write &quot;esm2nv_650M_converted.nemo&quot;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">)</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">actual_checkpoint_name</span><span class="p">)</span>
<span class="n">config_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">bionemo_home</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;examples/protein/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">/conf&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MODEL_PATH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_path</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%capture --no-display --no-stderr cell_output

if not os.path.exists(checkpoint_path):
    !python download_artifacts.py --model_dir ${BIONEMO_HOME}/models --models esm2nv_3b
else:
    print(f&quot;Model {model_version} already exists at {model_path}.&quot;)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="esm-2nv-inference">
<h2>ESM-2nv Inference<a class="headerlink" href="#esm-2nv-inference" title="Permalink to this headline">#</a></h2>
<p>In this section, we will explore the key inference functionalities of the pre-trained model.</p>
<div class="section" id="load-configurations">
<h3>Load Configurations<a class="headerlink" href="#load-configurations" title="Permalink to this headline">#</a></h3>
<p>Here, we initiate an inferer of class <code class="docutils literal notranslate"><span class="pre">ESM1nvInference</span></code> (note that ESM-1nv and ESM-2nv share an inference class) and point it to a YAML file with base configurations for ESM-2nv inference. Some key configurations include:</p>
<ul class="simple">
<li><p>The desired checkpoints path (<code class="docutils literal notranslate"><span class="pre">esm2nv_3B_converted.nemo</span></code>)</p></li>
<li><p>The HuggingFace tokenizer (<code class="docutils literal notranslate"><span class="pre">facebook/esm2_t36_3B_UR50D</span></code>)</p></li>
<li><p>The model class (<code class="docutils literal notranslate"><span class="pre">ESM2nvModel</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display --no-stderr cell_output

<span class="c1"># Load starting config for ESM2nv inference</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">load_model_config</span><span class="p">(</span><span class="n">config_name</span> <span class="o">=</span> <span class="s2">&quot;infer.yaml&quot;</span><span class="p">,</span> <span class="n">config_path</span> <span class="o">=</span> <span class="n">config_path</span><span class="p">)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;facebook/esm2_t36_3B_UR50D&quot;</span> <span class="c1"># for ESM-2nv 650M, write &quot;facebook/esm2_t33_650M_UR50D&quot;</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">downstream_task</span><span class="o">.</span><span class="n">restore_from_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span>

<span class="c1"># Create model object based on desired configuration</span>
<span class="n">inferer</span> <span class="o">=</span> <span class="n">ESM1nvInference</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">interactive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="esm-2nv-inference-functions">
<h3>ESM-2nv Inference Functions<a class="headerlink" href="#esm-2nv-inference-functions" title="Permalink to this headline">#</a></h3>
<p>Note that <code class="docutils literal notranslate"><span class="pre">inferer</span></code> is an object of the <code class="docutils literal notranslate"><span class="pre">ESM1nvInference</span></code> class, which contains the functionalities of <code class="docutils literal notranslate"><span class="pre">seq_to_hiddens()</span></code>, <code class="docutils literal notranslate"><span class="pre">hiddens_to_embedding()</span></code>, and <code class="docutils literal notranslate"><span class="pre">seq_to_embeddings()</span></code>. Because ESM-2nv is BERT-based (encoder-only), <code class="docutils literal notranslate"><span class="pre">hiddens_to_seq()</span></code> functionality is not available.</p>
<p><code class="docutils literal notranslate"><span class="pre">seq_to_hiddens()</span></code>: This function queries the model to fetch the encoder hidden states for the input protein sequences. Along with <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code>, <code class="docutils literal notranslate"><span class="pre">pad_masks</span></code> is returned and contains padding information. Note that the expected input to <code class="docutils literal notranslate"><span class="pre">seq_to_hiddens()</span></code> is a list.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seqs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;</span><span class="p">,</span> <span class="c1"># length: 41</span>
    <span class="s1">&#39;MIQSQINRNIRLDLADAILLSKAKKDLSFAEIADGTGLA&#39;</span><span class="p">,</span> <span class="c1"># length: 39</span>
<span class="p">]</span>

<span class="n">hidden_states</span><span class="p">,</span> <span class="n">pad_masks</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">seq_to_hiddens</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pad_masks</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>hidden_states.shape=torch.Size([2, 43, 2560])
pad_masks.shape=torch.Size([2, 43])
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">hiddens_to_embedding()</span></code>: This function converts the hidden states (which are usually the output of each layer in a neural network) into fixed-size vector embeddings. This is done by removing the hidden state vectors corresponding to padding tokens, then averaging across the rest. This process is often used when the goal is to create a single vector representation from the hidden states of a model, which can be used for various sequence-level downstream tasks such as classification (e.g. subcellular localization) or regression (e.g. melting temperature prediction).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">hiddens_to_embedding</span><span class="p">(</span><span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">enc_mask</span> <span class="o">=</span> <span class="n">pad_masks</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>embeddings.shape=torch.Size([2, 2560])
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">seq_to_embeddings()</span></code>: This function takes input sequences and directly obtains their embeddings from the model. This is a more end-to-end approach that handles the entire process of converting raw input (like text) into vector embeddings. The key difference is that <code class="docutils literal notranslate"><span class="pre">hiddens_to_embedding()</span></code> works with already processed hidden states, while <code class="docutils literal notranslate"><span class="pre">seq_to_embeddings()</span></code> starts with raw input sequences and produces the final embeddings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">seq_to_embeddings</span><span class="p">(</span><span class="n">seqs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>embeddings.shape=torch.Size([2, 2560])
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="obtaining-model-outputs-logits-and-probabilities">
<h2>Obtaining Model Outputs (Logits and Probabilities)<a class="headerlink" href="#obtaining-model-outputs-logits-and-probabilities" title="Permalink to this headline">#</a></h2>
<p>ESM-2nv was trained with a Masked Language Modeling (MLM) objective. Thus, we are able to mask a position in an amino acid sequence and obtain values for the most probable amino acids at that position, based on the surrounding context. Let’s sequentially obtain these values for every position in the sequence.</p>
<div class="section" id="language-model-head">
<h3>Language Model Head<a class="headerlink" href="#language-model-head" title="Permalink to this headline">#</a></h3>
<p>The model architecture is broken down into two components, the language model (which primarily consists of the input embedding and transformer encoder layers), and the model head. When extracting embeddings, we generally take the outputs of the final layer of the encoder. In our case, the model head is important because it is responsible for generating output predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inferer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lm_head</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BertLMHead(
  (dense): Linear(in_features=2560, out_features=2560, bias=True)
  (layernorm): MixedFusedLayerNorm(torch.Size([2560]), eps=1e-05, elementwise_affine=True)
)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tokenizer">
<h3>Tokenizer<a class="headerlink" href="#tokenizer" title="Permalink to this headline">#</a></h3>
<p>Let’s also check the tokenizer vocabulary, stemming from <a class="reference external" href="https://huggingface.co/facebook/esm2_t36_3B_UR50D/blob/main/vocab.txt">HuggingFace</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> unique tokens: </span><span class="si">{</span><span class="n">tokens</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>There are 33 unique tokens: [&#39;&lt;cls&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;eos&gt;&#39;, &#39;&lt;unk&gt;&#39;, &#39;L&#39;, &#39;A&#39;, &#39;G&#39;, &#39;V&#39;, &#39;S&#39;, &#39;E&#39;, &#39;R&#39;, &#39;T&#39;, &#39;I&#39;, &#39;D&#39;, &#39;P&#39;, &#39;K&#39;, &#39;Q&#39;, &#39;N&#39;, &#39;F&#39;, &#39;Y&#39;, &#39;M&#39;, &#39;H&#39;, &#39;W&#39;, &#39;C&#39;, &#39;X&#39;, &#39;B&#39;, &#39;U&#39;, &#39;Z&#39;, &#39;O&#39;, &#39;.&#39;, &#39;-&#39;, &#39;&lt;null_1&gt;&#39;, &#39;&lt;mask&gt;&#39;].
</pre></div>
</div>
</div>
</div>
<p>Let’s set aside the tokens corresponding to the 20 known amino acids.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">aa_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;L&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;V&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;P&#39;</span><span class="p">,</span> <span class="s1">&#39;K&#39;</span><span class="p">,</span> <span class="s1">&#39;Q&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">]</span>

<span class="n">aa_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">aa_tokens</span><span class="p">]</span>
<span class="n">extra_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">aa_tokens</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="extract-logits-and-probabilities">
<h3>Extract Logits and Probabilities<a class="headerlink" href="#extract-logits-and-probabilities" title="Permalink to this headline">#</a></h3>
<p>By passing the hidden state of an amino acid sequence through the BERT language model head, we can obtain output logits at each position and transform them into probabilities.</p>
<p>Checking <code class="docutils literal notranslate"><span class="pre">type(inferer.model.model.lm_head)</span></code> shows that the language model head is a <code class="docutils literal notranslate"><span class="pre">BertLMHead</span></code> object, with source code stemming from within the <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/nlp/models/language_modeling/megatron/bert/bert_model.py">NeMo NLP Collection</a>. The forward pass of the model head takes in two arguments, a <code class="docutils literal notranslate"><span class="pre">hidden_states</span></code> tensor and <code class="docutils literal notranslate"><span class="pre">word_embeddings_weight</span></code> matrix. The embedding weight matrix has a dimension of 128, with the first 33 positions corresponding to the amino acid vocabulary, followed by 95 paddings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hidden_states_to_probs</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">pad_masks</span><span class="p">):</span>
    
    <span class="c1"># Setup</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">logits_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">probas_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Perform batch inference</span>
    <span class="n">lm_out</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">inferer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">word_embeddings_weight</span><span class="p">())</span>

    <span class="c1"># Sequentially convert LM outputs to logits and then probabilities</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">lm_out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">pad_masks</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:</span><span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span>
        <span class="n">logits</span><span class="p">[:,</span> <span class="n">extra_indices</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span> <span class="c1"># force non-amino acid token probabilities to zero</span>
        <span class="n">logits_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="c1"># probas.sum(axis=1) # check that rows sum to 1</span>
        <span class="n">probas_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probas</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">probas_list</span> <span class="c1"># optionally also return logits_list</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="mutant-design-through-esm-2nv">
<h2>Mutant Design through ESM-2nv<a class="headerlink" href="#mutant-design-through-esm-2nv" title="Permalink to this headline">#</a></h2>
<p>In this section, we aim to optimize an input protein sequence by introducing single-point mutations that align it more closely with naturally occurring protein variants. These mutants may present properties that enhance the protein’s functionality, such as improved stability or increased catalytic activity. By leveraging ESM-2nv’s masked language modeling capabilities, we can identify amino acid substitutions with higher likelihood than the wild-type residues. This approach allows us to explore the protein sequence space efficiently, potentially discovering variants with superior characteristics.</p>
<div class="section" id="sequential-masking">
<h3>Sequential Masking<a class="headerlink" href="#sequential-masking" title="Permalink to this headline">#</a></h3>
<p>Let’s take a starting sequence and scan through the positions, iteratively placing a <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token in place of the existing amino acid at each position. We will then predict probabilities at each masked location. If you only want to analyze substitutions within a predefined portion of the sequence (e.g. a specific alpha helix), you can set <code class="docutils literal notranslate"><span class="pre">start_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">end_pos</span></code> accordingly, below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seq</span> <span class="o">=</span> <span class="s1">&#39;MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;</span> <span class="c1"># length: 41</span>

<span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">end_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span><span class="p">)</span>

<span class="n">sequentially_masked</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">:</span>
    <span class="n">masked</span> <span class="o">=</span> <span class="n">seq</span><span class="p">[:</span><span class="n">index</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;&lt;mask&gt;&quot;</span> <span class="o">+</span> <span class="n">seq</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">sequentially_masked</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">masked</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the first few elements of <code class="docutils literal notranslate"><span class="pre">sequentially_masked</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequentially_masked</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;&lt;mask&gt;SLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;,
 &#39;M&lt;mask&gt;LKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;,
 &#39;MS&lt;mask&gt;KRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;,
 &#39;MSL&lt;mask&gt;RKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;,
 &#39;MSLK&lt;mask&gt;KNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL&#39;]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="extraction-of-probabilities">
<h3>Extraction of Probabilities<a class="headerlink" href="#extraction-of-probabilities" title="Permalink to this headline">#</a></h3>
<p>We now extract the probability matrix for each element of <code class="docutils literal notranslate"><span class="pre">sequentially_masked</span></code>, which can easily be done based on the <code class="docutils literal notranslate"><span class="pre">hidden_states_to_probs()</span></code> function we defined above. We can then select the probability vectors corresponding to the masked positions, and combine them into a final probability matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract probabilities</span>
<span class="n">masked_seq_hiddens</span><span class="p">,</span> <span class="n">masked_seq_pads</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">seq_to_hiddens</span><span class="p">(</span><span class="n">sequentially_masked</span><span class="p">)</span>
<span class="n">probas_list</span> <span class="o">=</span> <span class="n">hidden_states_to_probs</span><span class="p">(</span><span class="n">masked_seq_hiddens</span><span class="p">,</span> <span class="n">masked_seq_pads</span><span class="p">)</span> <span class="c1"># length of seq</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;masked_seq_hiddens:&quot;</span><span class="p">,</span> <span class="n">masked_seq_hiddens</span><span class="o">.</span><span class="n">shape</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;masked_seq_pads.shape:&quot;</span><span class="p">,</span> <span class="n">masked_seq_pads</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Select and combine probabilities corresponding to each mask</span>
<span class="n">probas_stack</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">probas_list</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">probas_final</span> <span class="o">=</span> <span class="n">probas_stack</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">probas_stack</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">positions</span><span class="p">,</span> <span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;probas_stack:&quot;</span><span class="p">,</span> <span class="n">probas_stack</span><span class="o">.</span><span class="n">shape</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;probas_final.shape:&quot;</span><span class="p">,</span> <span class="n">probas_final</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>masked_seq_hiddens: torch.Size([41, 43, 2560])
masked_seq_pads.shape: torch.Size([41, 43])
probas_stack: (41, 41, 33)
probas_final.shape: (41, 33)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="amino-acid-heatmap">
<h3>Amino Acid Heatmap<a class="headerlink" href="#amino-acid-heatmap" title="Permalink to this headline">#</a></h3>
<p>Let’s visualize the results. We can plot the predicted probabilities of each token across all positions of interest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create heatmap</span>
<span class="n">dat</span> <span class="o">=</span> <span class="n">probas_final</span><span class="p">[:,</span> <span class="n">aa_indices</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">dat</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1"># Add color scale</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">270</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="c1"># Set y-axis labels (amino acid tokens) and x-axis labels (position in sequence)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">aa_tokens</span><span class="p">)),</span> <span class="n">labels</span><span class="o">=</span><span class="n">aa_tokens</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>

<span class="c1"># Add axes titles and main title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position in Sequence&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Token Labels&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Positional Token Probabilities&#39;</span><span class="p">)</span>

<span class="c1"># Adjust layout to prevent clipping of labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1ec8e5bdca7921b37e734e9cddf7f4eef2efad570b00d0d51ec73183a9d97fcc.png" src="../_images/1ec8e5bdca7921b37e734e9cddf7f4eef2efad570b00d0d51ec73183a9d97fcc.png" />
</div>
</div>
</div>
<div class="section" id="mutant-discovery">
<h3>Mutant Discovery<a class="headerlink" href="#mutant-discovery" title="Permalink to this headline">#</a></h3>
<p>We can now translate the logits/probabilities back into the sequence space, by mapping the highest probability in each position to the corresponding amino acid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicted seq (Argmax --&gt; Collect token IDs of predicted seq --&gt; Convert to amino acids)</span>
<span class="n">pred_idx_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probas_final</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">pred_seq</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ids_to_text</span><span class="p">(</span><span class="n">pred_idx_list</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="c1"># Original seq</span>
<span class="n">true_idx_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">text_to_ids</span><span class="p">(</span><span class="n">seq</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">positions</span><span class="p">]</span>
<span class="n">true_seq</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ids_to_text</span><span class="p">(</span><span class="n">true_idx_list</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s compare the sequences and visually inspect the positions where a mutant is suggested over the wild-type. Note that the predicted sequence is displayed on the top, and the original sequence is on the bottom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare prediction (reconstruction) to true (input sequence)</span>
<span class="n">display</span><span class="p">(</span><span class="n">pred_seq</span> <span class="o">+</span> <span class="s2">&quot; (Predicted Sequence)&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span>
    <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;.&quot;</span> <span class="k">if</span> <span class="n">a</span> <span class="o">==</span> <span class="n">b</span> <span class="k">else</span> <span class="s2">&quot;|&quot;</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">true_seq</span><span class="p">)]</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">true_seq</span> <span class="o">+</span> <span class="s2">&quot; (Input Sequence)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;MSEENKIIVVIVAAGKGSRMGSDRPKQYLKIGGKTILEHTI (Predicted Sequence)&#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;..|||.|.||.|...|.|.|.|.|....||..|..|...||&#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;MSLKRKNIALIPAAGIGVRFGADKPKQYVEIGSKTVLEHVL (Input Sequence)&#39;
</pre></div>
</div>
</div>
</div>
<p>Amongst the mismatches, we can:</p>
<ol class="arabic simple">
<li><p>Collect all positions where a mutant is suggested over the wild-type amino acid.</p></li>
<li><p>At these positions, find the mutant with the highest probability.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Collect indices where a mutant is suggested over the wild-type</span>
<span class="n">matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">c1</span> <span class="o">==</span> <span class="n">c2</span> <span class="k">for</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">true_seq</span><span class="p">)]</span>
<span class="n">mismatch_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="p">]</span>

<span class="c1"># Filter probability matrix to mismatches-only</span>
<span class="n">probas_mismatch</span> <span class="o">=</span> <span class="n">probas_final</span><span class="p">[</span><span class="n">mismatch_index</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Find index of mutant with highest likelihood</span>
<span class="n">index_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probas_mismatch</span><span class="p">)</span>
<span class="n">index_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">index_flat</span><span class="p">,</span> <span class="n">probas_mismatch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">index_of_interest</span> <span class="o">=</span> <span class="n">mismatch_index</span><span class="p">[</span><span class="n">index_2d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">position_of_interest</span> <span class="o">=</span> <span class="n">positions</span><span class="p">[</span><span class="n">index_of_interest</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Position:&quot;</span><span class="p">,</span> <span class="n">position_of_interest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mutation:&quot;</span><span class="p">,</span> <span class="n">true_seq</span><span class="p">[</span><span class="n">position_of_interest</span><span class="p">]</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">position_of_interest</span><span class="p">)</span> <span class="o">+</span> <span class="n">pred_seq</span><span class="p">[</span><span class="n">position_of_interest</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Position: 32
Mutation: S32G
</pre></div>
</div>
</div>
</div>
<p>Let’s check the probability associated to mutations at this position.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sort tokens by probability</span>
<span class="n">token_ids_sort</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">probas_final</span><span class="p">[</span><span class="n">index_of_interest</span><span class="p">]),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokens_sort</span> <span class="o">=</span> <span class="p">[(</span><span class="n">inferer</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">token_ids_sort</span><span class="p">]</span>

<span class="n">tokens_sort_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tokens_sort</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Token&#39;</span><span class="p">,</span> <span class="s1">&#39;Token ID&#39;</span><span class="p">,</span> <span class="s1">&#39;Probability&#39;</span><span class="p">])</span>
<span class="n">tokens_sort_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Token</th>
      <th>Token ID</th>
      <th>Probability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>G</td>
      <td>6</td>
      <td>0.777364</td>
    </tr>
    <tr>
      <th>1</th>
      <td>D</td>
      <td>13</td>
      <td>0.053317</td>
    </tr>
    <tr>
      <th>2</th>
      <td>N</td>
      <td>17</td>
      <td>0.052636</td>
    </tr>
    <tr>
      <th>3</th>
      <td>E</td>
      <td>9</td>
      <td>0.032532</td>
    </tr>
    <tr>
      <th>4</th>
      <td>S</td>
      <td>8</td>
      <td>0.023811</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It’s clear that for this position, the amino acid Glycine (G) has a higher likelihood than the wild-type, Serine (S). In this way, we can use ESM-2nv to design novel mutant candidates for downstream testing.</p>
<p>There are many ways that we can engineer candidates from ESM-2nv outputs. We can continue finding the top <em>n</em> single-point mutants, find the top <em>n</em> double- or multi-point mutants, randomly sample over the probability space generated by the input sequence, sample only within certain positions of interest (e.g. known active sites), etc. Through this process, a set of mutants can be developed for further <em>in silico</em> or wet lab testing.</p>
</div>
</div>
</div>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../preprocessing-bcp-training-diffdock.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">DiffDock: Preparing Workspace and Data for Pre-training</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="MMB_GenerativeAI_Inference_with_examples.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">BioNeMo - MegaMolBART Inferencing for Generative Chemistry</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2023-2024 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved..<br/>
    Last updated on Oct 17, 2024.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>