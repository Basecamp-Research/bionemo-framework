{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (1.26.4)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, biopython, openpyxl\n",
      "Successfully installed biopython-1.85 et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chromosome</th>\n",
       "      <th>position (hg19)</th>\n",
       "      <th>reference</th>\n",
       "      <th>alt</th>\n",
       "      <th>function.score.mean</th>\n",
       "      <th>func.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.372611</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.108254</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.277963</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.280973</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.973683</td>\n",
       "      <td>INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.373489</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>41276132</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.207552</td>\n",
       "      <td>FUNC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chromosome  position (hg19) reference alt  function.score.mean func.class\n",
       "0          17         41276135         T   G            -0.372611       FUNC\n",
       "1          17         41276135         T   C            -0.045313       FUNC\n",
       "2          17         41276135         T   A            -0.108254       FUNC\n",
       "3          17         41276134         T   G            -0.277963       FUNC\n",
       "4          17         41276134         T   C            -0.388414       FUNC\n",
       "5          17         41276134         T   A            -0.280973       FUNC\n",
       "6          17         41276133         C   T            -0.973683        INT\n",
       "7          17         41276133         C   G            -0.373489       FUNC\n",
       "8          17         41276133         C   A             0.006314       FUNC\n",
       "9          17         41276132         A   T            -0.207552       FUNC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca1_df = pd.read_excel(\n",
    "    os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx'),\n",
    "    header=2,\n",
    ")\n",
    "brca1_df = brca1_df[[\n",
    "    'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',\n",
    "]]\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.372611</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.108254</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.277963</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.280973</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.973683</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.373489</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>41276132</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.207552</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class\n",
       "0     17  41276135   T   G -0.372611  FUNC/INT\n",
       "1     17  41276135   T   C -0.045313  FUNC/INT\n",
       "2     17  41276135   T   A -0.108254  FUNC/INT\n",
       "3     17  41276134   T   G -0.277963  FUNC/INT\n",
       "4     17  41276134   T   C -0.388414  FUNC/INT\n",
       "5     17  41276134   T   A -0.280973  FUNC/INT\n",
       "6     17  41276133   C   T -0.973683  FUNC/INT\n",
       "7     17  41276133   C   G -0.373489  FUNC/INT\n",
       "8     17  41276133   C   A  0.006314  FUNC/INT\n",
       "9     17  41276132   A   T -0.207552  FUNC/INT"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "brca1_df.rename(columns={\n",
    "    'chromosome': 'chrom',\n",
    "    'position (hg19)': 'pos',\n",
    "    'reference': 'ref',\n",
    "    'alt': 'alt',\n",
    "    'function.score.mean': 'score',\n",
    "    'func.class': 'class',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert to two-class system\n",
    "brca1_df['class'] = brca1_df['class'].replace(['FUNC', 'INT'], 'FUNC/INT')\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom          17\n",
      "pos      41276135\n",
      "ref             T\n",
      "alt             G\n",
      "score   -0.372611\n",
      "class    FUNC/INT\n",
      "Name: 0, dtype: object\n",
      "--\n",
      "Reference, SNV 0: ...TGTTCCAATGAACTTTAACACATTAGAAAA...\n",
      "Variant, SNV 0:   ...TGTTCCAATGAACTGTAACACATTAGAAAA...\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 8192\n",
    "\n",
    "# Read the reference genome sequence of chromosome 17\n",
    "with gzip.open(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz'), \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_chr17 = str(record.seq)\n",
    "        break\n",
    "\n",
    "def parse_sequences(pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Parse reference and variant sequences from the reference genome sequence.\n",
    "    \"\"\"\n",
    "    p = pos - 1 # Convert to 0-indexed position\n",
    "    full_seq = seq_chr17\n",
    "\n",
    "    ref_seq_start = max(0, p - WINDOW_SIZE//2)\n",
    "    ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2)\n",
    "    ref_seq = seq_chr17[ref_seq_start:ref_seq_end]\n",
    "    snv_pos_in_ref = min(WINDOW_SIZE//2, p)\n",
    "    var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1:]\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(var_seq) == len(ref_seq)\n",
    "    assert ref_seq[snv_pos_in_ref] == ref\n",
    "    assert var_seq[snv_pos_in_ref] == alt\n",
    "\n",
    "    return ref_seq, var_seq\n",
    "\n",
    "# Parse sequences for the first variant\n",
    "row = brca1_df.iloc[0]\n",
    "ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "print(row)\n",
    "print('--')\n",
    "print(f'Reference, SNV 0: ...{ref_seq[4082:4112]}...')\n",
    "print(f'Variant, SNV 0:   ...{var_seq[4082:4112]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "print(len(ref_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bionemo stuff here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from lightning.fabric.plugins.environments.lightning import find_free_network_port\n",
    "\n",
    "from bionemo.core.data.load import load\n",
    "from bionemo.noodles.nvfaidx import NvFaidx\n",
    "from bionemo.testing.data.fasta import ALU_SEQUENCE, create_fasta_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tmp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "fasta_file_path = Path(\"tmp_path\") / \"test.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences=5\n",
    "target_sequence_lengths =  [3149, 3140, 1024, 3149, 3149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('tmp_path/test.fasta')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_fasta_file(\n",
    "        fasta_file_path, num_sequences, sequence_lengths=target_sequence_lengths, repeating_dna_pattern=ALU_SEQUENCE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = load(\"evo2/1b-8k:1.0\", source=\"pbss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-25 03:16:52 nemo_logging:405] /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/parallel_state.py:971: SyntaxWarning: \"is not\" with 'str' literal. Did you mean \"!=\"?\n",
      "      os.environ['CUDA_DEVICE_MAX_CONNECTIONS'] is not '1'\n",
      "    \n",
      "[NeMo W 2025-02-25 03:16:52 nemo_logging:405] /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/transformer/cuda_graphs.py:741: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "      assert (\n",
      "    \n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 03:16:56 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/checkpoint/convert_to_nemo.py:58: DeprecationWarning: support for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python 3.14\n",
      "  importer = HuggingFaceSavannaHyenaImporter(args.model_path.lstrip(\"hf://\"), model_config=evo2_config)\n",
      "\n",
      "savanna_evo2_1b_base.pt: 100%|█████████████| 2.71G/2.71G [02:50<00:00, 15.9MB/s]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Using byte-level tokenization\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: False\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "\n",
      "[NeMo I 2025-02-25 03:19:51 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:19:51 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 03:20:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-25 03:20:05 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1074: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /workspace/bionemo2/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/checkpoint/convert_to_nemo.py --model-path hf://arcinstitute/savanna_evo2_1b_base --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tmp_path/test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brca1  nemo2_evo2_1b_8k  tmp_path  zeroshot.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(\"nemo2_evo2_1b_8k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"tmp_path\") / \"test_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = (\n",
    "        f\"predict_evo2 --fasta {fasta_file_path} --ckpt-dir {checkpoint_path} \"\n",
    "        f\"--output-dir {output_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "        \"--pipeline-model-parallel-size 1 --context-parallel-size 1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 03:35:36 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-25 03:35:38 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Experiments will be logged at /tmp/tmpjdg3qd3n/default\n",
      "[NeMo W 2025-02-25 03:35:38 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpjdg3qd3n\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-25 03:35:38 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 03:35:38 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-02-25 03:35:38 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1108204800\n",
      "[NeMo I 2025-02-25 03:35:38 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-25 03:35:38 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "[NeMo I 2025-02-25 03:35:38 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-25 03:35:39 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-25 03:35:39 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_files = glob.glob(os.path.join(output_dir, \"predictions__rank_*.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pred_files) == 1, \"Expected 1 prediction file (for this test), got {}\".format(len(pred_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir / \"seq_idx_map.json\", \"r\") as f:\n",
    "    seq_idx_map = json.load(\n",
    "        f\n",
    "    )  # This gives us the mapping from the sequence names to the indices in the predictions.\n",
    "preds = torch.load(pred_files[0])\n",
    "assert isinstance(preds, dict)\n",
    "assert \"token_logits\" in preds\n",
    "assert \"pad_mask\" in preds\n",
    "assert \"seq_idx\" in preds\n",
    "assert len(preds[\"token_logits\"]) == len(preds[\"pad_mask\"]) == len(preds[\"seq_idx\"]) == num_sequences\n",
    "assert len(seq_idx_map) == num_sequences\n",
    "fasta = NvFaidx(fasta_file_path)\n",
    "for i, seq_name in enumerate(sorted(fasta.keys())):\n",
    "    expected_len = target_sequence_lengths[i]\n",
    "    idx = seq_idx_map[seq_name]  # look up the out of order prediction index for this sequence.\n",
    "    assert preds[\"pad_mask\"][idx].sum() == expected_len\n",
    "    assert preds[\"token_logits\"][idx].shape == (max(target_sequence_lengths), 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create fasta file\n",
    "2. Save to specific directory\n",
    "   - how should these look? one break per file, or one big one?\n",
    "3. Use `predict` to score reference sequences\n",
    "4. Use `predict` to score variant sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference sequences saved to: brca1_fasta_files/brca1_reference_sequences.fasta\n",
      "Variant sequences saved to: brca1_fasta_files/brca1_variant_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"brca1_fasta_files\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save reference sequences to FASTA\n",
    "ref_fasta_path = output_dir / \"brca1_reference_sequences.fasta\"\n",
    "with open(ref_fasta_path, \"w\") as f:\n",
    "    for idx, row in brca1_df.iterrows():\n",
    "        ref_seq, _ = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "        # Create unique header for each sequence\n",
    "        f.write(f\">BRCA1_ref_{idx}_pos_{row['pos']}_{row['ref']}_class_{row['class']}\\n\")\n",
    "        # Write sequence with line wrapping at 80 characters\n",
    "        for i in range(0, len(ref_seq), 80):\n",
    "            f.write(f\"{ref_seq[i:i+80]}\\n\")\n",
    "\n",
    "# Save variant sequences to FASTA\n",
    "var_fasta_path = output_dir / \"brca1_variant_sequences.fasta\"\n",
    "with open(var_fasta_path, \"w\") as f:\n",
    "    for idx, row in brca1_df.iterrows():\n",
    "        _, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "        # Create unique header for each sequence\n",
    "        f.write(f\">BRCA1_var_{idx}_pos_{row['pos']}_{row['ref']}to{row['alt']}_class_{row['class']}\\n\")\n",
    "        # Write sequence with line wrapping at 80 characters\n",
    "        for i in range(0, len(var_seq), 80):\n",
    "            f.write(f\"{var_seq[i:i+80]}\\n\")\n",
    "\n",
    "print(f\"Reference sequences saved to: {ref_fasta_path}\")\n",
    "print(f\"Variant sequences saved to: {var_fasta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, score the refernce sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ref_command = (\n",
    "        f\"predict_evo2 --fasta {ref_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "        f\"--output-dir {output_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "        \"--pipeline-model-parallel-size 1 --context-parallel-size 1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 04:41:45 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-25 04:41:47 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Experiments will be logged at /tmp/tmpz7dlvnez/default\n",
      "[NeMo W 2025-02-25 04:41:47 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpz7dlvnez\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-25 04:41:47 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 04:41:47 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-02-25 04:41:47 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1108204800\n",
      "[NeMo I 2025-02-25 04:41:47 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-25 04:41:47 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "[NeMo I 2025-02-25 04:41:47 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-25 04:41:48 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-25 04:41:48 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n",
      "^C\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "!{predict_ref_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above took too long, so let's try a test variant first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test reference sequences saved to: brca1_test_output/test_reference_sequences.fasta\n",
      "Test variant sequences saved to: brca1_test_output/test_variant_sequences.fasta\n",
      "Sample distribution: 700 FUNC/INT, 700 LOF\n",
      "Test reference prediction command:\n",
      "predict_evo2 --fasta brca1_test_output/test_reference_sequences.fasta --ckpt-dir nemo2_evo2_1b_8k --output-dir brca1_test_output/reference --model-size 1b --tensor-parallel-size 1 --pipeline-model-parallel-size 1 --context-parallel-size 1\n",
      "\n",
      "Test variant prediction command:\n",
      "predict_evo2 --fasta brca1_test_output/test_variant_sequences.fasta --ckpt-dir nemo2_evo2_1b_8k --output-dir brca1_test_output/variant --model-size 1b --tensor-parallel-size 1 --pipeline-model-parallel-size 1 --context-parallel-size 1\n"
     ]
    }
   ],
   "source": [
    "# Create a test directory\n",
    "test_output_dir = Path(\"brca1_test_output\")\n",
    "test_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_ref_dir = test_output_dir / \"reference\"\n",
    "test_var_dir = test_output_dir / \"variant\"\n",
    "test_ref_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_var_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_samples = 1400\n",
    "\n",
    "# Get indices for balanced samples\n",
    "func_int_indices = brca1_df[brca1_df['class'] == 'FUNC/INT'].index[:num_samples//2].tolist()\n",
    "lof_indices = brca1_df[brca1_df['class'] == 'LOF'].index[:num_samples//2].tolist()\n",
    "balanced_indices = func_int_indices + lof_indices\n",
    "\n",
    "# Save reference sequences to test FASTA\n",
    "test_ref_fasta_path = test_output_dir / \"test_reference_sequences.fasta\"\n",
    "with open(test_ref_fasta_path, \"w\") as f:\n",
    "    for idx in balanced_indices:\n",
    "        row = brca1_df.loc[idx]\n",
    "        ref_seq, _ = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "        f.write(f\">BRCA1_ref_{idx}_pos_{row['pos']}_{row['ref']}_class_{row['class']}\\n\")\n",
    "        for i in range(0, len(ref_seq), 80):\n",
    "            f.write(f\"{ref_seq[i:i+80]}\\n\")\n",
    "\n",
    "# Save variant sequences to test FASTA\n",
    "test_var_fasta_path = test_output_dir / \"test_variant_sequences.fasta\"\n",
    "with open(test_var_fasta_path, \"w\") as f:\n",
    "    for idx in balanced_indices:\n",
    "        row = brca1_df.loc[idx]\n",
    "        _, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "        f.write(f\">BRCA1_var_{idx}_pos_{row['pos']}_{row['ref']}to{row['alt']}_class_{row['class']}\\n\")\n",
    "        for i in range(0, len(var_seq), 80):\n",
    "            f.write(f\"{var_seq[i:i+80]}\\n\")\n",
    "\n",
    "print(f\"Test reference sequences saved to: {test_ref_fasta_path}\")\n",
    "print(f\"Test variant sequences saved to: {test_var_fasta_path}\")\n",
    "print(f\"Sample distribution: {len(func_int_indices)} FUNC/INT, {len(lof_indices)} LOF\")\n",
    "\n",
    "# Create test predict commands\n",
    "test_predict_ref_command = (\n",
    "    f\"predict_evo2 --fasta {test_ref_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {test_ref_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1\"\n",
    ")\n",
    "\n",
    "test_predict_var_command = (\n",
    "    f\"predict_evo2 --fasta {test_var_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {test_var_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1\"\n",
    ")\n",
    "\n",
    "print(\"Test reference prediction command:\")\n",
    "print(test_predict_ref_command)\n",
    "print(\"\\nTest variant prediction command:\")\n",
    "print(test_predict_var_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 05:58:55 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-25 05:58:57 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Experiments will be logged at /tmp/tmph7n9z6ow/default\n",
      "[NeMo W 2025-02-25 05:58:57 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmph7n9z6ow\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-25 05:58:57 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-25 05:58:57 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 05:58:57 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-02-25 05:58:57 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-25 05:58:58 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1108204800\n",
      "[NeMo I 2025-02-25 05:58:58 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-25 05:58:58 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "[NeMo I 2025-02-25 05:58:58 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-25 05:58:58 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-25 05:58:58 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{test_predict_ref_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 06:07:18 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-25 06:07:19 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Experiments will be logged at /tmp/tmpvhehqr6c/default\n",
      "[NeMo W 2025-02-25 06:07:19 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpvhehqr6c\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 06:07:19 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-25 06:07:19 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-25 06:07:20 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 06:07:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "[NeMo W 2025-02-25 06:07:20 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-25 06:07:20 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1108204800\n",
      "[NeMo I 2025-02-25 06:07:20 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-25 06:07:20 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "[NeMo I 2025-02-25 06:07:20 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspace/bionemo2/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-25 06:07:23 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-25 06:07:23 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{test_predict_var_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so far, we've turned the sequences into fasta files with unique headers per sequence.\n",
    "\n",
    "Then, we ran predictions for these sequences.\n",
    "\n",
    "Recall, we created seq_idx_maps that map FASTA sequence IDs (e.g. the sequence headers) to indices in the prediction arrays.\n",
    "\n",
    "so, now we need to\n",
    "\n",
    "1. load the prediction files and corresponding sequence id maps\n",
    "2. map each sequence id to its original dataframe index\n",
    "3. calculate the delta scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's load the prediction files and sequence id maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 reference prediction files\n",
      "Found 1 variant prediction files\n",
      "Found 1400 reference sequence IDs\n",
      "Found 1400 variant sequence IDs\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "test_ref_dir = Path(\"brca1_test_output/reference\")\n",
    "test_var_dir = Path(\"brca1_test_output/variant\")\n",
    "\n",
    "# Find and load prediction files\n",
    "ref_pred_files = glob.glob(os.path.join(test_ref_dir, \"predictions__rank_*.pt\"))\n",
    "var_pred_files = glob.glob(os.path.join(test_var_dir, \"predictions__rank_*.pt\"))\n",
    "\n",
    "print(f\"Found {len(ref_pred_files)} reference prediction files\")\n",
    "print(f\"Found {len(var_pred_files)} variant prediction files\")\n",
    "\n",
    "# Load sequence ID maps (maps sequence ID -> prediction index)\n",
    "with open(os.path.join(test_ref_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    ref_seq_idx_map = json.load(f)\n",
    "with open(os.path.join(test_var_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    var_seq_idx_map = json.load(f)\n",
    "\n",
    "print(f\"Found {len(ref_seq_idx_map)} reference sequence IDs\")\n",
    "print(f\"Found {len(var_seq_idx_map)} variant sequence IDs\")\n",
    "\n",
    "# Load predictions\n",
    "ref_preds = torch.load(ref_pred_files[0])\n",
    "var_preds = torch.load(var_pred_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Calculate Sequence Liklihoods\n",
    "\n",
    "calculate the normalized log-likelihood for each sequence. For each position in the sequence, we compute the probability the model assigns to the next token, then sum these log probabilities and normalize by sequence length. This gives us a measure of how \"natural\" or \"expected\" the sequence is according to the model. We calculate these scores for both reference and variant sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 512])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_preds[\"token_logits\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_preds[\"pad_mask\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference scores shape: (1400,)\n",
      "Variant scores shape: (1400,)\n"
     ]
    }
   ],
   "source": [
    "# Define function to calculate sequence log-likelihood\n",
    "def calculate_sequence_likelihood(token_logits, pad_mask):\n",
    "    \"\"\"Calculate normalized log-likelihood for sequences.\"\"\"\n",
    "    # Convert to log probabilities\n",
    "    # token_logits is [bs x seq_len x vocab_size]\n",
    "    # need probs for vocab, so take dim=-1\n",
    "    log_probs = torch.log_softmax(token_logits, dim=-1)\n",
    "    \n",
    "    # Shift sequences to predict next token\n",
    "    input_ids = torch.argmax(token_logits, dim=-1)\n",
    "    next_tokens = input_ids[:, 1:].contiguous()\n",
    "    shifted_logits = log_probs[:, :-1, :].contiguous()\n",
    "    shifted_mask = pad_mask[:, 1:].contiguous()\n",
    "    \n",
    "    # Get log probabilities for actual next tokens\n",
    "    gathered_log_probs = torch.gather(\n",
    "        shifted_logits, \n",
    "        dim=2, \n",
    "        index=next_tokens.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "    \n",
    "    # Sum log probabilities and normalize\n",
    "    masked_log_probs = gathered_log_probs * shifted_mask\n",
    "    seq_log_likelihood = masked_log_probs.sum(dim=1)\n",
    "    seq_length = shifted_mask.sum(dim=1)\n",
    "    normalized_log_likelihood = seq_log_likelihood / seq_length\n",
    "    \n",
    "    return normalized_log_likelihood\n",
    "\n",
    "# Calculate scores\n",
    "ref_scores = calculate_sequence_likelihood(ref_preds[\"token_logits\"], ref_preds[\"pad_mask\"])\n",
    "var_scores = calculate_sequence_likelihood(var_preds[\"token_logits\"], var_preds[\"pad_mask\"])\n",
    "\n",
    "# Convert to numpy\n",
    "ref_scores_np = ref_scores.cpu().numpy()\n",
    "var_scores_np = var_scores.cpu().numpy()\n",
    "\n",
    "# Print score shapes for validation\n",
    "print(f\"Reference scores shape: {ref_scores_np.shape}\")\n",
    "print(f\"Variant scores shape: {var_scores_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Map scores back to the original dataframe\n",
    "\n",
    "Create the mappings between the prediction scores and the original dataframe indices. First, we extract the dataframe index from each FASTA sequence ID by parsing the ID string. Then, we create two dictionaries that map from dataframe indices to prediction scores: one for reference sequences and one for variant sequences. Finally, we verify our mappings by checking how many sequences have both reference and variant scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample reference sequence IDs:\n",
      "  BRCA1_ref_1914_pos_41215944_G_class_LOF\n",
      "  BRCA1_ref_1703_pos_41219652_C_class_LOF\n",
      "  BRCA1_ref_394_pos_41267792_C_class_FUNC/INT\n",
      "\n",
      "Sample variant sequence IDs:\n",
      "  BRCA1_var_1389_pos_41222976_AtoT_class_LOF\n",
      "  BRCA1_var_928_pos_41256973_CtoG_class_LOF\n",
      "  BRCA1_var_225_pos_41276060_CtoG_class_FUNC/INT\n",
      "\n",
      "Successfully mapped scores for 1400 sequences\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from sequence ID to original dataframe index\n",
    "ref_df_indices = {}  # Maps: sequence ID -> dataframe index\n",
    "var_df_indices = {}  # Maps: sequence ID -> dataframe index\n",
    "\n",
    "# Print a few sequence IDs to verify format\n",
    "print(\"\\nSample reference sequence IDs:\")\n",
    "for seq_id in list(ref_seq_idx_map.keys())[:3]:\n",
    "    print(f\"  {seq_id}\")\n",
    "\n",
    "print(\"\\nSample variant sequence IDs:\")\n",
    "for seq_id in list(var_seq_idx_map.keys())[:3]:\n",
    "    print(f\"  {seq_id}\")\n",
    "\n",
    "# Extract dataframe indices from sequence IDs\n",
    "for seq_id in ref_seq_idx_map.keys():\n",
    "    parts = seq_id.split('_')\n",
    "    try:\n",
    "        df_idx = int(parts[2])  # Get index from \"BRCA1_ref_INDEX_...\"\n",
    "        ref_df_indices[seq_id] = df_idx\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"Warning: Could not parse index from reference ID: {seq_id}\")\n",
    "\n",
    "for seq_id in var_seq_idx_map.keys():\n",
    "    parts = seq_id.split('_')\n",
    "    try:\n",
    "        df_idx = int(parts[2])  # Get index from \"BRCA1_var_INDEX_...\"\n",
    "        var_df_indices[seq_id] = df_idx\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"Warning: Could not parse index from variant ID: {seq_id}\")\n",
    "\n",
    "# Create maps from dataframe index to prediction scores\n",
    "df_to_ref_score = {}  # Maps: dataframe index -> reference score\n",
    "df_to_var_score = {}  # Maps: dataframe index -> variant score\n",
    "\n",
    "# Map dataframe indices to scores using the sequence ID maps\n",
    "for seq_id, pred_idx in ref_seq_idx_map.items():\n",
    "    if seq_id in ref_df_indices:\n",
    "        df_idx = ref_df_indices[seq_id]\n",
    "        df_to_ref_score[df_idx] = ref_scores_np[pred_idx]\n",
    "\n",
    "for seq_id, pred_idx in var_seq_idx_map.items():\n",
    "    if seq_id in var_df_indices:\n",
    "        df_idx = var_df_indices[seq_id]\n",
    "        df_to_var_score[df_idx] = var_scores_np[pred_idx]\n",
    "\n",
    "# Verification: How many sequences could we map?\n",
    "common_indices = set(df_to_ref_score.keys()).intersection(set(df_to_var_score.keys()))\n",
    "print(f\"\\nSuccessfully mapped scores for {len(common_indices)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate delta scores\n",
    "\n",
    "alculates the delta scores (variant minus reference) for each sequence pair and adds them to both the original dataframe and a new test results dataframe. The delta score represents how much the variant affects the model's confidence in the sequence - a negative delta suggests the variant makes the sequence less likely, potentially indicating a disruptive mutation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test results summary:\n",
      "Total sequences: 1400\n",
      "Class distribution:\n",
      "class\n",
      "FUNC/INT    700\n",
      "LOF         700\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary statistics by class:\n",
      "          count      mean       std       min       25%       50%       75%  \\\n",
      "class                                                                         \n",
      "FUNC/INT  700.0  0.000052  0.000791 -0.002264 -0.000492  0.000059  0.000550   \n",
      "LOF       700.0  0.000154  0.000837 -0.002735 -0.000349  0.000161  0.000678   \n",
      "\n",
      "               max  \n",
      "class               \n",
      "FUNC/INT  0.003455  \n",
      "LOF       0.003263  \n",
      "\n",
      "Sample results:\n",
      "   ref_score  var_score  delta_score     class\n",
      "0  -1.535315  -1.536206    -0.000891  FUNC/INT\n",
      "1  -1.535315  -1.535313     0.000003  FUNC/INT\n",
      "2  -1.535315  -1.536393    -0.001077  FUNC/INT\n",
      "3  -1.537211  -1.538639    -0.001428  FUNC/INT\n",
      "4  -1.537211  -1.537266    -0.000056  FUNC/INT\n",
      "\n",
      "Found scores for 1400/1400 expected indices\n"
     ]
    }
   ],
   "source": [
    "# Calculate delta scores and add to dataframe\n",
    "delta_scores = {}\n",
    "for idx in common_indices:\n",
    "    delta = df_to_var_score[idx] - df_to_ref_score[idx]\n",
    "    delta_scores[idx] = delta\n",
    "    brca1_df.loc[idx, 'evo2_delta_score'] = delta\n",
    "\n",
    "# Create test results dataframe for further analysis\n",
    "test_results = pd.DataFrame(index=sorted(common_indices))\n",
    "test_results['ref_score'] = [df_to_ref_score[idx] for idx in test_results.index]\n",
    "test_results['var_score'] = [df_to_var_score[idx] for idx in test_results.index]\n",
    "test_results['delta_score'] = [delta_scores[idx] for idx in test_results.index]\n",
    "test_results['class'] = brca1_df.loc[test_results.index, 'class'].values\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nTest results summary:\")\n",
    "print(f\"Total sequences: {len(test_results)}\")\n",
    "print(\"Class distribution:\")\n",
    "print(test_results['class'].value_counts())\n",
    "print(\"\\nSummary statistics by class:\")\n",
    "print(test_results.groupby('class')['delta_score'].describe())\n",
    "\n",
    "# Look at a few examples\n",
    "print(\"\\nSample results:\")\n",
    "print(test_results.head())\n",
    "\n",
    "# Validate expected indices (if balanced_indices is available)\n",
    "if 'balanced_indices' in locals():\n",
    "    expected = set(balanced_indices)\n",
    "    found = set(test_results.index)\n",
    "    print(f\"\\nFound scores for {len(found.intersection(expected))}/{len(expected)} expected indices\")\n",
    "    if len(expected - found) > 0:\n",
    "        print(f\"Missing scores for {len(expected - found)} expected indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot prediction AUROC: 0.46\n",
      "\n",
      "Class distributions:\n",
      "  FUNC/INT median delta score: 0.000059\n",
      "  LOF median delta score: 0.000161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Only proceed if we have both classes in our results\n",
    "if len(test_results['class'].unique()) > 1:\n",
    "    # Calculate AUROC - we use negative delta score since more negative values \n",
    "    # are expected to correlate with loss-of-function\n",
    "    y_true = (test_results['class'] == 'LOF')\n",
    "    y_score = -test_results['delta_score']\n",
    "    \n",
    "    auroc = roc_auc_score(y_true, y_score)\n",
    "    print(f'Zero-shot prediction AUROC: {auroc:.2f}')\n",
    "    \n",
    "    # Calculate ROC curve for possible visualization\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    \n",
    "    # Print some additional classification metrics\n",
    "    print(f\"\\nClass distributions:\")\n",
    "    print(f\"  FUNC/INT median delta score: {test_results[test_results['class']=='FUNC/INT']['delta_score'].median():.6f}\")\n",
    "    print(f\"  LOF median delta score: {test_results[test_results['class']=='LOF']['delta_score'].median():.6f}\")\n",
    "else:\n",
    "    print(\"Cannot calculate AUROC - need examples from both classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plot aesthetics\n",
    "plt.figure(figsize=(4, 2))\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot stripplot of distributions\n",
    "p = sns.stripplot(\n",
    "    data=test_results,\n",
    "    x='delta_score',\n",
    "    y='class',\n",
    "    hue='class',\n",
    "    order=['FUNC/INT', 'LOF'],\n",
    "    palette=['#777777', 'C3'],\n",
    "    size=2,\n",
    "    jitter=0.3,\n",
    ")\n",
    "\n",
    "# Mark medians from each distribution with a line\n",
    "sns.boxplot(\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    meanprops={'visible': False},\n",
    "    medianprops={'color': 'k', 'ls': '-', 'lw': 2},\n",
    "    whiskerprops={'visible': False},\n",
    "    zorder=10,\n",
    "    x=\"delta_score\",\n",
    "    y=\"class\",\n",
    "    data=test_results,\n",
    "    showfliers=False,\n",
    "    showbox=False,\n",
    "    showcaps=False,\n",
    "    ax=p\n",
    ")\n",
    "\n",
    "# Add labels and adjust layout\n",
    "plt.xlabel('Delta likelihood score, Evo 2')\n",
    "plt.ylabel('BRCA1 SNV class')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display\n",
    "plt.savefig('brca1_delta_scores.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sequence_likelihood_corrected(token_logits, pad_mask):\n",
    "    \"\"\"Calculate log-likelihood based on original implementation.\"\"\"\n",
    "    # Convert to log probabilities\n",
    "    log_probs = torch.log_softmax(token_logits, dim=-1)\n",
    "    \n",
    "    # Get most likely tokens at each position (our best approximation of input)\n",
    "    input_ids = torch.argmax(token_logits, dim=-1)\n",
    "    \n",
    "    # Shift sequences (targets are shifted by 1 from inputs)\n",
    "    targets = input_ids[:, 1:].contiguous()\n",
    "    shifted_logits = log_probs[:, :-1, :].contiguous()\n",
    "    shifted_mask = pad_mask[:, 1:].contiguous()\n",
    "    \n",
    "    # Get log probabilities for the next tokens\n",
    "    gathered_log_probs = torch.gather(\n",
    "        shifted_logits, \n",
    "        dim=2, \n",
    "        index=targets.unsqueeze(-1)\n",
    "    ).squeeze(-1)\n",
    "    \n",
    "    # Apply mask\n",
    "    masked_log_probs = gathered_log_probs * shifted_mask\n",
    "    \n",
    "    # Sum and normalize (using mean method)\n",
    "    seq_sum = masked_log_probs.sum(dim=1)\n",
    "    seq_length = shifted_mask.sum(dim=1)\n",
    "    normalized_log_likelihood = seq_sum / seq_length\n",
    "    \n",
    "    return normalized_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC with negative delta scores: 0.463\n",
      "AUROC with positive delta scores: 0.537\n"
     ]
    }
   ],
   "source": [
    "# Calculate normalized log-likelihoods with corrected method\n",
    "ref_scores = calculate_sequence_likelihood_corrected(ref_preds[\"token_logits\"], ref_preds[\"pad_mask\"])\n",
    "var_scores = calculate_sequence_likelihood_corrected(var_preds[\"token_logits\"], var_preds[\"pad_mask\"])\n",
    "\n",
    "# Convert to numpy\n",
    "ref_scores_np = ref_scores.cpu().numpy()\n",
    "var_scores_np = var_scores.cpu().numpy()\n",
    "\n",
    "# Rest of mapping code remains the same...\n",
    "\n",
    "# When calculating AUROC, try both directions\n",
    "y_true = (test_results['class'] == 'LOF')\n",
    "auroc_neg = roc_auc_score(y_true, -test_results['delta_score'])\n",
    "auroc_pos = roc_auc_score(y_true, test_results['delta_score'])\n",
    "\n",
    "print(f\"AUROC with negative delta scores: {auroc_neg:.3f}\")\n",
    "print(f\"AUROC with positive delta scores: {auroc_pos:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
