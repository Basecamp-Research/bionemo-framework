{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.85)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from bionemo.noodles.nvfaidx import NvFaidx\n",
    "from bionemo.testing.data.fasta import ALU_SEQUENCE, create_fasta_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "1. Load evo2 model from hf checkpoints\n",
    "1. Create fasta files for brca_1 data\n",
    "2. Save to separate directory (one for reference, one for variance)\n",
    "3. Use `predict` to score reference sequences\n",
    "4. Use `predict` to score variant sequences\n",
    "5. Compare (todo: ask John, my logic wrong for sure)\n",
    "6. calculate auc\n",
    "7. plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load brca_1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data if not present\n",
    "if not os.path.exists('brca1'):\n",
    "    os.makedirs('brca1')\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/refs/heads/main/notebooks/brca1/41586_2018_461_MOESM3_ESM.xlsx -O brca1/41586_2018_461_MOESM3_ESM.xlsx\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/refs/heads/main/notebooks/brca1/GRCh37.p13_chr17.fna.gz -O brca1/GRCh37.p13_chr17.fna.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.372611</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.108254</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.277963</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.280973</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.973683</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.373489</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>41276132</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.207552</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class\n",
       "0     17  41276135   T   G -0.372611  FUNC/INT\n",
       "1     17  41276135   T   C -0.045313  FUNC/INT\n",
       "2     17  41276135   T   A -0.108254  FUNC/INT\n",
       "3     17  41276134   T   G -0.277963  FUNC/INT\n",
       "4     17  41276134   T   C -0.388414  FUNC/INT\n",
       "5     17  41276134   T   A -0.280973  FUNC/INT\n",
       "6     17  41276133   C   T -0.973683  FUNC/INT\n",
       "7     17  41276133   C   G -0.373489  FUNC/INT\n",
       "8     17  41276133   C   A  0.006314  FUNC/INT\n",
       "9     17  41276132   A   T -0.207552  FUNC/INT"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca1_df = pd.read_excel(\n",
    "    os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx'),\n",
    "    header=2,\n",
    ")\n",
    "brca1_df = brca1_df[[\n",
    "    'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',\n",
    "]]\n",
    "\n",
    "# Rename columns\n",
    "brca1_df.rename(columns={\n",
    "    'chromosome': 'chrom',\n",
    "    'position (hg19)': 'pos',\n",
    "    'reference': 'ref',\n",
    "    'alt': 'alt',\n",
    "    'function.score.mean': 'score',\n",
    "    'func.class': 'class',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert to two-class system\n",
    "brca1_df['class'] = brca1_df['class'].replace(['FUNC', 'INT'], 'FUNC/INT')\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 8192\n",
    "\n",
    "# Read the reference genome sequence of chromosome 17\n",
    "with gzip.open(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz'), \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_chr17 = str(record.seq)\n",
    "        break\n",
    "\n",
    "def parse_sequences(pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Parse reference and variant sequences from the reference genome sequence.\n",
    "    \"\"\"\n",
    "    p = pos - 1 # Convert to 0-indexed position\n",
    "    full_seq = seq_chr17\n",
    "\n",
    "    ref_seq_start = max(0, p - WINDOW_SIZE//2)\n",
    "    ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2)\n",
    "    ref_seq = seq_chr17[ref_seq_start:ref_seq_end]\n",
    "    snv_pos_in_ref = min(WINDOW_SIZE//2, p)\n",
    "    var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1:]\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(var_seq) == len(ref_seq)\n",
    "    assert ref_seq[snv_pos_in_ref] == ref\n",
    "    assert var_seq[snv_pos_in_ref] == alt\n",
    "\n",
    "    return ref_seq, var_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom          17\n",
      "pos      41276135\n",
      "ref             T\n",
      "alt             G\n",
      "score   -0.372611\n",
      "class    FUNC/INT\n",
      "Name: 0, dtype: object\n",
      "--\n",
      "Reference, SNV 0: ...TGTTCCAATGAACTTTAACACATTAGAAAA...\n",
      "Variant, SNV 0:   ...TGTTCCAATGAACTGTAACACATTAGAAAA...\n",
      "8192\n"
     ]
    }
   ],
   "source": [
    "# TODO: Delete this, just for parity\n",
    "# Parse sequences for the first variant\n",
    "row = brca1_df.iloc[0]\n",
    "ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "print(row)\n",
    "print('--')\n",
    "print(f'Reference, SNV 0: ...{ref_seq[4082:4112]}...')\n",
    "print(f'Variant, SNV 0:   ...{var_seq[4082:4112]}...')\n",
    "print(len(ref_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring likelihoods of 1326 reference sequences with Evo 2...\n",
      "Scoring likelihoods of 3893 variant sequences with Evo 2...\n"
     ]
    }
   ],
   "source": [
    "# Build mappings of unique reference sequences\n",
    "ref_seqs = []\n",
    "ref_seq_to_index = {}\n",
    "\n",
    "# Parse sequences and store indexes\n",
    "ref_seq_indexes = []\n",
    "var_seqs = []\n",
    "\n",
    "for _, row in brca1_df.iterrows():\n",
    "    ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "    # Get or create index for reference sequence\n",
    "    if ref_seq not in ref_seq_to_index:\n",
    "        ref_seq_to_index[ref_seq] = len(ref_seqs)\n",
    "        ref_seqs.append(ref_seq)\n",
    "    \n",
    "    ref_seq_indexes.append(ref_seq_to_index[ref_seq])\n",
    "    var_seqs.append(var_seq)\n",
    "\n",
    "ref_seq_indexes = np.array(ref_seq_indexes)\n",
    "\n",
    "\n",
    "print(f'Scoring likelihoods of {len(ref_seqs)} reference sequences with Evo 2...')\n",
    "\n",
    "print(f'Scoring likelihoods of {len(var_seqs)} variant sequences with Evo 2...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Evo2\n",
    "\n",
    "We'll load evo2 weights from hugging face.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-26 22:42:53 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-26 22:42:56 nemo_logging:393] Using byte-level tokenization\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: False\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "\n",
      "[NeMo I 2025-02-26 22:42:57 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:42:57 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/usr/local/bin/evo2_convert_to_nemo2\", line 8, in <module>\n",
      "[rank0]:     sys.exit(main())\n",
      "[rank0]:              ^^^^^^\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/checkpoint/convert_to_nemo.py\", line 61, in main\n",
      "[rank0]:     importer.apply(args.output_dir)\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/3rdparty/NeMo/nemo/collections/llm/gpt/model/hyena.py\", line 581, in apply\n",
      "[rank0]:     self.nemo_save(output_path, trainer)\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/3rdparty/NeMo/nemo/lightning/io/connector.py\", line 207, in nemo_save\n",
      "[rank0]:     trainer.save_checkpoint(output_path)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1365, in save_checkpoint\n",
      "[rank0]:     self.strategy.save_checkpoint(checkpoint, filepath, storage_options=storage_options)\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/3rdparty/NeMo/nemo/lightning/pytorch/strategies/megatron_strategy.py\", line 791, in save_checkpoint\n",
      "[rank0]:     self.checkpoint_io.save_checkpoint(checkpoint, filepath, storage_options=storage_options)\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/3rdparty/NeMo/nemo/lightning/io/pl.py\", line 200, in save_checkpoint\n",
      "[rank0]:     return dist_checkpointing.save(\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/serialization.py\", line 354, in save\n",
      "[rank0]:     raise CheckpointingException(\n",
      "[rank0]: megatron.core.dist_checkpointing.core.CheckpointingException: Checkpoint destination directory (nemo2_evo2_1b_8k/weights) is not empty\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 --model-path hf://arcinstitute/savanna_evo2_1b_base --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to store a `Path` reference to where these checkpoints were saved so we can use them in the `predict` command later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: match path here with above command via shared string template\n",
    "checkpoint_path = Path(\"nemo2_evo2_1b_8k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to directories\n",
    "\n",
    "Convert both the reference and variant fasta sequences to their own respective `.fasta` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRAC = 1.0\n",
    "if SAMPLE_FRAC < 1.0:\n",
    "    brca1_df = brca1_df.sample(frac=SAMPLE_FRAC).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique reference sequences: 1326\n",
      "Total unique variant sequences: 3893\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"brca1_fasta_files\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save reference and variant sequences to FASTA\n",
    "ref_fasta_path = output_dir / \"brca1_reference_sequences.fasta\"\n",
    "var_fasta_path = output_dir / \"brca1_variant_sequences.fasta\"\n",
    "\n",
    "# Track unique sequences\n",
    "ref_sequences = set()\n",
    "var_sequences = set()\n",
    "ref_seq_to_name = {}\n",
    "# Store unique sequences with metadata for writing\n",
    "ref_entries = []\n",
    "var_entries = []\n",
    "ref_names = []\n",
    "var_names = []\n",
    "# Collect unique reference and variant sequences\n",
    "for idx, row in brca1_df.iterrows():\n",
    "    ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "    # Add to sets to ensure uniqueness\n",
    "    if ref_seq not in ref_sequences:\n",
    "        ref_sequences.add(ref_seq)\n",
    "        ref_name = f\"BRCA1_ref_pos_{row['pos']}_{row['ref']}_class_{row['class']}\"\n",
    "\n",
    "        ref_entries.append(\n",
    "            f\">{ref_name}\\n{ref_seq}\\n\"\n",
    "        )\n",
    "        ref_names.append(ref_name)\n",
    "        ref_seq_to_name[ref_seq] = ref_name\n",
    "    else:\n",
    "        ref_name = ref_seq_to_name[ref_seq]\n",
    "        ref_names.append(ref_name)\n",
    "    if var_seq not in var_sequences:\n",
    "        var_sequences.add(var_seq)\n",
    "        var_name = f\"BRCA1_var_pos_{row['pos']}_{row['ref']}to{row['alt']}_class_{row['class']}\"\n",
    "\n",
    "        var_entries.append(\n",
    "            f\">{var_name}\\n{var_seq}\\n\"\n",
    "        )\n",
    "        var_names.append(var_name)\n",
    "    else:\n",
    "        assert False, \"Duplicate variant sequence\"\n",
    "\n",
    "# Write unique sequences to FASTA files\n",
    "with open(ref_fasta_path, \"w\") as f:\n",
    "    f.writelines(ref_entries)\n",
    "\n",
    "with open(var_fasta_path, \"w\") as f:\n",
    "    f.writelines(var_entries)\n",
    "\n",
    "# Print counts\n",
    "print(f\"Total unique reference sequences: {len(ref_sequences)}\")\n",
    "print(f\"Total unique variant sequences: {len(var_sequences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_df['ref_fasta_name'] = ref_names\n",
    "brca1_df['var_fasta_name'] = var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Samples of Reference/Variants.\n",
    "\n",
    "The full samples takes too long for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directories for prediction results\n",
    "predict_ref_dir = output_dir / \"reference_predictions\"\n",
    "predict_var_dir = output_dir / \"variant_predictions\"\n",
    "predict_ref_dir.mkdir(parents=True, exist_ok=True)\n",
    "predict_var_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Update predict commands to run on the full dataset\n",
    "predict_ref_command = (\n",
    "    f\"predict_evo2 --fasta {ref_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_ref_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs\"\n",
    ")\n",
    "\n",
    "predict_var_command = (\n",
    "    f\"predict_evo2 --fasta {var_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_var_dir} --model-size 1b --tensor-parallel-size 1 \"\n",
    "    \"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-26 22:43:10 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-26 22:43:12 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Experiments will be logged at /tmp/tmpa1nhlpo0/default\n",
      "[NeMo W 2025-02-26 22:43:12 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpa1nhlpo0\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-26 22:43:12 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:43:12 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "[NeMo W 2025-02-26 22:43:12 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-02-26 22:43:12 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-26 22:43:12 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "[NeMo I 2025-02-26 22:43:12 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-26 22:43:13 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-26 22:43:13 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{predict_ref_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict variant seqs (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-26 22:50:48 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-26 22:50:50 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Experiments will be logged at /tmp/tmp8_5fsaxe/default\n",
      "[NeMo W 2025-02-26 22:50:50 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmp8_5fsaxe\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-26 22:50:50 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-26 22:50:50 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-26 22:50:51 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "[NeMo W 2025-02-26 22:50:51 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-02-26 22:50:51 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-02-26 22:50:51 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-26 22:50:51 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "[NeMo I 2025-02-26 22:50:51 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-26 22:50:51 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-26 22:50:51 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{predict_var_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so far, we've turned the sequences into fasta files with unique headers per sequence.\n",
    "\n",
    "Then, we ran predictions for these sequences.\n",
    "\n",
    "Recall, we created seq_idx_maps that map FASTA sequence IDs (e.g. the sequence headers) to indices in the prediction arrays.\n",
    "\n",
    "so, now we need to\n",
    "\n",
    "1. load the prediction files and corresponding sequence id maps\n",
    "2. map each sequence id to its original dataframe index\n",
    "3. calculate the delta scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's load the prediction files and sequence id maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load prediction files\n",
    "ref_pred_files = glob.glob(os.path.join(predict_ref_dir, \"predictions__rank_*.pt\"))\n",
    "var_pred_files = glob.glob(os.path.join(predict_var_dir, \"predictions__rank_*.pt\"))\n",
    "\n",
    "# Load sequence ID maps (maps sequence ID -> prediction index)\n",
    "with open(os.path.join(predict_ref_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    ref_seq_idx_map = json.load(f)\n",
    "with open(os.path.join(predict_var_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    var_seq_idx_map = json.load(f)\n",
    "\n",
    "# Load predictions\n",
    "ref_preds = torch.load(ref_pred_files[0])\n",
    "var_preds = torch.load(var_pred_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "      <th>ref_fasta_name</th>\n",
       "      <th>var_fasta_name</th>\n",
       "      <th>ref_log_probs</th>\n",
       "      <th>var_log_probs</th>\n",
       "      <th>diff_score</th>\n",
       "      <th>evo2_delta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276062</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.056789</td>\n",
       "      <td>FUNC/INT</td>\n",
       "      <td>BRCA1_ref_pos_41276062_T_class_FUNC/INT</td>\n",
       "      <td>BRCA1_var_pos_41276062_TtoA_class_FUNC/INT</td>\n",
       "      <td>-1.633416</td>\n",
       "      <td>-1.633648</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41215890</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-1.796453</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41215890_C_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41215890_CtoT_class_LOF</td>\n",
       "      <td>-1.782346</td>\n",
       "      <td>-1.782195</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41201178</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.999553</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41201178_G_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41201178_GtoA_class_LOF</td>\n",
       "      <td>-1.718188</td>\n",
       "      <td>-1.718212</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41219643</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>-1.652875</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41219643_G_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41219643_GtoC_class_LOF</td>\n",
       "      <td>-1.592031</td>\n",
       "      <td>-1.592255</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41215913</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.360066</td>\n",
       "      <td>FUNC/INT</td>\n",
       "      <td>BRCA1_ref_pos_41215913_T_class_FUNC/INT</td>\n",
       "      <td>BRCA1_var_pos_41215913_TtoA_class_FUNC/INT</td>\n",
       "      <td>-1.791920</td>\n",
       "      <td>-1.792505</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>-0.000585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class  \\\n",
       "0     17  41276062   T   A -0.056789  FUNC/INT   \n",
       "1     17  41215890   C   T -1.796453       LOF   \n",
       "2     17  41201178   G   A -1.999553       LOF   \n",
       "3     17  41219643   G   C -1.652875       LOF   \n",
       "4     17  41215913   T   A -0.360066  FUNC/INT   \n",
       "\n",
       "                            ref_fasta_name  \\\n",
       "0  BRCA1_ref_pos_41276062_T_class_FUNC/INT   \n",
       "1       BRCA1_ref_pos_41215890_C_class_LOF   \n",
       "2       BRCA1_ref_pos_41201178_G_class_LOF   \n",
       "3       BRCA1_ref_pos_41219643_G_class_LOF   \n",
       "4  BRCA1_ref_pos_41215913_T_class_FUNC/INT   \n",
       "\n",
       "                               var_fasta_name  ref_log_probs  var_log_probs  \\\n",
       "0  BRCA1_var_pos_41276062_TtoA_class_FUNC/INT      -1.633416      -1.633648   \n",
       "1       BRCA1_var_pos_41215890_CtoT_class_LOF      -1.782346      -1.782195   \n",
       "2       BRCA1_var_pos_41201178_GtoA_class_LOF      -1.718188      -1.718212   \n",
       "3       BRCA1_var_pos_41219643_GtoC_class_LOF      -1.592031      -1.592255   \n",
       "4  BRCA1_var_pos_41215913_TtoA_class_FUNC/INT      -1.791920      -1.792505   \n",
       "\n",
       "   diff_score  evo2_delta_score  \n",
       "0   -0.000232         -0.000232  \n",
       "1    0.000151          0.000151  \n",
       "2   -0.000023         -0.000023  \n",
       "3   -0.000224         -0.000224  \n",
       "4   -0.000585         -0.000585  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_log_probs = []\n",
    "var_log_probs = []\n",
    "for _, row in brca1_df.iterrows():\n",
    "    ref_name = row['ref_fasta_name']\n",
    "    var_name = row['var_fasta_name']\n",
    "    ref_log_probs.append(ref_preds['log_probs_seqs'][ref_seq_idx_map[ref_name]].item())\n",
    "    var_log_probs.append(var_preds['log_probs_seqs'][var_seq_idx_map[var_name]].item())\n",
    "brca1_df['ref_log_probs'] = ref_log_probs\n",
    "brca1_df['var_log_probs'] = var_log_probs\n",
    "# ideally probability of a broken variant is lower than a good one. So a bad var - good ref is negative.\n",
    "brca1_df['evo2_delta_score'] = brca1_df['var_log_probs'] - brca1_df['ref_log_probs']\n",
    "brca1_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot prediction AUROC: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUROC of zero-shot predictions\n",
    "#  class 1 is LOF which is the bad thing. That means we expect this to be more negative.\n",
    "y_true = (brca1_df['class'] == 'LOF')\n",
    "auroc = roc_auc_score(y_true, -brca1_df['evo2_delta_score'])\n",
    "print(f'Zero-shot prediction AUROC: {auroc:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "# Plot stripplot of distributions\n",
    "p = sns.stripplot(\n",
    "    data=brca1_df,\n",
    "    x='evo2_delta_score',\n",
    "    y='class',\n",
    "    hue='class',\n",
    "    order=['FUNC/INT', 'LOF'],\n",
    "    palette=['#777777', 'C3'],\n",
    "    size=2,\n",
    "    jitter=0.3,\n",
    ")\n",
    "\n",
    "# Mark medians from each distribution\n",
    "sns.boxplot(showmeans=True,\n",
    "            meanline=True,\n",
    "            meanprops={'visible': False},\n",
    "            medianprops={'color': 'k', 'ls': '-', 'lw': 2},\n",
    "            whiskerprops={'visible': False},\n",
    "            zorder=10,\n",
    "            x=\"evo2_delta_score\",\n",
    "            y=\"class\",\n",
    "            data=brca1_df,\n",
    "            showfliers=False,\n",
    "            showbox=False,\n",
    "            showcaps=False,\n",
    "            ax=p)\n",
    "plt.xlabel('Delta likelihood score, Evo 2')\n",
    "plt.ylabel('BRCA1 SNV class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
